{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset-Lenta-2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmX41fGZrNAG"
      },
      "source": [
        "## Локальное подключение Google Диска"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7V3RL0upWuP",
        "outputId": "41fac6f7-b6ff-49e8-88f8-f0d96a245a5e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdyvNYO_toU0",
        "outputId": "60b8a208-94a7-42d6-cd53-58c441bd9cc2"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUagVV6z0z8T",
        "outputId": "625a718d-ff13-4c09-fd01-897e3a958ca5"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Mar 18 11:27:12 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYWSIYMK7nXR"
      },
      "source": [
        "## Читаем датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKfPjCcarP_0",
        "outputId": "d1cc2225-f616-4e32-aaf2-a49703f4ffea"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "\r\n",
        "df = pd.read_csv(\"drive/My Drive/lenta-ru-news.csv\")\r\n",
        "\r\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/Datasets/data_from_Sait/lenta-ru-news.csv\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "J1cr96AzrXdX",
        "outputId": "4f754dce-b42c-4693-f989-809a3243f73f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "      <th>tags</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://lenta.ru/news/1914/09/16/hungarnn/</td>\n",
              "      <td>1914. Русские войска вступили в пределы Венгрии</td>\n",
              "      <td>Бои у Сопоцкина и Друскеник закончились отступ...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://lenta.ru/news/1914/09/16/lermontov/</td>\n",
              "      <td>1914. Празднование столетия М.Ю. Лермонтова от...</td>\n",
              "      <td>Министерство народного просвещения, в виду про...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://lenta.ru/news/1914/09/17/nesteroff/</td>\n",
              "      <td>1914. Das ist Nesteroff!</td>\n",
              "      <td>Штабс-капитан П. Н. Нестеров на днях, увидев в...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://lenta.ru/news/1914/09/17/bulldogn/</td>\n",
              "      <td>1914. Бульдог-гонец под Льежем</td>\n",
              "      <td>Фотограф-корреспондент Daily Mirror рассказыва...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://lenta.ru/news/1914/09/18/zver/</td>\n",
              "      <td>1914. Под Люблином пойман швабский зверь</td>\n",
              "      <td>Лица, приехавшие в Варшаву из Люблина, передаю...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           url  ...        date\n",
              "0   https://lenta.ru/news/1914/09/16/hungarnn/  ...  1914/09/16\n",
              "1  https://lenta.ru/news/1914/09/16/lermontov/  ...  1914/09/16\n",
              "2  https://lenta.ru/news/1914/09/17/nesteroff/  ...  1914/09/17\n",
              "3   https://lenta.ru/news/1914/09/17/bulldogn/  ...  1914/09/17\n",
              "4       https://lenta.ru/news/1914/09/18/zver/  ...  1914/09/18\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYrax3_Y7r7v"
      },
      "source": [
        "## Смотрим на темы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO33Ti5bucLD",
        "outputId": "d5fde76e-d7f5-4a81-a928-7f98a3b45d00"
      },
      "source": [
        "df['topic'].unique()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Библиотека', 'Россия', 'Мир', 'Экономика', 'Интернет и СМИ',\n",
              "       'Спорт', 'Культура', 'Из жизни', 'Силовые структуры',\n",
              "       'Наука и техника', 'Бывший СССР', nan, 'Дом', 'Сочи', 'ЧМ-2014',\n",
              "       'Путешествия', 'Ценности', 'Легпром', 'Бизнес', 'МедНовости',\n",
              "       'Оружие', '69-я параллель', 'Культпросвет ', 'Крым'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8O2aBke7ksS"
      },
      "source": [
        "topic1 = df['text'][(df['topic']=='Спорт')].reset_index(drop=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTb3RRXy9Rm9"
      },
      "source": [
        "topic2 = df['text'][(df['topic']=='Наука и техника')].reset_index(drop=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onqG1V8R9hme"
      },
      "source": [
        "topic1 = topic1.tolist()[:1000]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhZcTLrB9ji-"
      },
      "source": [
        "topic2 = topic2.tolist()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMB_6E5OHwnk",
        "outputId": "bc1f78f2-9413-444f-97dd-168837d8965c"
      },
      "source": [
        "len(topic1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuH1ulRlHyva",
        "outputId": "a7ae7734-0838-444e-a67c-a0b55058a3c4"
      },
      "source": [
        "len(topic2)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53136"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u982mJK99aG",
        "outputId": "23c51f61-68f3-4fdc-d304-936f10b5875f"
      },
      "source": [
        "print(max([len(x) for x in topic1]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYI6vGoK-E8Z",
        "outputId": "a4422858-4e84-4b8f-e996-9e0710905f6e"
      },
      "source": [
        "print(max([len(x) for x in topic2]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "kHelWPjZM0MN",
        "outputId": "7d6bd621-3723-4fb5-8b9f-150410197815"
      },
      "source": [
        "topic2[0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Американские ученые в ближайшее время отправят на орбиту спутник, который проверит два фундаментальных предположения, выдвинутых Альбертом Эйнштейном в рамках общей теории относительности, сообщает Associated Press. Представители NASA и Стенфордского университета в пятницу рассказали о том, что проект спутника Gravity Probe B разрабатывается с 1959 года. С тех пор было проведено несколько неудачных попыток старта и решено множество технических проблем. Наконец, 17 апреля спутник будет запущен с базы ВВС США Вандерберг. Аппарат создан с тем, чтобы проверить высказанные в теории относительности Альберта Эйнштейна предположения относительно пространственно-временных закономерностей любых физических процессов. Эксперимент касается заявления ученого о том, что пространство и время искривляются в присутствии Земли, а вращение Земли \"увлекает за собой\" пространство и время. В основе аппарата - четыре кварцевых сферы размером с мяч для пинг-понга. Шары находятся в гироскопах и максимально изолированы от воздействия внешней среды. В космосе, на полярной орбите они будут раскручены. Ось вращения шаров сориентируют на один космический объект. В случае если теория Эйнштейна верна, ось вращения гироскопов должна измениться на ничтожную, но измеряемую величину.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgWZA4GJELuQ"
      },
      "source": [
        "# Universal Sentence Encoder (rus)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZrXqugwEyNH",
        "outputId": "bd739e47-ee55-4768-d858-807506a137df"
      },
      "source": [
        "!pip install tensorflow_text\r\n",
        "import tensorflow_text"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.4.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.12)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.12.4)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.36.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.27.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (54.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.4.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUWZDgB8-HKT"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "hub_layer_rus = hub.KerasLayer(\r\n",
        "    'https://tfhub.dev/google/universal-sentence-encoder-multilingual/3',\r\n",
        "    input_shape=[], \r\n",
        "    dtype=tf.string,\r\n",
        "    trainable=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AEEmfKwEZxO",
        "outputId": "22acab90-1e74-4de5-916e-0e45f8f49d40"
      },
      "source": [
        "hub_layer_rus(\"Я тебя люблю!\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
              "array([[ 0.0296976 ,  0.00904592,  0.01671933, -0.00797092, -0.11031102,\n",
              "         0.03078268, -0.00831644, -0.00055633, -0.01202351,  0.02838768,\n",
              "         0.00666981, -0.01986899,  0.04776657,  0.10307449, -0.02278832,\n",
              "        -0.01142634, -0.00914613, -0.01268484,  0.05287232, -0.01782409,\n",
              "        -0.02868603, -0.01913683, -0.01367332, -0.04538286, -0.04944963,\n",
              "         0.00056962,  0.04408803, -0.00771147, -0.0060773 , -0.02827202,\n",
              "        -0.06743123, -0.01004823,  0.04389869, -0.03071374,  0.04569931,\n",
              "        -0.01681056,  0.02394738, -0.00253611,  0.08103531, -0.07045291,\n",
              "         0.02012455,  0.00962694, -0.0532879 , -0.0130172 ,  0.03059912,\n",
              "        -0.01949406,  0.02198114, -0.06312382,  0.04018677, -0.03843167,\n",
              "         0.04623028, -0.01742821, -0.04040927, -0.06189498, -0.01191114,\n",
              "        -0.09732323,  0.00166289, -0.00224782,  0.01678378, -0.02326612,\n",
              "         0.06176266,  0.02141315,  0.06820528,  0.03506508,  0.03825854,\n",
              "        -0.02615167,  0.00410415,  0.00173093,  0.05269623,  0.01195787,\n",
              "         0.05594153, -0.0071919 , -0.08047094, -0.10609572,  0.02197961,\n",
              "        -0.00627256,  0.05881496,  0.02153405,  0.02088602,  0.08456448,\n",
              "        -0.10009327,  0.07223724, -0.02480186,  0.03834926, -0.04125544,\n",
              "         0.07667001,  0.05204619,  0.0190475 , -0.05330645,  0.00078579,\n",
              "        -0.02364882,  0.08314337, -0.00026826, -0.05904676, -0.07322992,\n",
              "        -0.03597647, -0.04926321,  0.00498289,  0.02547207, -0.04243339,\n",
              "        -0.04423346,  0.00296716,  0.02431623, -0.0428751 , -0.04622524,\n",
              "        -0.02120653,  0.03023272,  0.00076371,  0.07380014,  0.0072068 ,\n",
              "         0.01836233, -0.06444421,  0.01990315,  0.03757875, -0.02013818,\n",
              "        -0.04393629, -0.06394602, -0.00279747,  0.01388231, -0.04346691,\n",
              "         0.05258523,  0.01438157, -0.02626527, -0.00248908,  0.02191917,\n",
              "        -0.07091906, -0.06064992,  0.07511137,  0.02186946, -0.07993848,\n",
              "         0.02715921,  0.00223191, -0.00290429,  0.02795409, -0.05663726,\n",
              "         0.02563802,  0.00257064,  0.02420928, -0.00031108,  0.01462747,\n",
              "        -0.01632149, -0.03203526,  0.00060876,  0.02578528, -0.11395486,\n",
              "        -0.020681  , -0.02793168, -0.07378571, -0.00564646,  0.02623592,\n",
              "        -0.03654025,  0.03007003,  0.05323462, -0.06913411, -0.08794774,\n",
              "        -0.02394121, -0.0083484 , -0.02589515,  0.03302255,  0.00646209,\n",
              "        -0.05689267,  0.05380145, -0.00126282,  0.01948274,  0.03543841,\n",
              "        -0.03914414, -0.03938154,  0.03333554, -0.07984223, -0.02851977,\n",
              "        -0.01797511, -0.07699051, -0.05006867, -0.01981359,  0.05688744,\n",
              "        -0.08987809,  0.10973164, -0.01388615, -0.0242007 ,  0.09954806,\n",
              "        -0.00356168,  0.06114048, -0.02441122,  0.01371908,  0.01028444,\n",
              "         0.02870042, -0.02736905,  0.03783654, -0.04453145,  0.02916975,\n",
              "         0.05496662, -0.00793182, -0.06680369,  0.01631845,  0.03503084,\n",
              "         0.0160717 ,  0.046383  , -0.00893741,  0.04425567, -0.01896672,\n",
              "         0.06443575,  0.00482974, -0.02125456,  0.00366348, -0.0308854 ,\n",
              "        -0.00989354,  0.00599706,  0.02819349, -0.02194535,  0.03012825,\n",
              "         0.03978792, -0.01969417,  0.1081981 ,  0.04861023, -0.02271739,\n",
              "        -0.0476271 ,  0.03270293,  0.03776173,  0.04525691, -0.01527302,\n",
              "         0.00804041,  0.03021456,  0.04639079, -0.04596722,  0.0771087 ,\n",
              "         0.0572624 ,  0.03185127,  0.02182488, -0.00115262, -0.03133803,\n",
              "        -0.03390939, -0.00673394,  0.0648578 ,  0.06191633, -0.00870876,\n",
              "         0.08385544,  0.02942782, -0.07203746, -0.01970132, -0.04671666,\n",
              "        -0.02485887,  0.0512363 , -0.00191123, -0.00366923,  0.06587958,\n",
              "        -0.04297253,  0.02818291,  0.0414565 , -0.02225511, -0.02918622,\n",
              "         0.11358304, -0.0031612 , -0.00630288, -0.03762977, -0.04169378,\n",
              "         0.00749177,  0.03601908, -0.05507157, -0.0407736 , -0.05349635,\n",
              "         0.0779004 ,  0.02822439, -0.02128463,  0.05558729, -0.08029689,\n",
              "        -0.01315789,  0.03977554,  0.03337053, -0.03787275,  0.02782675,\n",
              "        -0.04577861, -0.05411924, -0.09886249,  0.00501721, -0.02914698,\n",
              "        -0.04556013, -0.03080693,  0.00771946, -0.04478354,  0.04059101,\n",
              "         0.02396096, -0.02572561, -0.10201269, -0.00766362,  0.0687063 ,\n",
              "        -0.04429819, -0.04189603, -0.01513417, -0.02745933, -0.02372067,\n",
              "        -0.03087256,  0.00174245,  0.05345593,  0.02481607,  0.05960389,\n",
              "        -0.06293614, -0.00132306, -0.04672857, -0.00494925, -0.01869242,\n",
              "         0.01305625,  0.04885176, -0.02785355, -0.04111308, -0.03457179,\n",
              "        -0.0487974 , -0.03630999,  0.01144186, -0.05464995,  0.0217955 ,\n",
              "         0.05531284,  0.05744013, -0.00093407,  0.02129245,  0.08575956,\n",
              "        -0.01286744, -0.07078147, -0.04389195, -0.02121137, -0.04538991,\n",
              "         0.02479826,  0.03351599, -0.01348007,  0.04591977, -0.0841355 ,\n",
              "         0.02360339,  0.01760244,  0.00926424,  0.03315328,  0.04193871,\n",
              "         0.10553616,  0.0627165 , -0.00821646, -0.00957375,  0.0412737 ,\n",
              "        -0.02158693,  0.00386785,  0.0033867 , -0.08998486, -0.03028565,\n",
              "        -0.03039145,  0.03209411, -0.06773839,  0.03982953,  0.02444769,\n",
              "         0.01872732, -0.0766099 ,  0.0041992 ,  0.02901969,  0.00268659,\n",
              "        -0.06076373,  0.03672862,  0.02017713, -0.07331075,  0.02050021,\n",
              "        -0.0239756 ,  0.02853268, -0.0605323 , -0.04909059, -0.07886687,\n",
              "        -0.00139635,  0.0053889 ,  0.04846346, -0.02018868,  0.01882984,\n",
              "        -0.0076654 , -0.01805858, -0.1067856 , -0.01237418,  0.00379045,\n",
              "         0.00524956, -0.00598436,  0.02807037, -0.03562478, -0.00073642,\n",
              "         0.03884581, -0.01742221,  0.03620548, -0.04012684,  0.0367612 ,\n",
              "        -0.03457699, -0.07329247,  0.05748907, -0.02741573,  0.02935853,\n",
              "        -0.02213507, -0.01688447, -0.06898489, -0.02156063,  0.01281625,\n",
              "        -0.00604955, -0.01865509, -0.04648548, -0.05880878, -0.04752836,\n",
              "         0.00329816, -0.02158504,  0.01705591,  0.01897203,  0.05572562,\n",
              "        -0.03433144, -0.0239147 ,  0.04044938, -0.03119496, -0.03837754,\n",
              "         0.03262679,  0.03606638, -0.00024097,  0.03426967, -0.0551492 ,\n",
              "         0.0960712 ,  0.02152462, -0.04577131,  0.00700787, -0.05855964,\n",
              "        -0.11204283, -0.04183901,  0.05368679, -0.00544727,  0.02938373,\n",
              "        -0.06170741,  0.00894619,  0.01643819, -0.02474865,  0.06638701,\n",
              "        -0.01272475, -0.03295754,  0.05677252, -0.09835993,  0.04435584,\n",
              "         0.03685721,  0.03043398, -0.05841159, -0.05533605,  0.00345428,\n",
              "         0.01018225, -0.03705378, -0.01228917, -0.04968689,  0.02316751,\n",
              "        -0.01299846,  0.0705364 ,  0.00863126, -0.02758464, -0.0304071 ,\n",
              "         0.06291815,  0.05021307,  0.10289165, -0.04343272, -0.05413757,\n",
              "        -0.0464763 ,  0.04459314, -0.00442438, -0.01805016, -0.00469209,\n",
              "         0.05457275, -0.08634175, -0.01257456,  0.0810682 ,  0.04055335,\n",
              "        -0.07220228, -0.06887411, -0.05020295, -0.02741363, -0.02283119,\n",
              "         0.0061992 ,  0.03584855,  0.03452443, -0.04271394, -0.11016699,\n",
              "        -0.01093313,  0.10208241,  0.00249242,  0.00932462, -0.05533149,\n",
              "        -0.03456326,  0.01841107, -0.00712489,  0.00632545, -0.01064837,\n",
              "         0.01316036,  0.09896763, -0.0324428 ,  0.00215724,  0.04427949,\n",
              "        -0.02934119,  0.01094712, -0.02813944,  0.03776289, -0.01634516,\n",
              "         0.0132255 , -0.04707612, -0.06336528,  0.04875814, -0.01828978,\n",
              "         0.01176286,  0.03753439,  0.03270826,  0.05169191,  0.07497069,\n",
              "        -0.03074019,  0.01971969, -0.01230523, -0.04477558, -0.02651563,\n",
              "         0.07852448, -0.0347067 ,  0.06077964, -0.07320585,  0.07739366,\n",
              "         0.00798872, -0.07027141]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ceI9ecrFqrn"
      },
      "source": [
        "c = 0.1  # отношение количества аномальных экземпляров к нормальным\r\n",
        "\r\n",
        "normal_data = topic1\r\n",
        "anomal_data = topic2[:int(c * len(normal_data)) + 1]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSIyL1qyHLLD",
        "outputId": "b0ecc6a1-7167-4fbb-948e-5a44ff086eb6"
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn.utils import shuffle\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "all_data = normal_data + anomal_data\r\n",
        "x = pd.Series(all_data)\r\n",
        "y = np.array([False] * len(normal_data) + [True] * len(anomal_data))\r\n",
        "\r\n",
        "all_data, x, y = shuffle(all_data, x, y, random_state=123)\r\n",
        "print(\"Всего экземпляров = {}\".format(len(all_data)))\r\n",
        "# print(\"(Кол-во текстов, число признаков текста) = {}\".format(x.shape))\r\n",
        "print(\"Кол-во меток = {}\".format(len(y)))\r\n",
        "print(\"Кол-во нормальных экземпляров = {}\".format(len(normal_data)))\r\n",
        "print(\"Кол-во аномальных экземпляров = {}\".format(len(anomal_data)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Всего экземпляров = 1101\n",
            "Кол-во меток = 1101\n",
            "Кол-во нормальных экземпляров = 1000\n",
            "Кол-во аномальных экземпляров = 101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E9-SgYVIkwy"
      },
      "source": [
        "## Функция Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAvrzkc9HOeH"
      },
      "source": [
        "def cosine_similarity(x_predict, x):\r\n",
        "    if type(x_predict) is np.ndarray:\r\n",
        "        flat_output = x_predict\r\n",
        "        flat_input = x_predict\r\n",
        "        # flat_output = np.reshape(x_predict, (np.shape(x)[0], -1))\r\n",
        "        # flat_input = np.reshape(x_predict, (np.shape(x)[0], -1))\r\n",
        "        sum = np.sum(flat_output * flat_input, -1)\r\n",
        "        norm1 = np.linalg.norm(flat_output, axis=-1) + 0.000001\r\n",
        "        norm2 = np.linalg.norm(flat_input, axis=-1) + 0.000001 \r\n",
        "        return -(sum / norm1 / norm2)\r\n",
        "    else:\r\n",
        "        # ДЛЯ НЕ ПОЛНОСВЯЗНЫХ СЛОЕВ НУЖЕН ДРУГОЙ shape\r\n",
        "        flat_output = x_predict\r\n",
        "        flat_input = x_predict\r\n",
        "        # flat_output = tf.reshape(tensor=x_predict, shape=[x.shape.as_list()[0], -1])\r\n",
        "        # flat_input = tf.reshape(tensor=x_predict, shape=[x.shape.as_list()[0], -1])\r\n",
        "        sum = tf.math.reduce_sum(tf.math.multiply(flat_output, flat_input), axis=-1)\r\n",
        "        norm1 = tf.norm(flat_output, axis=-1) + 0.000001\r\n",
        "        norm2 = tf.norm(flat_input, axis=-1) + 0.000001\r\n",
        "        return -(tf.math.divide(tf.math.divide(sum, norm1), norm2))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZJE4GBII06Y"
      },
      "source": [
        "## RSRAE model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uuWVWVdIxPN",
        "outputId": "adeb838e-5378-411a-9b5d-9851002808ad"
      },
      "source": [
        "import math\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "print(\"Tensorflow version = {}\".format(tf.__version__)) # текущая версия tf\r\n",
        "\r\n",
        "from tensorflow.keras import Model, optimizers, metrics\r\n",
        "from tensorflow.keras.layers import Layer, Flatten, Dense, BatchNormalization, Dropout\r\n",
        "\r\n",
        "# from tensorflow.keras import activations, Sequential, Input\r\n",
        "# from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Reshape\r\n",
        "# from sklearn.metrics import roc_auc_score, average_precision_score\r\n",
        "\r\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\r\n",
        "\r\n",
        "# Задаем random_seed для tensorflow и numpy\r\n",
        "random_seed = 123\r\n",
        "tf.random.set_seed(random_seed)\r\n",
        "np.random.seed(random_seed)\r\n",
        "\r\n",
        "# Sets the default float type\r\n",
        "tf.keras.backend.set_floatx('float64')\r\n",
        "\r\n",
        "# Set random seed\r\n",
        "tf.random.set_seed(123)\r\n",
        "np.random.seed(123)\r\n",
        "\r\n",
        "\r\n",
        "class RSR(Layer):\r\n",
        "    \"\"\"\r\n",
        "    Robust Subspace Recovery (RSR) layer.\r\n",
        "    Робастный слой, восстанавливающий подпространство. Задача данного слоя - отобразить\r\n",
        "    закодированные энкодером данные в подпростраство так, чтобы после их обратного\r\n",
        "    отображения декодером дивергенция между экземпляром исходных данных и его образом,\r\n",
        "    полученным от автоэнкодера была незначительной для нормального экземпляра и была\r\n",
        "    большой для аномального экземпляра. \r\n",
        "\r\n",
        "    # Example\r\n",
        "    ```\r\n",
        "        z_rsr, A = RSR(intrinsic_size=10)(z)\r\n",
        "    ```\r\n",
        "    # Arguments\r\n",
        "        intrinsic_size: размерность z_rsr.\r\n",
        "    # Input shape\r\n",
        "        2D tensor with shape: `(n_samples, n_features)` after encoding.\r\n",
        "    # Output shape\r\n",
        "        2D tensor with shape: `(n_samples, intrinsic_size)`.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, intrinsic_size: int, name=\"RSR_layer\", **kwargs):\r\n",
        "        super(RSR, self).__init__(name=name, **kwargs)\r\n",
        "        # Если присваивать экземпляр слоя, как атрибут другого слоя, то хорошей\r\n",
        "        # практикой делать создавать такие подслои в __init__ (поскольку подслои обычно\r\n",
        "        # имеют метод build, они будут собраны, когда будет собран внешний слой). \r\n",
        "        self.flatten = Flatten()\r\n",
        "        self.intrinsic_size = intrinsic_size\r\n",
        "        \r\n",
        "    def build(self, input_shape):\r\n",
        "        \"\"\"Определяет веса слоя, а именно задает матрицу A.\"\"\"\r\n",
        "        self.A = self.add_weight(name=\"A\",\r\n",
        "                                 shape=[int(input_shape[-1]), self.intrinsic_size],\r\n",
        "                                 initializer='random_normal',\r\n",
        "                                 trainable=True,)\r\n",
        "        \r\n",
        "        # self.V = self.add_weight(name=\"V\",\r\n",
        "        #                          shape=[int(input_shape[-1]), 1],\r\n",
        "        #                          initializer='random_normal',\r\n",
        "        #                          trainable=True,)\r\n",
        "        \r\n",
        "    def call(self, z):\r\n",
        "        \"\"\"\r\n",
        "        Логика слоя. Умножение выхода энкодера - вектора z на матрицу A.\r\n",
        "        Возвращает отображенный z_rsr и матрицу A, которая потребуется далее.\r\n",
        "        \"\"\"\r\n",
        "        z = self.flatten(z)\r\n",
        "        # print(\"z.shpae Before A:\", z.shape)\r\n",
        "        z_rsr = tf.linalg.matmul(z, self.A)\r\n",
        "        # print(\"z_rsr.shpae After A:\", z_rsr.shape) \r\n",
        "        return z_rsr\r\n",
        "\r\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \r\n",
        "    # get_config и метода класса (@classmethod) from_config.\r\n",
        "    def get_config(self):\r\n",
        "        config = super(Layer, self).get_config()\r\n",
        "        config.update({'intrinsic_size': self.intrinsic_size})\r\n",
        "        return config\r\n",
        "\r\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \r\n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "        return cls(**config)\r\n",
        "\r\n",
        "\r\n",
        "class L2Normalization(Layer):\r\n",
        "    \"\"\"Слой для l_2 нормализации, который будет применяться к выходу RSR layer.\"\"\"\r\n",
        "    \r\n",
        "    def __init__(self, name=\"L2Normalization\", **kwargs):\r\n",
        "        super(L2Normalization, self).__init__(name=name, **kwargs)\r\n",
        "\r\n",
        "    def call(self, z_rsr):\r\n",
        "        \"\"\"\r\n",
        "        Выполняет l_2 нормализацию векторов, полученных после применения RSR layer\r\n",
        "        вдоль оси, соответсвующей числу признаков. То есть производится нормализация\r\n",
        "        каждого экземпляра выборки, в результате которой признаки экземпляров будут\r\n",
        "        находиться в отрезке [-1; 1].\r\n",
        "        \"\"\"\r\n",
        "        z_tilde = tf.math.l2_normalize(z_rsr, axis=-1)\r\n",
        "        return z_tilde\r\n",
        "\r\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \r\n",
        "    # get_config и метода класса (@classmethod) from_config.\r\n",
        "    def get_config(self):\r\n",
        "        config = super(Layer, self).get_config()\r\n",
        "        return config\r\n",
        "\r\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \r\n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "        return cls(**config)\r\n",
        "\r\n",
        "\r\n",
        "class Encoder(Layer):\r\n",
        "    \"\"\"\r\n",
        "    Класс для encoder модели RSRAE. Отображает исходные данные input_data в вектор z,\r\n",
        "    кодирующий исходные данные.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self,\r\n",
        "                 hidden_layer_dimensions,\r\n",
        "                 activation,\r\n",
        "                 flag_bn=True, \r\n",
        "                 name=\"Encoder\",\r\n",
        "                 **kwargs):\r\n",
        "        super(Encoder, self).__init__(name=name, **kwargs)\r\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\r\n",
        "        self.activation = activation\r\n",
        "        self.flag_bn = flag_bn\r\n",
        "        self.dense0 = Dense(hidden_layer_dimensions[0], activation=activation,\r\n",
        "                            name='encoder_0')\r\n",
        "        self.dense1 = Dense(hidden_layer_dimensions[1], activation=activation,\r\n",
        "                            name='encoder_1')\r\n",
        "        self.dense2 = Dense(hidden_layer_dimensions[2], activation=activation,\r\n",
        "                            name='encoder_2')\r\n",
        "        if flag_bn:\r\n",
        "            self.batch_normalization0 = BatchNormalization(name=\"encoder_bn_layer_0\")\r\n",
        "            self.batch_normalization1 = BatchNormalization(name=\"encoder_bn_layer_1\")\r\n",
        "            self.batch_normalization2 = BatchNormalization(name=\"encoder_bn_layer_2\")\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        \"\"\"Отображние исходных данных x -> в закодированный вектор z.\"\"\"\r\n",
        "        x = inputs\r\n",
        "        x = self.dense0(x)\r\n",
        "        if self.flag_bn:\r\n",
        "            x = self.batch_normalization0(x)\r\n",
        "        x = self.dense1(x)\r\n",
        "        if self.flag_bn:\r\n",
        "            x = self.batch_normalization1(x)\r\n",
        "        x = Dropout(0.2)((x))\r\n",
        "        x = self.dense2(x)\r\n",
        "        if self.flag_bn:\r\n",
        "            x = self.batch_normalization2(x)\r\n",
        "        x = Dropout(0.2)((x))    \r\n",
        "        z = x\r\n",
        "        return z\r\n",
        "    \r\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \r\n",
        "    # get_config и метода класса (@classmethod) from_config.\r\n",
        "    def get_config(self):\r\n",
        "        config = super(Layer, self).get_config()\r\n",
        "        config.update({'hidden_layer_dimensions': self.hidden_layer_dimensions})\r\n",
        "        config.update({'activation': self.activation})\r\n",
        "        config.update({'flag_bn': self.flag_bn})\r\n",
        "        return config\r\n",
        "\r\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \r\n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "        return cls(**config)\r\n",
        "\r\n",
        "\r\n",
        "class Decoder(Layer):\r\n",
        "    \"\"\"\r\n",
        "    Класс для decoder модели RSRAE. Отображает вектор z_rsr, полученный в результате\r\n",
        "    кодирования исходных данных в вектор z, и последующим отображением вектора z при\r\n",
        "    помощи RSR layer (x -> z -> z_rsr), обратно в пространство исходных данных \r\n",
        "    (z_rsr -> x_tilde).\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self,\r\n",
        "                 inputs_dim,\r\n",
        "                 hidden_layer_dimensions,\r\n",
        "                 activation,\r\n",
        "                 flag_bn=True, \r\n",
        "                 name=\"Decoder\",\r\n",
        "                 **kwargs):\r\n",
        "        super(Decoder, self).__init__(name=name, **kwargs)\r\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\r\n",
        "        self.activation = activation\r\n",
        "        self.flag_bn = flag_bn\r\n",
        "        self.dense2 = Dense(hidden_layer_dimensions[2], activation=activation,\r\n",
        "                            name='decoder_2')\r\n",
        "        self.dense1 = Dense(hidden_layer_dimensions[1], activation=activation,\r\n",
        "                            name='decoder_1')\r\n",
        "        self.dense0 = Dense(hidden_layer_dimensions[0], activation=activation,\r\n",
        "                            name='decoder_0')\r\n",
        "        self.dense_output = Dense(inputs_dim, activation=activation,\r\n",
        "                            name='decoder_output')\r\n",
        "        if flag_bn:\r\n",
        "            self.batch_normalization2 = BatchNormalization(name=\"decoder_bn_layer_2\")\r\n",
        "            self.batch_normalization1 = BatchNormalization(name=\"decoder_bn_layer_1\")\r\n",
        "            self.batch_normalization0 = BatchNormalization(name=\"decoder_bn_layer_0\")\r\n",
        "    def call(self, inputs):\r\n",
        "        \"\"\"\r\n",
        "        Отображние z_rsr -> x_tilde, где x_tilde - вектор, лежащий в пространстве\r\n",
        "        исходных даных.\r\n",
        "        \"\"\"\r\n",
        "        z_rsr = inputs\r\n",
        "        z_rsr = self.dense2(z_rsr)\r\n",
        "        if self.flag_bn:\r\n",
        "            z_rsr = self.batch_normalization2(z_rsr)\r\n",
        "        z_rsr = Dropout(0.3)((z_rsr))\r\n",
        "        z_rsr = self.dense1(z_rsr)\r\n",
        "        if self.flag_bn:\r\n",
        "            z_rsr = self.batch_normalization1(z_rsr)\r\n",
        "        z_rsr = Dropout(0.4)((z_rsr))\r\n",
        "        z_rsr = self.dense0(z_rsr)\r\n",
        "        if self.flag_bn:\r\n",
        "            z_rsr = self.batch_normalization0(z_rsr)\r\n",
        "        z_rsr = Dropout(0.4)((z_rsr))\r\n",
        "        x_tilde = self.dense_output(z_rsr)\r\n",
        "        return x_tilde\r\n",
        "    \r\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \r\n",
        "    # get_config и метода класса (@classmethod) from_config.\r\n",
        "    def get_config(self):\r\n",
        "        config = super(Layer, self).get_config()\r\n",
        "        config.update({'hidden_layer_dimensions': self.hidden_layer_dimensions})\r\n",
        "        config.update({'activation': self.activation})\r\n",
        "        config.update({'flag_bn': self.flag_bn})\r\n",
        "        return config\r\n",
        "\r\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \r\n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "        return cls(**config)\r\n",
        "\r\n",
        "\r\n",
        "class RSRAE(Model):\r\n",
        "    \"\"\"\r\n",
        "    Нейросетевая модель-автоэнкодер для обнаружения аномалий с робастным слоем,\r\n",
        "    восстанавливающим подпространство (RSR layer между encoder и decoder).\r\n",
        "    Комбинируем encoder + RSR layer + decoder в end-to-end модель.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self,\r\n",
        "                 inputs_dim, # размерность вектора признаков\r\n",
        "                 hidden_layer_dimensions,\r\n",
        "                 intrinsic_size, # разерность z_rsr после RSR layer\r\n",
        "                 activation,\r\n",
        "                 hub_layer,\r\n",
        "                 flag_bn=True,\r\n",
        "                 flag_normalize=True,\r\n",
        "                 learning_rate=1e-3,\r\n",
        "                 beta=1,\r\n",
        "                 eta=1,\r\n",
        "                 t_step=0,\r\n",
        "                 ae_loss_norm_type='MSE',\r\n",
        "                 rsr_loss_norm_type='MSE',\r\n",
        "                 name='RSRAE',\r\n",
        "                 **kwargs):\r\n",
        "        super(RSRAE, self).__init__(name=name, **kwargs)\r\n",
        "        self.inputs_dim = inputs_dim\r\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\r\n",
        "        self.intrinsic_size = intrinsic_size\r\n",
        "        self.activation = activation\r\n",
        "        self.flag_bn = flag_bn\r\n",
        "        self.flag_normalize = flag_normalize\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "        self.beta = tf.Variable(beta, dtype=tf.float64, trainable=False)\r\n",
        "        self.beta0 = tf.Variable(beta, dtype=tf.float64, trainable=False)\r\n",
        "        self.eta = tf.Variable(eta, dtype=tf.float64, trainable=False)\r\n",
        "        self.eta0 = tf.Variable(eta, dtype=tf.float64, trainable=False)\r\n",
        "        self.t_step = tf.Variable(t_step, dtype=tf.float64, trainable=False)\r\n",
        "        self.ae_loss_norm_type = ae_loss_norm_type\r\n",
        "        self.rsr_loss_norm_type = rsr_loss_norm_type\r\n",
        "        # Для вычисления среднего loss по loss всех батчей в эпохе\r\n",
        "        self.loss_tracker = metrics.Mean(name=\"loss\")\r\n",
        "        self.auc_tracker = metrics.Mean(name=\"auc\")\r\n",
        "        self.ap_tracker = metrics.Mean(name=\"ap\")\r\n",
        "\r\n",
        "        # Создание экземпляров оптимизаторов\r\n",
        "        self.optimizer_ae = optimizers.Adam(learning_rate=learning_rate)\r\n",
        "        self.optimizer_rsr1 = optimizers.Adam(learning_rate=5 * learning_rate)\r\n",
        "        self.optimizer_rsr2 = optimizers.Adam(learning_rate=5 * learning_rate)\r\n",
        "\r\n",
        "        # Слои\r\n",
        "        self.emnedding_layer = hub_layer\r\n",
        "        self.encoder = Encoder(hidden_layer_dimensions=hidden_layer_dimensions,\r\n",
        "                               activation=activation,\r\n",
        "                               flag_bn=flag_bn)\r\n",
        "        self.rsr = RSR(intrinsic_size=intrinsic_size)\r\n",
        "        if flag_normalize:\r\n",
        "            self.l2normalization = L2Normalization()\r\n",
        "        self.decoder = Decoder(inputs_dim=inputs_dim,\r\n",
        "                               hidden_layer_dimensions=hidden_layer_dimensions,\r\n",
        "                               activation=activation,\r\n",
        "                               flag_bn=flag_bn)\r\n",
        "        \r\n",
        "    def call(self, inputs):\r\n",
        "        e = self.emnedding_layer(inputs)\r\n",
        "        e = tf.cast(e, dtype=tf.float64)\r\n",
        "        z = self.encoder(e)\r\n",
        "        z_rsr = self.rsr(z)\r\n",
        "        if self.flag_normalize:\r\n",
        "            z_rsr = self.l2normalization(z_rsr)\r\n",
        "        x_tilde = self.decoder(z_rsr)\r\n",
        "        return e, z, z_rsr, x_tilde\r\n",
        "\r\n",
        "    def ae_loss(self, x, x_tilde):\r\n",
        "        \"\"\"Функция потерь реконструкции автоэнкодера - L_AE.\"\"\"\r\n",
        "\r\n",
        "        x = tf.reshape(x, (tf.shape(x)[0], -1))\r\n",
        "        x_tilde = tf.reshape(x_tilde, (tf.shape(x_tilde)[0], -1))\r\n",
        "\r\n",
        "        # axis=1 для tf.norm => вычисление вдоль оси признаков\r\n",
        "        # tf.math.reduce_mean без параметров - mean от элементов матрицы\r\n",
        "        if self.ae_loss_norm_type in ['MSE', 'mse', 'Frob', 'F']:\r\n",
        "            return tf.math.reduce_mean(tf.math.square(tf.norm(x-x_tilde, \r\n",
        "                                                              ord=2, axis=1)))\r\n",
        "        elif self.ae_loss_norm_type in ['L1', 'l1']:\r\n",
        "            return tf.math.reduce_mean(tf.norm(x-x_tilde, ord=1, axis=1))\r\n",
        "        elif self.ae_loss_norm_type in ['LAD', 'lad', 'L21', 'l21', 'L2', 'l2']:\r\n",
        "            return tf.math.reduce_mean(tf.norm(x-x_tilde, ord=2, axis=1))\r\n",
        "        else:\r\n",
        "            raise Exception(\"Norm type error!\")\r\n",
        "    \r\n",
        "    def rsr1_loss(self, z, z_rsr, beta, eta):\r\n",
        "        \"\"\"Функция потери для RSR layer - L_RSR1.\"\"\"\r\n",
        "        z_rsr = tf.matmul(z_rsr, tf.transpose(self.rsr.A))\r\n",
        "        # z_rsr_new = tf.matmul(z_rsr, self.)\r\n",
        "\r\n",
        "        if self.rsr_loss_norm_type in ['MSE', 'mse', 'Frob', 'F']:\r\n",
        "            return tf.math.reduce_mean(tf.math.square(tf.norm(z-z_rsr, ord=2, \r\n",
        "                                                            axis=1)))\r\n",
        "        elif self.rsr_loss_norm_type in ['L1', 'l1']:\r\n",
        "            return tf.math.reduce_mean(tf.norm(z-z_rsr, ord=1, axis=1))\r\n",
        "        elif self.rsr_loss_norm_type in ['LAD', 'lad', 'L21', 'l21', 'L2', 'l2']:\r\n",
        "            return tf.math.reduce_mean(tf.norm(z-z_rsr, ord=2, axis=1))\r\n",
        "        else:\r\n",
        "            raise Exception(\"Norm type error!\")\r\n",
        "    \r\n",
        "    def rsr2_loss(self):\r\n",
        "        \"\"\"Функция потери для RSR layer - L_RSR2.\"\"\"\r\n",
        "        A = self.rsr.A\r\n",
        "        A_T = tf.transpose(A)\r\n",
        "        I = tf.eye(self.intrinsic_size, dtype=tf.float64)\r\n",
        "        return tf.math.reduce_mean(tf.math.square(tf.linalg.matmul(A_T, A) - I))\r\n",
        "\r\n",
        "    def rsr3_loss(self, z, z_rsr, beta, eta):\r\n",
        "        \"\"\"\r\n",
        "        Cтатьи 'Robust principal component analysis by \r\n",
        "        self-organizing rules basedon statistical physics approach', на которую\r\n",
        "        ссылается http://files.is.tue.mpg.de/black/papers/delatorreIJCV03.pdf\r\n",
        "        \"\"\"\r\n",
        "        z_rsr = tf.matmul(z_rsr, tf.transpose(self.rsr.A))  # AA'z\r\n",
        "        e_pca = tf.math.square(tf.norm(z-z_rsr, ord=2, axis=1))\r\n",
        "        self.min_div = tf.reduce_min(e_pca)\r\n",
        "        self.max_div = tf.reduce_max(e_pca)\r\n",
        "        self.mean_div = tf.reduce_mean(e_pca)\r\n",
        "        print(beta)\r\n",
        "        loss = -1 * tf.math.reduce_mean(tf.math.log(1 + tf.math.exp(-beta * e_pca - eta))) / beta\r\n",
        "        return loss\r\n",
        "        \r\n",
        "    def gradients(model, inputs, targets):\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            loss_value = loss_fn(model, inputs, targets)\r\n",
        "        return tape.gradient(loss_value, model.trainable_variables)\r\n",
        "    \r\n",
        "    @tf.function()\r\n",
        "    def train_step(self, data):\r\n",
        "        \"\"\"\r\n",
        "        Override the method. Будет вызываться при 'model.fit()'.\r\n",
        "        Один шаг обучения, на котором вычисляются функции потерь для автоэнкодера и\r\n",
        "        RSR layer, и в соотвествии с ними обновляются значения обучаемых переменных - \r\n",
        "        весов нейросети и матрицы A соответсвенно. Будет вызываться от одного батча.\r\n",
        "        Заметим, что в этом методе мы используем пользовательские оптимизаторы и функции\r\n",
        "        потерь, поэтому перед тренировкой метод compile вызывать не придется.\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "\r\n",
        "        x, y = data\r\n",
        "\r\n",
        "        # tf.GradientTape() - записывает операции для автоматического дифференцирования\r\n",
        "\r\n",
        "        # По умолчанию persistent=False и удерживаемые GradientTape, высвобождаются,\r\n",
        "        # как только вызывается метод GradientTape.gradient(). Чтобы вычислить несколько\r\n",
        "        # градиентов за одно вычисление, требуется задать persistent=true. Это позволяет\r\n",
        "        # многократно вызывать метод gradient(), тогда требуется самостоятельно\r\n",
        "        # освободить ресурсы с помощью 'del tape'.\r\n",
        "\r\n",
        "        # watch_accessed_variables=True => автоматическое отслеживание всех обучаемых\r\n",
        "        # переменные, к которым осуществляется доступ. Так градиенты могут быть\r\n",
        "        # запрошены c любого вычисленного результата в tape.\r\n",
        "        with tf.GradientTape(persistent=True, watch_accessed_variables=True) as tape:\r\n",
        "            # Здесь требуется запустить прямой проход нейросети. Операции применяемые\r\n",
        "            # при проходе к входных данным будут записаны на GradientTape. \r\n",
        "            e, z, z_rsr, x_tilde = self.call(x) # прямой проход RSRAE\r\n",
        "            z = tf.keras.layers.Flatten()(z) # вроде для текстовых данных необязательно\r\n",
        "            # Вычисляем значения функций потерь для этого прохода\r\n",
        "            loss_ae = self.ae_loss(e, x_tilde)\r\n",
        "            loss_rsr3 = self.rsr3_loss(z, z_rsr, self.beta, self.eta)\r\n",
        "            loss_rsr2 = self.rsr2_loss()\r\n",
        "  \r\n",
        "        # Метод gradient вычисляет градиенты обучаемых параметров(весов) для минимизации\r\n",
        "        # функции потерь, используя операции, записанные в контексте этого tape.\r\n",
        "        gradients_ae = tape.gradient(loss_ae, self.trainable_weights)\r\n",
        "        gradients_rsr3 = tape.gradient(loss_rsr3, self.rsr.A)\r\n",
        "        gradients_rsr2 = tape.gradient(loss_rsr2, self.rsr.A)\r\n",
        "\r\n",
        "        # Обновим значения обучаемых переменных - градиентный шаг чтобы min loss.\r\n",
        "        self.optimizer_ae.apply_gradients(grads_and_vars=\r\n",
        "                                          zip(gradients_ae, self.trainable_weights))\r\n",
        "        self.optimizer_rsr1.apply_gradients(grads_and_vars=\r\n",
        "                                            zip([gradients_rsr3], [self.rsr.A]))\r\n",
        "        self.optimizer_rsr2.apply_gradients(grads_and_vars=\r\n",
        "                                            zip([gradients_rsr2], [self.rsr.A]))\r\n",
        "        \r\n",
        "        self.loss_tracker.update_state(loss_ae) # обновляем средний loss по батчам\r\n",
        "\r\n",
        "        self.t_step.assign_add(1, use_locking=True)\r\n",
        "        self.beta.assign(self.beta0.value() * tf.math.log(self.t_step.value() + 3))\r\n",
        "        self.eta.assign(self.eta0.value() * self.t_step.value())\r\n",
        "\r\n",
        "        # Обновляем метрики\r\n",
        "        if len(tf.unique(y)[0]) == 2:\r\n",
        "            # иначе roc_auc_score бросит ValueError и обучение приостановится\r\n",
        "            auc = self.auc_metric(y, cosine_similarity(x_tilde, e))\r\n",
        "            self.auc_tracker.update_state(auc)\r\n",
        "\r\n",
        "        ap = self.ap_metric(y, cosine_similarity(x_tilde, e))\r\n",
        "        self.ap_tracker.update_state(ap)\r\n",
        "\r\n",
        "        del tape # persistent=True => требуется самостоятельно освободить ресурсы\r\n",
        "        return {\"loss\": self.loss_tracker.result(),\r\n",
        "                \"auc\": self.auc_tracker.result(),\r\n",
        "                \"ap\": self.ap_tracker.result(),\r\n",
        "                # \"mean_div\": self.mean_div,\r\n",
        "                # \"min_div\": self.min_div, \r\n",
        "                # \"max_div\": self.max_div,\r\n",
        "                \"beta\": self.beta,\r\n",
        "                \"eta\": self.eta,\r\n",
        "                \"t_step\": self.t_step}\r\n",
        "\r\n",
        "    @property\r\n",
        "    def metrics(self):\r\n",
        "        \"\"\"\r\n",
        "        В пару к train_step. Сбрасывает метрики (`reset_states()`) в начале каждой\r\n",
        "        эпохи обучения с помощью 'fit()'. Без этого свойства 'result()' будет \r\n",
        "        возвращать среднее значение с начала обучения.\r\n",
        "        \"\"\"\r\n",
        "        return [self.loss_tracker, self.auc_tracker, self.ap_tracker]\r\n",
        "\r\n",
        "    def auc_metric(self, y_true, y_pred):\r\n",
        "        return tf.py_function(roc_auc_score, (y_true, y_pred), tf.float64)\r\n",
        "\r\n",
        "    def ap_metric(self, y_true, y_pred):\r\n",
        "        return tf.py_function(average_precision_score, (y_true, y_pred), tf.float64)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version = 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy6j-5l3I8K5"
      },
      "source": [
        "## Тренировка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGvdXlnxI63Y",
        "outputId": "edd04833-27ff-4d9e-a3e2-c9d2183ab660"
      },
      "source": [
        "# Изначальный слой USE\r\n",
        "layer = hub_layer_rus\r\n",
        "\r\n",
        "config = layer.get_config()\r\n",
        "weights = layer.get_weights()\r\n",
        "cloned_layer = type(layer).from_config(config)\r\n",
        "cloned_layer.set_weights(weights)\r\n",
        "\r\n",
        "hub_layer_now = cloned_layer\r\n",
        "\r\n",
        "\r\n",
        "# Тренировка модели\r\n",
        "model_rsrae = RSRAE(inputs_dim=512,\r\n",
        "                    hidden_layer_dimensions=[512, 1024, 2048],\r\n",
        "                    intrinsic_size=20,\r\n",
        "                    activation='relu',\r\n",
        "                    hub_layer=hub_layer_now,\r\n",
        "                    learning_rate=5e-5,\r\n",
        "                    beta=1.0,\r\n",
        "                    eta=0.0015,\r\n",
        "                    ae_loss_norm_type='MSE',\r\n",
        "                    rsr_loss_norm_type='MSE',)\r\n",
        "model_rsrae.compile(run_eagerly=True)\r\n",
        "model_rsrae.fit(x, y,\r\n",
        "                batch_size=128,\r\n",
        "                epochs=8)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7f7bbb8140e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7f7bbb8140e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_1_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_2_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_3_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_3_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_3_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_4_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_4_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_4_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_5_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_5_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_5_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_6_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_6_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_6_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_7_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_7_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_7_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_8_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_8_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_8_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_9_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_9_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_9_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_10_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_10_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_10_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_11_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_11_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_11_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_12_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_12_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_12_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_13_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_13_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_13_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_14_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_14_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_14_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_15_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_15_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_15_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_16_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_16_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_16_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/DNN/combine_word_embeddings/SegmentSum_grad/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/DNN/combine_word_embeddings/SegmentSum_grad/GatherV2_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/DNN/combine_word_embeddings/SegmentSum_grad/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float64>\n",
            "<tf.Variable 'Variable:0' shape=() dtype=float64>\n",
            "8/9 [=========================>....] - ETA: 0s - loss: 0.9609 - auc: 0.3462 - ap: 0.0854 - beta: 1.9638 - eta: 0.0068 - t_step: 4.5000<tf.Variable 'Variable:0' shape=() dtype=float64>\n",
            "9/9 [==============================] - 41s 1s/step - loss: 0.9492 - auc: 0.3620 - ap: 0.0908 - beta: 2.0680 - eta: 0.0081 - t_step: 5.4000\n",
            "Epoch 2/12\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.7262 - auc: 0.7925 - ap: 0.4687 - beta: 2.8437 - eta: 0.0216 - t_step: 14.4000\n",
            "Epoch 3/12\n",
            "9/9 [==============================] - 2s 221ms/step - loss: 0.5115 - auc: 0.9571 - ap: 0.8024 - beta: 3.2679 - eta: 0.0351 - t_step: 23.4000\n",
            "Epoch 4/12\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.3596 - auc: 0.9627 - ap: 0.8063 - beta: 3.5637 - eta: 0.0486 - t_step: 32.4000\n",
            "Epoch 5/12\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.2628 - auc: 0.9923 - ap: 0.9397 - beta: 3.7913 - eta: 0.0621 - t_step: 41.4000\n",
            "Epoch 6/12\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.1948 - auc: 0.9979 - ap: 0.9747 - beta: 3.9765 - eta: 0.0756 - t_step: 50.4000\n",
            "Epoch 7/12\n",
            "9/9 [==============================] - 2s 222ms/step - loss: 0.1477 - auc: 0.9986 - ap: 0.9878 - beta: 4.1326 - eta: 0.0891 - t_step: 59.4000\n",
            "Epoch 8/12\n",
            "9/9 [==============================] - 2s 222ms/step - loss: 0.1172 - auc: 0.9978 - ap: 0.9732 - beta: 4.2676 - eta: 0.1026 - t_step: 68.4000\n",
            "Epoch 9/12\n",
            "9/9 [==============================] - 2s 221ms/step - loss: 0.0947 - auc: 0.9973 - ap: 0.9746 - beta: 4.3864 - eta: 0.1161 - t_step: 77.4000\n",
            "Epoch 10/12\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.0765 - auc: 0.9924 - ap: 0.9266 - beta: 4.4927 - eta: 0.1296 - t_step: 86.4000\n",
            "Epoch 11/12\n",
            "9/9 [==============================] - 2s 220ms/step - loss: 0.0635 - auc: 0.9916 - ap: 0.9417 - beta: 4.5887 - eta: 0.1431 - t_step: 95.4000\n",
            "Epoch 12/12\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.0530 - auc: 0.9920 - ap: 0.9316 - beta: 4.6762 - eta: 0.1566 - t_step: 104.4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7bbf301c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhmZL0gEJBl-"
      },
      "source": [
        "## Тестирование модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hygws44JDDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe6b5530-82f0-4bf0-f3f3-26fe80d1a704"
      },
      "source": [
        "# model_rsrae.predict(x) - ВЫДАЕТ НЕПОНЯТНЫЕ ОШИБКИ\r\n",
        "e, _, _, x_predict = model_rsrae.call(x)\r\n",
        "\r\n",
        "auc = roc_auc_score(y, cosine_similarity(x_predict, e))\r\n",
        "ap = average_precision_score(y, cosine_similarity(x_predict, e))\r\n",
        "                                    \r\n",
        "print(\"auc = \", auc)\r\n",
        "print(\"ap = \", ap)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auc =  0.9885742574257426\n",
            "ap =  0.9058938694155285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFbplby3JDs6"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}