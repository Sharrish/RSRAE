{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset-Lenta.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmX41fGZrNAG"
      },
      "source": [
        "## Локальное подключение Google Диска"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7V3RL0upWuP",
        "outputId": "69fb1aa8-ed4c-4f1a-cc6e-918c5ace923d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AY0e-g7lSFC7eK46H_Qs1ad54lW759cNk9l1BOJl6KYYqlRIv0UMJcW6TRk\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdyvNYO_toU0",
        "outputId": "63c19b4f-fd9b-4fdb-8906-303cff893a20"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUagVV6z0z8T",
        "outputId": "cfb75469-e416-4ec4-834e-7691a9fcc675"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Mar 18 05:34:21 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYWSIYMK7nXR"
      },
      "source": [
        "## Читаем датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKfPjCcarP_0",
        "outputId": "d0f4fa61-41e6-4b5a-9955-45be0b58734f"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "\r\n",
        "#df = pd.read_csv(\"drive/My Drive/lenta-ru-news.csv\")\r\n",
        "\r\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Datasets/data_from_Sait/lenta-ru-news.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "J1cr96AzrXdX",
        "outputId": "1cc95a61-bfc7-4997-b531-945eec166396"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "      <th>tags</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://lenta.ru/news/1914/09/16/hungarnn/</td>\n",
              "      <td>1914. Русские войска вступили в пределы Венгрии</td>\n",
              "      <td>Бои у Сопоцкина и Друскеник закончились отступ...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://lenta.ru/news/1914/09/16/lermontov/</td>\n",
              "      <td>1914. Празднование столетия М.Ю. Лермонтова от...</td>\n",
              "      <td>Министерство народного просвещения, в виду про...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://lenta.ru/news/1914/09/17/nesteroff/</td>\n",
              "      <td>1914. Das ist Nesteroff!</td>\n",
              "      <td>Штабс-капитан П. Н. Нестеров на днях, увидев в...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://lenta.ru/news/1914/09/17/bulldogn/</td>\n",
              "      <td>1914. Бульдог-гонец под Льежем</td>\n",
              "      <td>Фотограф-корреспондент Daily Mirror рассказыва...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://lenta.ru/news/1914/09/18/zver/</td>\n",
              "      <td>1914. Под Люблином пойман швабский зверь</td>\n",
              "      <td>Лица, приехавшие в Варшаву из Люблина, передаю...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           url  ...        date\n",
              "0   https://lenta.ru/news/1914/09/16/hungarnn/  ...  1914/09/16\n",
              "1  https://lenta.ru/news/1914/09/16/lermontov/  ...  1914/09/16\n",
              "2  https://lenta.ru/news/1914/09/17/nesteroff/  ...  1914/09/17\n",
              "3   https://lenta.ru/news/1914/09/17/bulldogn/  ...  1914/09/17\n",
              "4       https://lenta.ru/news/1914/09/18/zver/  ...  1914/09/18\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYrax3_Y7r7v"
      },
      "source": [
        "## Смотрим на темы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO33Ti5bucLD",
        "outputId": "a32bdd1a-ee07-45be-b872-85fcf3753159"
      },
      "source": [
        "df['topic'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Библиотека', 'Россия', 'Мир', 'Экономика', 'Интернет и СМИ',\n",
              "       'Спорт', 'Культура', 'Из жизни', 'Силовые структуры',\n",
              "       'Наука и техника', 'Бывший СССР', nan, 'Дом', 'Сочи', 'ЧМ-2014',\n",
              "       'Путешествия', 'Ценности', 'Легпром', 'Бизнес', 'МедНовости',\n",
              "       'Оружие', '69-я параллель', 'Культпросвет ', 'Крым'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8O2aBke7ksS"
      },
      "source": [
        "topic1 = df['text'][(df['topic']=='Спорт')].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTb3RRXy9Rm9"
      },
      "source": [
        "topic2 = df['text'][(df['topic']=='Наука и техника')].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onqG1V8R9hme"
      },
      "source": [
        "topic1 = topic1.tolist()[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhZcTLrB9ji-"
      },
      "source": [
        "topic2 = topic2.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMB_6E5OHwnk",
        "outputId": "c401ba90-b34b-4973-9313-515d5540e739"
      },
      "source": [
        "len(topic1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuH1ulRlHyva",
        "outputId": "5b9daa2c-f317-4272-b90b-9c654abcf19d"
      },
      "source": [
        "len(topic2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53136"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u982mJK99aG",
        "outputId": "605fa236-1d8b-46d0-8bca-7fa5c9a0386b"
      },
      "source": [
        "print(max([len(x) for x in topic1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYI6vGoK-E8Z",
        "outputId": "a96c8b4d-e2d0-4e03-8c68-b438bd841f47"
      },
      "source": [
        "print(max([len(x) for x in topic2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "kHelWPjZM0MN",
        "outputId": "5c875ccb-85ce-4dfd-cf5c-1e7bb1fcf693"
      },
      "source": [
        "topic2[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Американские ученые в ближайшее время отправят на орбиту спутник, который проверит два фундаментальных предположения, выдвинутых Альбертом Эйнштейном в рамках общей теории относительности, сообщает Associated Press. Представители NASA и Стенфордского университета в пятницу рассказали о том, что проект спутника Gravity Probe B разрабатывается с 1959 года. С тех пор было проведено несколько неудачных попыток старта и решено множество технических проблем. Наконец, 17 апреля спутник будет запущен с базы ВВС США Вандерберг. Аппарат создан с тем, чтобы проверить высказанные в теории относительности Альберта Эйнштейна предположения относительно пространственно-временных закономерностей любых физических процессов. Эксперимент касается заявления ученого о том, что пространство и время искривляются в присутствии Земли, а вращение Земли \"увлекает за собой\" пространство и время. В основе аппарата - четыре кварцевых сферы размером с мяч для пинг-понга. Шары находятся в гироскопах и максимально изолированы от воздействия внешней среды. В космосе, на полярной орбите они будут раскручены. Ось вращения шаров сориентируют на один космический объект. В случае если теория Эйнштейна верна, ось вращения гироскопов должна измениться на ничтожную, но измеряемую величину.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgWZA4GJELuQ"
      },
      "source": [
        "# Universal Sentence Encoder (rus)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZrXqugwEyNH",
        "outputId": "ffdf2662-95b0-4dfc-eb04-2aba23c35151"
      },
      "source": [
        "!pip install tensorflow_text\r\n",
        "import tensorflow_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_text\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/c0/c0fed4301f592c3b56638ae7292612c17d91a43891ba1aaf9636d535beae/tensorflow_text-2.4.3-cp37-cp37m-manylinux1_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.11.0)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub>=0.8.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-hub>=0.8.0->tensorflow_text) (3.12.4)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.36.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.4.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.10.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.32.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.12)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow-hub>=0.8.0->tensorflow_text) (54.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.4.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.27.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.4.8)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUWZDgB8-HKT"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "hub_layer_rus = hub.KerasLayer(\r\n",
        "    'https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3',\r\n",
        "    input_shape=[], \r\n",
        "    dtype=tf.string,\r\n",
        "    trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AEEmfKwEZxO",
        "outputId": "9ec2e95b-fa94-49c1-922e-b28e30e484f3"
      },
      "source": [
        "hub_layer_rus(\"Я тебя люблю!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
              "array([[ 8.56634751e-02,  3.31225619e-02, -1.16250068e-02,\n",
              "        -1.34115219e-02,  1.97107047e-02, -6.96857199e-02,\n",
              "        -1.49906622e-02, -3.82314622e-02,  9.57699772e-03,\n",
              "         1.72690805e-02,  5.84928878e-02,  6.99707717e-02,\n",
              "         7.98224732e-02,  4.93081938e-03,  3.60946096e-02,\n",
              "         5.15512675e-02,  2.31780335e-02,  2.55165957e-02,\n",
              "         3.12567391e-02,  7.31933191e-02,  7.32296556e-02,\n",
              "         2.04584952e-02,  3.08928210e-02,  1.75313968e-02,\n",
              "        -2.37775352e-02, -2.32466869e-03,  2.48465370e-02,\n",
              "        -6.49326295e-03, -2.59369034e-02, -5.43671399e-02,\n",
              "         1.39377289e-03,  3.27450484e-02,  7.49375895e-02,\n",
              "        -7.53188953e-02, -1.76724140e-02, -9.59488899e-02,\n",
              "        -7.99258426e-02,  8.20515212e-03,  1.38501066e-03,\n",
              "        -2.41921954e-02,  1.39087327e-02, -3.11491713e-02,\n",
              "        -7.27787241e-02,  5.88333346e-02, -2.48262603e-02,\n",
              "        -3.83213609e-02,  2.70233825e-02, -6.73358049e-03,\n",
              "         2.63447454e-03, -7.62860328e-02, -2.01788973e-02,\n",
              "        -4.04613130e-02,  4.17123921e-03,  5.36149964e-02,\n",
              "        -2.93224342e-02, -4.44798768e-02, -5.79857528e-02,\n",
              "        -1.35607133e-02,  5.72532676e-02,  3.33629660e-02,\n",
              "         3.53656709e-03,  6.08776398e-02,  5.71448058e-02,\n",
              "         1.02256788e-02, -2.70932298e-02, -5.79120591e-03,\n",
              "         3.23387384e-02,  3.68975825e-03,  1.32658156e-02,\n",
              "         3.61888967e-02,  6.86493292e-02, -1.21597638e-02,\n",
              "        -3.19997035e-02,  3.68759548e-03, -9.65958578e-04,\n",
              "         7.13852346e-02,  2.13789400e-02,  6.60926756e-03,\n",
              "        -3.70355807e-02, -2.12660714e-04, -7.22468039e-03,\n",
              "        -3.75933424e-02,  1.10475700e-02, -3.10622193e-02,\n",
              "        -8.48005041e-02, -6.72654212e-02, -7.99142122e-02,\n",
              "        -5.90982568e-03,  4.20907773e-02,  2.03831191e-03,\n",
              "        -2.45528724e-02, -1.27297165e-02,  6.91507710e-04,\n",
              "         4.89160977e-02, -4.53730412e-02,  1.24634661e-01,\n",
              "        -2.39438452e-02,  6.76595792e-03, -4.23118286e-02,\n",
              "         1.41443256e-02, -6.85774833e-02,  5.73958755e-02,\n",
              "        -2.21412349e-02,  3.65958288e-02,  8.19960237e-02,\n",
              "        -3.04153208e-02,  1.51862707e-02,  4.00401019e-02,\n",
              "        -1.53581863e-02,  2.91933045e-02, -2.09202059e-02,\n",
              "        -3.17929201e-02, -9.26598907e-03, -3.39877270e-02,\n",
              "        -1.10186696e-01,  1.21946149e-02, -2.18026619e-02,\n",
              "         4.88194451e-02,  4.19778265e-02,  9.64047480e-03,\n",
              "         1.63905546e-02,  3.27348448e-02,  1.72946341e-02,\n",
              "        -2.10956819e-02, -6.70247898e-02,  3.09343170e-03,\n",
              "        -1.22066565e-04, -3.35870609e-02,  2.42925081e-02,\n",
              "         3.62704135e-02,  3.48834693e-02, -3.54527086e-02,\n",
              "        -3.25557142e-02,  2.87115891e-02,  4.18716744e-02,\n",
              "        -2.01243069e-02, -4.36275564e-02, -5.40758856e-02,\n",
              "        -2.41763107e-02,  3.88873182e-02, -3.21941474e-03,\n",
              "         9.68211982e-03,  1.61762852e-02, -3.76105867e-02,\n",
              "        -5.37408590e-02,  4.20842692e-02, -7.95554183e-03,\n",
              "         1.04091410e-02,  4.91987579e-02,  1.36256330e-02,\n",
              "         3.49623151e-02, -2.51907632e-02,  5.96581623e-02,\n",
              "         1.20942295e-03, -5.79569750e-02, -2.67092176e-02,\n",
              "        -2.55430304e-02, -9.93321612e-02,  1.45035842e-02,\n",
              "         3.16455476e-02,  2.90998369e-02, -2.53753066e-02,\n",
              "        -3.72784138e-02,  8.95727202e-02,  4.64357287e-02,\n",
              "         2.12397911e-02,  4.81288470e-02,  1.07315749e-01,\n",
              "         2.54127514e-02, -7.95395449e-02, -5.70295639e-02,\n",
              "         8.59089270e-02, -6.04183301e-02,  3.18365451e-03,\n",
              "         7.46015972e-03,  4.94210199e-02, -1.92751568e-02,\n",
              "         2.06641605e-04,  4.61571366e-02,  2.59037036e-02,\n",
              "         3.65945045e-03,  4.26112302e-02,  1.33554218e-02,\n",
              "         3.01056411e-02,  4.80726510e-02,  1.29655544e-02,\n",
              "        -5.52162379e-02, -2.55645905e-02, -3.52634043e-02,\n",
              "        -1.32904500e-02, -1.75038744e-02,  1.48171354e-02,\n",
              "         3.30917612e-02,  3.32558788e-02,  1.00339182e-01,\n",
              "         3.56880240e-02,  1.03409272e-02, -5.04089743e-02,\n",
              "         3.57096680e-02, -3.17836218e-02,  6.13523871e-02,\n",
              "        -6.46949187e-02, -5.13816578e-03,  1.55013949e-02,\n",
              "         3.51807056e-03,  4.81883883e-02,  6.60642013e-02,\n",
              "        -5.18512167e-02,  4.20604907e-02, -1.34357566e-03,\n",
              "         1.13711599e-02, -2.25472208e-02, -7.25526884e-02,\n",
              "        -6.11044355e-02,  8.00163299e-03, -3.50745246e-02,\n",
              "         3.44594978e-02, -6.07239604e-02, -6.99718297e-02,\n",
              "         7.38685206e-02, -3.32606211e-02, -5.67775331e-02,\n",
              "        -2.80575585e-02, -3.28892693e-02, -6.19696118e-02,\n",
              "        -3.06257289e-02,  4.39841822e-02,  5.68487905e-02,\n",
              "        -1.78444032e-02,  4.45514657e-02,  1.15170637e-02,\n",
              "        -2.63086315e-02, -2.46057753e-02, -2.24723686e-02,\n",
              "        -7.99471047e-04,  4.27836590e-02, -2.27921014e-03,\n",
              "         3.73273604e-02, -7.21605122e-02,  5.76342158e-02,\n",
              "         3.59318554e-02,  1.06704496e-02,  4.81328927e-02,\n",
              "         4.88081463e-02,  1.06078396e-02, -8.10832009e-02,\n",
              "        -5.11851385e-02,  5.23219407e-02,  4.28600311e-02,\n",
              "         3.46638076e-02, -8.37449059e-02, -4.06521984e-04,\n",
              "         4.25096527e-02,  1.28437607e-02,  3.23664024e-03,\n",
              "        -4.18377621e-03,  3.58066633e-02, -1.64717413e-03,\n",
              "         2.31158268e-02,  2.25628307e-03, -7.48861283e-02,\n",
              "         5.59269860e-02,  4.86996584e-02,  3.14949988e-03,\n",
              "        -9.08138081e-02, -6.50672615e-02,  6.30697608e-02,\n",
              "        -5.80256619e-03,  2.89980154e-02, -3.31741907e-02,\n",
              "         2.80077439e-02, -2.10555289e-02,  1.79412149e-04,\n",
              "        -7.15215132e-02, -4.08559293e-02, -1.51274726e-02,\n",
              "        -3.89590599e-02, -1.79688036e-02,  4.81015677e-03,\n",
              "         3.87830809e-02,  1.72124002e-02,  2.51249168e-02,\n",
              "         1.97261088e-02, -2.21614279e-02,  4.27471362e-02,\n",
              "         1.24356218e-01, -5.40729575e-02, -1.02667347e-01,\n",
              "        -1.92160381e-03, -1.47135451e-03, -3.93290892e-02,\n",
              "        -5.94464391e-02, -3.46003212e-02,  7.05445334e-02,\n",
              "        -1.68622509e-02,  3.86278667e-02, -5.06402440e-02,\n",
              "         8.21330920e-02,  2.78636953e-03, -1.07763462e-01,\n",
              "         9.01518390e-03, -1.98760144e-02,  4.03028019e-02,\n",
              "         2.46420037e-02, -8.66470952e-03, -7.58705065e-02,\n",
              "         8.58741850e-02,  7.78678991e-03,  6.56191306e-03,\n",
              "         5.70448302e-02,  7.38752708e-02, -7.21952990e-02,\n",
              "        -2.10029799e-02, -5.51597886e-02,  7.14533124e-03,\n",
              "         2.64757145e-02, -1.04655884e-02, -1.38026820e-02,\n",
              "         1.82000063e-02,  8.26761052e-02, -1.17029464e-02,\n",
              "        -8.32419246e-02, -2.96600889e-02, -1.91036740e-03,\n",
              "         7.79182091e-02, -6.65232167e-02,  3.13470103e-02,\n",
              "        -8.98894854e-03,  1.30566293e-02,  2.61621736e-02,\n",
              "        -1.98201537e-02,  4.35157418e-02,  4.24742745e-03,\n",
              "         6.84132725e-02, -3.34900199e-03,  7.31357560e-02,\n",
              "        -1.89439747e-02, -2.30185203e-02, -4.38338183e-02,\n",
              "        -4.61920574e-02, -1.21890604e-02, -7.09689111e-02,\n",
              "        -2.07946636e-02, -7.08205625e-02,  5.42958491e-02,\n",
              "        -2.94901952e-02, -1.28000742e-02,  1.50362672e-02,\n",
              "        -7.30906101e-03,  5.74041158e-02, -1.43169723e-02,\n",
              "        -2.23605838e-02, -4.56232950e-02, -2.65196748e-02,\n",
              "         1.56748341e-03,  6.18297346e-02, -5.07267052e-03,\n",
              "        -1.02511626e-02,  4.26837988e-02, -3.81636955e-02,\n",
              "        -8.20168406e-02, -3.55520025e-02, -3.80589664e-02,\n",
              "        -2.72928849e-02, -2.97392737e-02, -1.01597067e-02,\n",
              "        -2.92771906e-02, -5.74080907e-02, -1.09333098e-01,\n",
              "        -1.03353979e-02, -1.11299329e-01, -1.43264942e-02,\n",
              "        -2.30057593e-02,  6.49935305e-02, -4.66157794e-02,\n",
              "        -8.32097381e-02,  4.53239195e-02,  5.66062219e-02,\n",
              "        -3.90121574e-03, -4.76616099e-02,  1.66355390e-02,\n",
              "         4.49800584e-03, -6.57755509e-02, -3.85845057e-03,\n",
              "        -3.02290618e-02, -5.61282709e-02, -5.43148369e-02,\n",
              "        -2.96183191e-02, -5.19148307e-03, -4.46306542e-03,\n",
              "         2.99144108e-02, -3.40123363e-02, -7.93099403e-02,\n",
              "         4.18831371e-02, -9.51167848e-03, -5.58031574e-02,\n",
              "        -2.48545948e-02, -2.78344029e-03, -1.36596544e-04,\n",
              "        -5.30387722e-02,  4.15457487e-02, -1.83076765e-02,\n",
              "         2.90706434e-04,  4.43447456e-02,  8.83830339e-03,\n",
              "         1.89844444e-02,  4.36773822e-02, -1.42222578e-02,\n",
              "         6.69130304e-06,  6.30455166e-02, -3.94993871e-02,\n",
              "        -5.63049354e-02, -2.68699490e-02,  1.73468553e-02,\n",
              "        -5.57510629e-02, -1.50017384e-02,  5.32644577e-02,\n",
              "         3.18098143e-02, -2.98221055e-02,  4.41048704e-02,\n",
              "         3.63088548e-02,  1.10510243e-02, -5.35040125e-02,\n",
              "         5.47483414e-02,  4.44791056e-02, -5.63693754e-02,\n",
              "        -1.33470083e-02, -6.88191131e-02,  8.74502119e-03,\n",
              "        -1.56946126e-02,  4.68905382e-02,  3.94971371e-02,\n",
              "         6.09551510e-03,  2.03198427e-03, -3.34025249e-02,\n",
              "        -1.00071222e-01, -1.26298964e-02, -6.34763017e-02,\n",
              "        -3.69291492e-02, -4.91034836e-02,  3.89056057e-02,\n",
              "        -9.89825428e-02,  6.98999129e-03, -6.72468916e-02,\n",
              "         6.25784695e-02, -8.23757872e-02,  3.40713635e-02,\n",
              "        -1.12677805e-01, -1.78764500e-02,  2.67578028e-02,\n",
              "         2.14300975e-02,  2.67136265e-02, -3.79963666e-02,\n",
              "         5.50963357e-02,  4.52665752e-03,  2.50210166e-02,\n",
              "         4.25607758e-03, -8.33725091e-03, -1.00860139e-02,\n",
              "         1.27442041e-02,  4.19268273e-02,  9.33257397e-03,\n",
              "         2.27389438e-03,  7.17393262e-03, -8.34710598e-02,\n",
              "        -5.93745336e-03, -3.00116464e-02, -2.83677131e-04,\n",
              "         7.86481574e-02, -5.82557321e-02, -3.27576026e-02,\n",
              "        -4.19961996e-02,  1.90203618e-02,  8.67906213e-02,\n",
              "        -4.28648442e-02,  3.80804278e-02,  1.74997114e-02,\n",
              "        -2.45486610e-02,  3.17244753e-02,  5.23274718e-03,\n",
              "         6.47846423e-03, -4.48664092e-02,  1.07318401e-01,\n",
              "         5.58978841e-02,  3.42536941e-02,  1.06463078e-02,\n",
              "         3.16582844e-02,  6.66194484e-02,  5.60141131e-02,\n",
              "         6.65164441e-02,  4.03290614e-02, -7.42756724e-02,\n",
              "        -8.39175470e-03, -6.68335333e-02,  4.53241868e-03,\n",
              "        -2.87330635e-02,  4.80879992e-02, -4.69006859e-02,\n",
              "        -1.79481413e-02, -7.71417515e-03,  3.82247530e-02,\n",
              "        -4.15830426e-02,  9.68053043e-02, -2.03782488e-02,\n",
              "        -7.57835107e-04, -3.83332819e-02,  6.00728765e-02,\n",
              "         4.90232836e-03,  3.48141268e-02,  1.00170374e-02,\n",
              "        -1.28350006e-02,  3.83750908e-02]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ceI9ecrFqrn"
      },
      "source": [
        "c = 0.1  # отношение количества аномальных экземпляров к нормальным\r\n",
        "\r\n",
        "normal_data = topic1\r\n",
        "anomal_data = topic2[:int(c * len(normal_data)) + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSIyL1qyHLLD",
        "outputId": "8beae534-17ad-4c2d-878d-a5418270a09b"
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn.utils import shuffle\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "all_data = normal_data + anomal_data\r\n",
        "x = pd.Series(all_data)\r\n",
        "y = np.array([False] * len(normal_data) + [True] * len(anomal_data))\r\n",
        "\r\n",
        "all_data, x, y = shuffle(all_data, x, y, random_state=123)\r\n",
        "print(\"Всего экземпляров = {}\".format(len(all_data)))\r\n",
        "# print(\"(Кол-во текстов, число признаков текста) = {}\".format(x.shape))\r\n",
        "print(\"Кол-во меток = {}\".format(len(y)))\r\n",
        "print(\"Кол-во нормальных экземпляров = {}\".format(len(normal_data)))\r\n",
        "print(\"Кол-во аномальных экземпляров = {}\".format(len(anomal_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Всего экземпляров = 1101\n",
            "Кол-во меток = 1101\n",
            "Кол-во нормальных экземпляров = 1000\n",
            "Кол-во аномальных экземпляров = 101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E9-SgYVIkwy"
      },
      "source": [
        "## Функция Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAvrzkc9HOeH"
      },
      "source": [
        "def cosine_similarity(x_predict, x):\r\n",
        "    if type(x_predict) is np.ndarray:\r\n",
        "        flat_output = x_predict\r\n",
        "        flat_input = x_predict\r\n",
        "        # flat_output = np.reshape(x_predict, (np.shape(x)[0], -1))\r\n",
        "        # flat_input = np.reshape(x_predict, (np.shape(x)[0], -1))\r\n",
        "        sum = np.sum(flat_output * flat_input, -1)\r\n",
        "        norm1 = np.linalg.norm(flat_output, axis=-1) + 0.000001\r\n",
        "        norm2 = np.linalg.norm(flat_input, axis=-1) + 0.000001 \r\n",
        "        return -(sum / norm1 / norm2)\r\n",
        "    else:\r\n",
        "        # ДЛЯ НЕ ПОЛНОСВЯЗНЫХ СЛОЕВ НУЖЕН ДРУГОЙ shape\r\n",
        "        flat_output = x_predict\r\n",
        "        flat_input = x_predict\r\n",
        "        # flat_output = tf.reshape(tensor=x_predict, shape=[x.shape.as_list()[0], -1])\r\n",
        "        # flat_input = tf.reshape(tensor=x_predict, shape=[x.shape.as_list()[0], -1])\r\n",
        "        sum = tf.math.reduce_sum(tf.math.multiply(flat_output, flat_input), axis=-1)\r\n",
        "        norm1 = tf.norm(flat_output, axis=-1) + 0.000001\r\n",
        "        norm2 = tf.norm(flat_input, axis=-1) + 0.000001\r\n",
        "        return -(tf.math.divide(tf.math.divide(sum, norm1), norm2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZJE4GBII06Y"
      },
      "source": [
        "## RSRAE model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uuWVWVdIxPN",
        "outputId": "cba2b1b1-1a0f-481f-8219-4b7002ca5999"
      },
      "source": [
        "import math\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "print(\"Tensorflow version = {}\".format(tf.__version__)) # текущая версия tf\r\n",
        "\r\n",
        "from tensorflow.keras import Model, optimizers, metrics\r\n",
        "from tensorflow.keras.layers import Layer, Flatten, Dense, BatchNormalization, Dropout\r\n",
        "\r\n",
        "# from tensorflow.keras import activations, Sequential, Input\r\n",
        "# from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Reshape\r\n",
        "# from sklearn.metrics import roc_auc_score, average_precision_score\r\n",
        "\r\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\r\n",
        "\r\n",
        "# Задаем random_seed для tensorflow и numpy\r\n",
        "random_seed = 123\r\n",
        "tf.random.set_seed(random_seed)\r\n",
        "np.random.seed(random_seed)\r\n",
        "\r\n",
        "# Sets the default float type\r\n",
        "tf.keras.backend.set_floatx('float64')\r\n",
        "\r\n",
        "# Set random seed\r\n",
        "tf.random.set_seed(123)\r\n",
        "np.random.seed(123)\r\n",
        "\r\n",
        "\r\n",
        "class RSR(Layer):\r\n",
        "    \"\"\"\r\n",
        "    Robust Subspace Recovery (RSR) layer.\r\n",
        "    Робастный слой, восстанавливающий подпространство. Задача данного слоя - отобразить\r\n",
        "    закодированные энкодером данные в подпростраство так, чтобы после их обратного\r\n",
        "    отображения декодером дивергенция между экземпляром исходных данных и его образом,\r\n",
        "    полученным от автоэнкодера была незначительной для нормального экземпляра и была\r\n",
        "    большой для аномального экземпляра. \r\n",
        "\r\n",
        "    # Example\r\n",
        "    ```\r\n",
        "        z_rsr, A = RSR(intrinsic_size=10)(z)\r\n",
        "    ```\r\n",
        "    # Arguments\r\n",
        "        intrinsic_size: размерность z_rsr.\r\n",
        "    # Input shape\r\n",
        "        2D tensor with shape: `(n_samples, n_features)` after encoding.\r\n",
        "    # Output shape\r\n",
        "        2D tensor with shape: `(n_samples, intrinsic_size)`.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, intrinsic_size: int, name=\"RSR_layer\", **kwargs):\r\n",
        "        super(RSR, self).__init__(name=name, **kwargs)\r\n",
        "        # Если присваивать экземпляр слоя, как атрибут другого слоя, то хорошей\r\n",
        "        # практикой делать создавать такие подслои в __init__ (поскольку подслои обычно\r\n",
        "        # имеют метод build, они будут собраны, когда будет собран внешний слой). \r\n",
        "        self.flatten = Flatten()\r\n",
        "        self.intrinsic_size = intrinsic_size\r\n",
        "        \r\n",
        "    def build(self, input_shape):\r\n",
        "        \"\"\"Определяет веса слоя, а именно задает матрицу A.\"\"\"\r\n",
        "        self.A = self.add_weight(name=\"A\",\r\n",
        "                                 shape=[int(input_shape[-1]), self.intrinsic_size],\r\n",
        "                                 initializer='random_normal',\r\n",
        "                                 trainable=True,)\r\n",
        "        \r\n",
        "        # self.V = self.add_weight(name=\"V\",\r\n",
        "        #                          shape=[int(input_shape[-1]), 1],\r\n",
        "        #                          initializer='random_normal',\r\n",
        "        #                          trainable=True,)\r\n",
        "        \r\n",
        "    def call(self, z):\r\n",
        "        \"\"\"\r\n",
        "        Логика слоя. Умножение выхода энкодера - вектора z на матрицу A.\r\n",
        "        Возвращает отображенный z_rsr и матрицу A, которая потребуется далее.\r\n",
        "        \"\"\"\r\n",
        "        z = self.flatten(z)\r\n",
        "        # print(\"z.shpae Before A:\", z.shape)\r\n",
        "        z_rsr = tf.linalg.matmul(z, self.A)\r\n",
        "        # print(\"z_rsr.shpae After A:\", z_rsr.shape) \r\n",
        "        return z_rsr\r\n",
        "\r\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \r\n",
        "    # get_config и метода класса (@classmethod) from_config.\r\n",
        "    def get_config(self):\r\n",
        "        config = super(Layer, self).get_config()\r\n",
        "        config.update({'intrinsic_size': self.intrinsic_size})\r\n",
        "        return config\r\n",
        "\r\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \r\n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "        return cls(**config)\r\n",
        "\r\n",
        "\r\n",
        "class L2Normalization(Layer):\r\n",
        "    \"\"\"Слой для l_2 нормализации, который будет применяться к выходу RSR layer.\"\"\"\r\n",
        "    \r\n",
        "    def __init__(self, name=\"L2Normalization\", **kwargs):\r\n",
        "        super(L2Normalization, self).__init__(name=name, **kwargs)\r\n",
        "\r\n",
        "    def call(self, z_rsr):\r\n",
        "        \"\"\"\r\n",
        "        Выполняет l_2 нормализацию векторов, полученных после применения RSR layer\r\n",
        "        вдоль оси, соответсвующей числу признаков. То есть производится нормализация\r\n",
        "        каждого экземпляра выборки, в результате которой признаки экземпляров будут\r\n",
        "        находиться в отрезке [-1; 1].\r\n",
        "        \"\"\"\r\n",
        "        z_tilde = tf.math.l2_normalize(z_rsr, axis=-1)\r\n",
        "        return z_tilde\r\n",
        "\r\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \r\n",
        "    # get_config и метода класса (@classmethod) from_config.\r\n",
        "    def get_config(self):\r\n",
        "        config = super(Layer, self).get_config()\r\n",
        "        return config\r\n",
        "\r\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \r\n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "        return cls(**config)\r\n",
        "\r\n",
        "\r\n",
        "class Encoder(Layer):\r\n",
        "    \"\"\"\r\n",
        "    Класс для encoder модели RSRAE. Отображает исходные данные input_data в вектор z,\r\n",
        "    кодирующий исходные данные.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self,\r\n",
        "                 hidden_layer_dimensions,\r\n",
        "                 activation,\r\n",
        "                 flag_bn=True, \r\n",
        "                 name=\"Encoder\",\r\n",
        "                 **kwargs):\r\n",
        "        super(Encoder, self).__init__(name=name, **kwargs)\r\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\r\n",
        "        self.activation = activation\r\n",
        "        self.flag_bn = flag_bn\r\n",
        "        self.dense0 = Dense(hidden_layer_dimensions[0], activation=activation,\r\n",
        "                            name='encoder_0')\r\n",
        "        self.dense1 = Dense(hidden_layer_dimensions[1], activation=activation,\r\n",
        "                            name='encoder_1')\r\n",
        "        self.dense2 = Dense(hidden_layer_dimensions[2], activation=activation,\r\n",
        "                            name='encoder_2')\r\n",
        "        if flag_bn:\r\n",
        "            self.batch_normalization0 = BatchNormalization(name=\"encoder_bn_layer_0\")\r\n",
        "            self.batch_normalization1 = BatchNormalization(name=\"encoder_bn_layer_1\")\r\n",
        "            self.batch_normalization2 = BatchNormalization(name=\"encoder_bn_layer_2\")\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        \"\"\"Отображние исходных данных x -> в закодированный вектор z.\"\"\"\r\n",
        "        x = inputs\r\n",
        "        x = self.dense0(x)\r\n",
        "        if self.flag_bn:\r\n",
        "            x = self.batch_normalization0(x)\r\n",
        "        x = self.dense1(x)\r\n",
        "        if self.flag_bn:\r\n",
        "            x = self.batch_normalization1(x)\r\n",
        "        x = Dropout(0.2)((x))\r\n",
        "        x = self.dense2(x)\r\n",
        "        if self.flag_bn:\r\n",
        "            x = self.batch_normalization2(x)\r\n",
        "        x = Dropout(0.2)((x))    \r\n",
        "        z = x\r\n",
        "        return z\r\n",
        "    \r\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \r\n",
        "    # get_config и метода класса (@classmethod) from_config.\r\n",
        "    def get_config(self):\r\n",
        "        config = super(Layer, self).get_config()\r\n",
        "        config.update({'hidden_layer_dimensions': self.hidden_layer_dimensions})\r\n",
        "        config.update({'activation': self.activation})\r\n",
        "        config.update({'flag_bn': self.flag_bn})\r\n",
        "        return config\r\n",
        "\r\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \r\n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "        return cls(**config)\r\n",
        "\r\n",
        "\r\n",
        "class Decoder(Layer):\r\n",
        "    \"\"\"\r\n",
        "    Класс для decoder модели RSRAE. Отображает вектор z_rsr, полученный в результате\r\n",
        "    кодирования исходных данных в вектор z, и последующим отображением вектора z при\r\n",
        "    помощи RSR layer (x -> z -> z_rsr), обратно в пространство исходных данных \r\n",
        "    (z_rsr -> x_tilde).\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self,\r\n",
        "                 inputs_dim,\r\n",
        "                 hidden_layer_dimensions,\r\n",
        "                 activation,\r\n",
        "                 flag_bn=True, \r\n",
        "                 name=\"Decoder\",\r\n",
        "                 **kwargs):\r\n",
        "        super(Decoder, self).__init__(name=name, **kwargs)\r\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\r\n",
        "        self.activation = activation\r\n",
        "        self.flag_bn = flag_bn\r\n",
        "        self.dense2 = Dense(hidden_layer_dimensions[2], activation=activation,\r\n",
        "                            name='decoder_2')\r\n",
        "        self.dense1 = Dense(hidden_layer_dimensions[1], activation=activation,\r\n",
        "                            name='decoder_1')\r\n",
        "        self.dense0 = Dense(hidden_layer_dimensions[0], activation=activation,\r\n",
        "                            name='decoder_0')\r\n",
        "        self.dense_output = Dense(inputs_dim, activation=activation,\r\n",
        "                            name='decoder_output')\r\n",
        "        if flag_bn:\r\n",
        "            self.batch_normalization2 = BatchNormalization(name=\"decoder_bn_layer_2\")\r\n",
        "            self.batch_normalization1 = BatchNormalization(name=\"decoder_bn_layer_1\")\r\n",
        "            self.batch_normalization0 = BatchNormalization(name=\"decoder_bn_layer_0\")\r\n",
        "    def call(self, inputs):\r\n",
        "        \"\"\"\r\n",
        "        Отображние z_rsr -> x_tilde, где x_tilde - вектор, лежащий в пространстве\r\n",
        "        исходных даных.\r\n",
        "        \"\"\"\r\n",
        "        z_rsr = inputs\r\n",
        "        z_rsr = self.dense2(z_rsr)\r\n",
        "        if self.flag_bn:\r\n",
        "            z_rsr = self.batch_normalization2(z_rsr)\r\n",
        "        z_rsr = Dropout(0.3)((z_rsr))\r\n",
        "        z_rsr = self.dense1(z_rsr)\r\n",
        "        if self.flag_bn:\r\n",
        "            z_rsr = self.batch_normalization1(z_rsr)\r\n",
        "        z_rsr = Dropout(0.4)((z_rsr))\r\n",
        "        z_rsr = self.dense0(z_rsr)\r\n",
        "        if self.flag_bn:\r\n",
        "            z_rsr = self.batch_normalization0(z_rsr)\r\n",
        "        z_rsr = Dropout(0.4)((z_rsr))\r\n",
        "        x_tilde = self.dense_output(z_rsr)\r\n",
        "        return x_tilde\r\n",
        "    \r\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \r\n",
        "    # get_config и метода класса (@classmethod) from_config.\r\n",
        "    def get_config(self):\r\n",
        "        config = super(Layer, self).get_config()\r\n",
        "        config.update({'hidden_layer_dimensions': self.hidden_layer_dimensions})\r\n",
        "        config.update({'activation': self.activation})\r\n",
        "        config.update({'flag_bn': self.flag_bn})\r\n",
        "        return config\r\n",
        "\r\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \r\n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\r\n",
        "    @classmethod\r\n",
        "    def from_config(cls, config):\r\n",
        "        return cls(**config)\r\n",
        "\r\n",
        "\r\n",
        "class RSRAE(Model):\r\n",
        "    \"\"\"\r\n",
        "    Нейросетевая модель-автоэнкодер для обнаружения аномалий с робастным слоем,\r\n",
        "    восстанавливающим подпространство (RSR layer между encoder и decoder).\r\n",
        "    Комбинируем encoder + RSR layer + decoder в end-to-end модель.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self,\r\n",
        "                 inputs_dim, # размерность вектора признаков\r\n",
        "                 hidden_layer_dimensions,\r\n",
        "                 intrinsic_size, # разерность z_rsr после RSR layer\r\n",
        "                 activation,\r\n",
        "                 hub_layer,\r\n",
        "                 flag_bn=True,\r\n",
        "                 flag_normalize=True,\r\n",
        "                 learning_rate=1e-3,\r\n",
        "                 beta=1,\r\n",
        "                 eta=1,\r\n",
        "                 t_step=0,\r\n",
        "                 ae_loss_norm_type='MSE',\r\n",
        "                 rsr_loss_norm_type='MSE',\r\n",
        "                 name='RSRAE',\r\n",
        "                 **kwargs):\r\n",
        "        super(RSRAE, self).__init__(name=name, **kwargs)\r\n",
        "        self.inputs_dim = inputs_dim\r\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\r\n",
        "        self.intrinsic_size = intrinsic_size\r\n",
        "        self.activation = activation\r\n",
        "        self.flag_bn = flag_bn\r\n",
        "        self.flag_normalize = flag_normalize\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "        self.beta = tf.Variable(beta, dtype=tf.float64, trainable=False)\r\n",
        "        self.beta0 = tf.Variable(beta, dtype=tf.float64, trainable=False)\r\n",
        "        self.eta = tf.Variable(eta, dtype=tf.float64, trainable=False)\r\n",
        "        self.eta0 = tf.Variable(eta, dtype=tf.float64, trainable=False)\r\n",
        "        self.t_step = tf.Variable(t_step, dtype=tf.float64, trainable=False)\r\n",
        "        self.ae_loss_norm_type = ae_loss_norm_type\r\n",
        "        self.rsr_loss_norm_type = rsr_loss_norm_type\r\n",
        "        # Для вычисления среднего loss по loss всех батчей в эпохе\r\n",
        "        self.loss_tracker = metrics.Mean(name=\"loss\")\r\n",
        "        self.auc_tracker = metrics.Mean(name=\"auc\")\r\n",
        "        self.ap_tracker = metrics.Mean(name=\"ap\")\r\n",
        "\r\n",
        "        # Создание экземпляров оптимизаторов\r\n",
        "        self.optimizer_ae = optimizers.Adam(learning_rate=learning_rate)\r\n",
        "        self.optimizer_rsr1 = optimizers.Adam(learning_rate=5 * learning_rate)\r\n",
        "        self.optimizer_rsr2 = optimizers.Adam(learning_rate=5 * learning_rate)\r\n",
        "\r\n",
        "        # Слои\r\n",
        "        self.emnedding_layer = hub_layer\r\n",
        "        self.encoder = Encoder(hidden_layer_dimensions=hidden_layer_dimensions,\r\n",
        "                               activation=activation,\r\n",
        "                               flag_bn=flag_bn)\r\n",
        "        self.rsr = RSR(intrinsic_size=intrinsic_size)\r\n",
        "        if flag_normalize:\r\n",
        "            self.l2normalization = L2Normalization()\r\n",
        "        self.decoder = Decoder(inputs_dim=inputs_dim,\r\n",
        "                               hidden_layer_dimensions=hidden_layer_dimensions,\r\n",
        "                               activation=activation,\r\n",
        "                               flag_bn=flag_bn)\r\n",
        "        \r\n",
        "    def call(self, inputs):\r\n",
        "        e = self.emnedding_layer(inputs)\r\n",
        "        e = tf.cast(e, dtype=tf.float64)\r\n",
        "        z = self.encoder(e)\r\n",
        "        z_rsr = self.rsr(z)\r\n",
        "        if self.flag_normalize:\r\n",
        "            z_rsr = self.l2normalization(z_rsr)\r\n",
        "        x_tilde = self.decoder(z_rsr)\r\n",
        "        return e, z, z_rsr, x_tilde\r\n",
        "\r\n",
        "    def ae_loss(self, x, x_tilde):\r\n",
        "        \"\"\"Функция потерь реконструкции автоэнкодера - L_AE.\"\"\"\r\n",
        "\r\n",
        "        x = tf.reshape(x, (tf.shape(x)[0], -1))\r\n",
        "        x_tilde = tf.reshape(x_tilde, (tf.shape(x_tilde)[0], -1))\r\n",
        "\r\n",
        "        # axis=1 для tf.norm => вычисление вдоль оси признаков\r\n",
        "        # tf.math.reduce_mean без параметров - mean от элементов матрицы\r\n",
        "        if self.ae_loss_norm_type in ['MSE', 'mse', 'Frob', 'F']:\r\n",
        "            return tf.math.reduce_mean(tf.math.square(tf.norm(x-x_tilde, \r\n",
        "                                                              ord=2, axis=1)))\r\n",
        "        elif self.ae_loss_norm_type in ['L1', 'l1']:\r\n",
        "            return tf.math.reduce_mean(tf.norm(x-x_tilde, ord=1, axis=1))\r\n",
        "        elif self.ae_loss_norm_type in ['LAD', 'lad', 'L21', 'l21', 'L2', 'l2']:\r\n",
        "            return tf.math.reduce_mean(tf.norm(x-x_tilde, ord=2, axis=1))\r\n",
        "        else:\r\n",
        "            raise Exception(\"Norm type error!\")\r\n",
        "    \r\n",
        "    def rsr1_loss(self, z, z_rsr, beta, eta):\r\n",
        "        \"\"\"Функция потери для RSR layer - L_RSR1.\"\"\"\r\n",
        "        z_rsr = tf.matmul(z_rsr, tf.transpose(self.rsr.A))\r\n",
        "        # z_rsr_new = tf.matmul(z_rsr, self.)\r\n",
        "\r\n",
        "        if self.rsr_loss_norm_type in ['MSE', 'mse', 'Frob', 'F']:\r\n",
        "            return tf.math.reduce_mean(tf.math.square(tf.norm(z-z_rsr, ord=2, \r\n",
        "                                                            axis=1)))\r\n",
        "        elif self.rsr_loss_norm_type in ['L1', 'l1']:\r\n",
        "            return tf.math.reduce_mean(tf.norm(z-z_rsr, ord=1, axis=1))\r\n",
        "        elif self.rsr_loss_norm_type in ['LAD', 'lad', 'L21', 'l21', 'L2', 'l2']:\r\n",
        "            return tf.math.reduce_mean(tf.norm(z-z_rsr, ord=2, axis=1))\r\n",
        "        else:\r\n",
        "            raise Exception(\"Norm type error!\")\r\n",
        "    \r\n",
        "    def rsr2_loss(self):\r\n",
        "        \"\"\"Функция потери для RSR layer - L_RSR2.\"\"\"\r\n",
        "        A = self.rsr.A\r\n",
        "        A_T = tf.transpose(A)\r\n",
        "        I = tf.eye(self.intrinsic_size, dtype=tf.float64)\r\n",
        "        return tf.math.reduce_mean(tf.math.square(tf.linalg.matmul(A_T, A) - I))\r\n",
        "\r\n",
        "    def rsr3_loss(self, z, z_rsr, beta, eta):\r\n",
        "        \"\"\"\r\n",
        "        Cтатьи 'Robust principal component analysis by \r\n",
        "        self-organizing rules basedon statistical physics approach', на которую\r\n",
        "        ссылается http://files.is.tue.mpg.de/black/papers/delatorreIJCV03.pdf\r\n",
        "        \"\"\"\r\n",
        "        z_rsr = tf.matmul(z_rsr, tf.transpose(self.rsr.A))  # AA'z\r\n",
        "        e_pca = tf.math.square(tf.norm(z-z_rsr, ord=2, axis=1))\r\n",
        "        self.min_div = tf.reduce_min(e_pca)\r\n",
        "        self.max_div = tf.reduce_max(e_pca)\r\n",
        "        self.mean_div = tf.reduce_mean(e_pca)\r\n",
        "        print(beta)\r\n",
        "        loss = -1 * tf.math.reduce_mean(tf.math.log(1 + tf.math.exp(-beta * e_pca - eta))) / beta\r\n",
        "        return loss\r\n",
        "        \r\n",
        "    def gradients(model, inputs, targets):\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            loss_value = loss_fn(model, inputs, targets)\r\n",
        "        return tape.gradient(loss_value, model.trainable_variables)\r\n",
        "    \r\n",
        "    @tf.function()\r\n",
        "    def train_step(self, data):\r\n",
        "        \"\"\"\r\n",
        "        Override the method. Будет вызываться при 'model.fit()'.\r\n",
        "        Один шаг обучения, на котором вычисляются функции потерь для автоэнкодера и\r\n",
        "        RSR layer, и в соотвествии с ними обновляются значения обучаемых переменных - \r\n",
        "        весов нейросети и матрицы A соответсвенно. Будет вызываться от одного батча.\r\n",
        "        Заметим, что в этом методе мы используем пользовательские оптимизаторы и функции\r\n",
        "        потерь, поэтому перед тренировкой метод compile вызывать не придется.\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "\r\n",
        "        x, y = data\r\n",
        "\r\n",
        "        # tf.GradientTape() - записывает операции для автоматического дифференцирования\r\n",
        "\r\n",
        "        # По умолчанию persistent=False и удерживаемые GradientTape, высвобождаются,\r\n",
        "        # как только вызывается метод GradientTape.gradient(). Чтобы вычислить несколько\r\n",
        "        # градиентов за одно вычисление, требуется задать persistent=true. Это позволяет\r\n",
        "        # многократно вызывать метод gradient(), тогда требуется самостоятельно\r\n",
        "        # освободить ресурсы с помощью 'del tape'.\r\n",
        "\r\n",
        "        # watch_accessed_variables=True => автоматическое отслеживание всех обучаемых\r\n",
        "        # переменные, к которым осуществляется доступ. Так градиенты могут быть\r\n",
        "        # запрошены c любого вычисленного результата в tape.\r\n",
        "        with tf.GradientTape(persistent=True, watch_accessed_variables=True) as tape:\r\n",
        "            # Здесь требуется запустить прямой проход нейросети. Операции применяемые\r\n",
        "            # при проходе к входных данным будут записаны на GradientTape. \r\n",
        "            e, z, z_rsr, x_tilde = self.call(x) # прямой проход RSRAE\r\n",
        "            z = tf.keras.layers.Flatten()(z) # вроде для текстовых данных необязательно\r\n",
        "            # Вычисляем значения функций потерь для этого прохода\r\n",
        "            loss_ae = self.ae_loss(e, x_tilde)\r\n",
        "            loss_rsr3 = self.rsr3_loss(z, z_rsr, self.beta, self.eta)\r\n",
        "            loss_rsr2 = self.rsr2_loss()\r\n",
        "  \r\n",
        "        # Метод gradient вычисляет градиенты обучаемых параметров(весов) для минимизации\r\n",
        "        # функции потерь, используя операции, записанные в контексте этого tape.\r\n",
        "        gradients_ae = tape.gradient(loss_ae, self.trainable_weights)\r\n",
        "        gradients_rsr3 = tape.gradient(loss_rsr3, self.rsr.A)\r\n",
        "        gradients_rsr2 = tape.gradient(loss_rsr2, self.rsr.A)\r\n",
        "\r\n",
        "        # Обновим значения обучаемых переменных - градиентный шаг чтобы min loss.\r\n",
        "        self.optimizer_ae.apply_gradients(grads_and_vars=\r\n",
        "                                          zip(gradients_ae, self.trainable_weights))\r\n",
        "        self.optimizer_rsr1.apply_gradients(grads_and_vars=\r\n",
        "                                            zip([gradients_rsr3], [self.rsr.A]))\r\n",
        "        self.optimizer_rsr2.apply_gradients(grads_and_vars=\r\n",
        "                                            zip([gradients_rsr2], [self.rsr.A]))\r\n",
        "        \r\n",
        "        self.loss_tracker.update_state(loss_ae) # обновляем средний loss по батчам\r\n",
        "\r\n",
        "        self.t_step.assign_add(1, use_locking=True)\r\n",
        "        self.beta.assign(self.beta0.value() * tf.math.log(self.t_step.value() + 3))\r\n",
        "        self.eta.assign(self.eta0.value() * self.t_step.value())\r\n",
        "\r\n",
        "        # Обновляем метрики\r\n",
        "        if len(tf.unique(y)[0]) == 2:\r\n",
        "            # иначе roc_auc_score бросит ValueError и обучение приостановится\r\n",
        "            auc = self.auc_metric(y, cosine_similarity(x_tilde, e))\r\n",
        "            self.auc_tracker.update_state(auc)\r\n",
        "\r\n",
        "        ap = self.ap_metric(y, cosine_similarity(x_tilde, e))\r\n",
        "        self.ap_tracker.update_state(ap)\r\n",
        "\r\n",
        "        del tape # persistent=True => требуется самостоятельно освободить ресурсы\r\n",
        "        return {\"loss\": self.loss_tracker.result(),\r\n",
        "                \"auc\": self.auc_tracker.result(),\r\n",
        "                \"ap\": self.ap_tracker.result(),\r\n",
        "                # \"mean_div\": self.mean_div,\r\n",
        "                # \"min_div\": self.min_div, \r\n",
        "                # \"max_div\": self.max_div,\r\n",
        "                \"beta\": self.beta,\r\n",
        "                \"eta\": self.eta,\r\n",
        "                \"t_step\": self.t_step}\r\n",
        "\r\n",
        "    @property\r\n",
        "    def metrics(self):\r\n",
        "        \"\"\"\r\n",
        "        В пару к train_step. Сбрасывает метрики (`reset_states()`) в начале каждой\r\n",
        "        эпохи обучения с помощью 'fit()'. Без этого свойства 'result()' будет \r\n",
        "        возвращать среднее значение с начала обучения.\r\n",
        "        \"\"\"\r\n",
        "        return [self.loss_tracker, self.auc_tracker, self.ap_tracker]\r\n",
        "\r\n",
        "    def auc_metric(self, y_true, y_pred):\r\n",
        "        return tf.py_function(roc_auc_score, (y_true, y_pred), tf.float64)\r\n",
        "\r\n",
        "    def ap_metric(self, y_true, y_pred):\r\n",
        "        return tf.py_function(average_precision_score, (y_true, y_pred), tf.float64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version = 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy6j-5l3I8K5"
      },
      "source": [
        "## Тренировка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QGvdXlnxI63Y",
        "outputId": "3e691bad-89d7-497b-c30e-9b7e76dd18eb"
      },
      "source": [
        "# Изначальный слой USE\r\n",
        "layer = hub_layer_rus\r\n",
        "\r\n",
        "config = layer.get_config()\r\n",
        "weights = layer.get_weights()\r\n",
        "cloned_layer = type(layer).from_config(config)\r\n",
        "cloned_layer.set_weights(weights)\r\n",
        "\r\n",
        "hub_layer_now = cloned_layer\r\n",
        "\r\n",
        "\r\n",
        "# Тренировка модели\r\n",
        "model_rsrae = RSRAE(inputs_dim=512,\r\n",
        "                    hidden_layer_dimensions=[512, 1024, 2048],\r\n",
        "                    intrinsic_size=20,\r\n",
        "                    activation='relu',\r\n",
        "                    hub_layer=hub_layer_now,\r\n",
        "                    learning_rate=1e-4,\r\n",
        "                    beta=1.0,\r\n",
        "                    eta=0.0015,\r\n",
        "                    ae_loss_norm_type='MSE',\r\n",
        "                    rsr_loss_norm_type='MSE',)\r\n",
        "model_rsrae.compile(run_eagerly=True)\r\n",
        "model_rsrae.fit(x, y,\r\n",
        "                batch_size=16,\r\n",
        "                epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/Transformer/SegmentMean_grad/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/gradients/EncoderTransformer/Transformer/SegmentMean_grad/GatherV2_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/Transformer/SegmentMean_grad/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_1_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_2_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_3_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_3_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_3_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_4_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_4_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_4_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_5_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_5_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_5_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_6_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_6_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_6_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_7_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_7_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_7_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_8_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_8_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_8_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_9_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_9_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_9_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_10_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_10_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_10_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_11_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_11_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_11_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_12_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_12_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_12_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_13_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_13_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_13_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_14_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_14_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_14_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_15_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_15_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_15_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_16_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_16_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_16_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/Transformer/AttentionPooling/UnsortedSegmentSum_grad/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/gradients/EncoderTransformer/Transformer/AttentionPooling/UnsortedSegmentSum_grad/GatherV2_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/Transformer/AttentionPooling/UnsortedSegmentSum_grad/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderTransformer/Transformer/AttentionPooling/UnsortedSegmentSum_1_grad/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/gradients/EncoderTransformer/Transformer/AttentionPooling/UnsortedSegmentSum_1_grad/GatherV2_grad/Reshape:0\", shape=(None, 512), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderTransformer/Transformer/AttentionPooling/UnsortedSegmentSum_1_grad/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float64>\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float64>\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_0/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_1/AdjustDepth/projection/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_2/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/dense/kernel/part_16:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_0:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_1:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_2:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_3:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_4:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_5:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_6:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_7:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_8:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_9:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_10:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_11:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_12:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_13:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_14:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_15:0', 'EncoderDNN/DNN/ResidualHidden_3/AdjustDepth/projection/kernel/part_16:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 2/69 [..............................] - ETA: 10s - loss: 1.0261 - auc: 0.1795 - ap: nan - beta: 1.4979 - eta: 0.0023 - t_step: 1.5000       "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 6/69 [=>............................] - ETA: 11s - loss: 0.9364 - auc: 0.3915 - ap: nan - beta: 1.8350 - eta: 0.0053 - t_step: 3.5000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ca57f892690e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m model_rsrae.fit(x, y,\n\u001b[1;32m     25\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 epochs=10)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    803\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[16,8,845,845] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node zeros_like_75 (defined at <ipython-input-20-7afdb675c01a>:419) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/EncoderTransformer/Transformer/layer_prepostprocess/layer_norm/add_1/_200]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[16,8,845,845] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node zeros_like_75 (defined at <ipython-input-20-7afdb675c01a>:419) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_step_238068]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node zeros_like_75:\n keras_layer/StatefulPartitionedCall (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_hub/keras_layer.py:228)\n\nInput Source operations connected to node zeros_like_75:\n keras_layer/StatefulPartitionedCall (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_hub/keras_layer.py:228)\n\nFunction call stack:\ntrain_step -> train_step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhmZL0gEJBl-"
      },
      "source": [
        "## Тестирование модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hygws44JDDU"
      },
      "source": [
        "# model_rsrae.predict(x) - ВЫДАЕТ НЕПОНЯТНЫЕ ОШИБКИ\r\n",
        "e, _, _, x_predict = model_rsrae.call(x)\r\n",
        "\r\n",
        "auc = roc_auc_score(y, cosine_similarity(x_predict, e))\r\n",
        "ap = average_precision_score(y, cosine_similarity(x_predict, e))\r\n",
        "                                    \r\n",
        "print(\"auc = \", auc)\r\n",
        "print(\"ap = \", ap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFbplby3JDs6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}