{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "СNN+TF_IDF+RSRAE_20newsgroups_example.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC7Kq3lHMNBd"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYmgkGW5LhVO",
        "outputId": "6810e22e-024f-4f9e-a82a-a8ca87ee8e7e"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "\n",
        "c = 0.1  # отношение количества аномальных экземпляров к нормальным\n",
        "\n",
        "# загужаем данные\n",
        "normal_data = fetch_20newsgroups(subset='all', categories=['comp.graphics'],\n",
        "                               shuffle=True, random_state=123, \n",
        "                               remove=['headers', 'footers'], return_X_y=True)[0]\n",
        "anomal_data = fetch_20newsgroups(subset='all', categories=['rec.sport.hockey'],\n",
        "                               shuffle=True, random_state=123,\n",
        "                               remove=['headers', 'footers'],\n",
        "                               return_X_y=True)[0][:int(c * len(normal_data)) + 1]\n",
        "\n",
        "# # приводим к одинаковой длине\n",
        "# min_len = max(len(normal_data), len(anomal_data))\n",
        "# normal_data = normal_data[:min_len]\n",
        "# anomal_data = anomal_data[:min_len]\n",
        "print(\"Количество нормальных экземпляров = {}\".format(len(normal_data)))\n",
        "print(\"Количество аномальных экземпляров = {}\".format(len(anomal_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество нормальных экземпляров = 973\n",
            "Количество аномальных экземпляров = 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svfj5oa7MJQ7"
      },
      "source": [
        "## Предобработка текстовых данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orVDv2w4MCXH",
        "outputId": "0dfcb118-b98c-4f4e-d45a-a86283ea3fcd"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.parsing.preprocessing import strip_short\n",
        "from gensim.parsing.preprocessing import strip_non_alphanum\n",
        "from gensim.parsing.preprocessing import strip_numeric\n",
        "from gensim.utils import tokenize\n",
        "import nltk; nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "def strip_html_tags(text):\n",
        "    \"\"\"Удаление html tags из текста.\"\"\"\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    stripped_text = soup.get_text(separator=\" \")\n",
        "    return stripped_text\n",
        "\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = strip_html_tags(text)  # удаление html tags\n",
        "    text = strip_non_alphanum(text) # заменили все небуквенные символы на пробел\n",
        "    text = strip_numeric(text) # удалили все цифры\n",
        "    text = remove_stopwords(text) # удалили все стоп-слова\n",
        "    # text = strip_short(text, minsize=2) # удалили короткие слова\n",
        "    word_list = list(tokenize(text, deacc=True, to_lower=True)) # токенизация, deacc - избавляет от ударений\n",
        "    word_list = [WordNetLemmatizer().lemmatize(word) for word in word_list] # лемматизация\n",
        "    return ' '.join(word for word in word_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mPZjfpXMVJF"
      },
      "source": [
        "normal_data = [preprocess_text(text) for text in normal_data]\n",
        "anomal_data = [preprocess_text(text) for text in anomal_data]\n",
        "all_data = normal_data + anomal_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rar8q1p5MVnn",
        "outputId": "9a47780f-5391-4b3d-ae0a-da9e7c168466"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "len_all_data = np.array([len(text.split(' ')) for text in all_data])\n",
        "# print(len(len_all_data[len_all_data <= 150]))\n",
        "print(\"mean length of sentence: \" + str(len_all_data.mean()))\n",
        "print(\"max length of sentence: \" + str(len_all_data.max()))\n",
        "print(\"std dev length of sentence: \" + str(len_all_data.std()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean length of sentence: 139.71615312791783\n",
            "max length of sentence: 6264\n",
            "std dev length of sentence: 521.7326013321044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOwAuraz2F1-"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alInBxb6PA6s"
      },
      "source": [
        "# from sklearn.feature_extraction.text import HashingVectorizer\n",
        "# from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# h_vectorizer = HashingVectorizer(ngram_range=(1, 1))\n",
        "# all_data_counts = h_vectorizer.fit_transform(all_data)\n",
        "# tf_transformer = TfidfTransformer(use_idf=True).fit(all_data_counts)\n",
        "# all_data_tf = tf_transformer.transform(all_data_counts).toarray()\n",
        "\n",
        "# print(all_data_tf.shape)\n",
        "# print(all_data_tf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EVOLW811LWn",
        "outputId": "581f1c60-fcf3-4f72-cbe4-47b65e5f84ab"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "all_data_tf = vectorizer.fit_transform(all_data).toarray()\n",
        "\n",
        "print(type(all_data_tf))\n",
        "print(all_data_tf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(1071, 13691)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsK3-rVC2f60"
      },
      "source": [
        "## Формирование выборок"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBdCv-uRM7v0",
        "outputId": "7a387b03-ae57-43f3-9652-7af81ffdc2d9"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "x = all_data_tf\n",
        "y = np.array([False] * len(normal_data) + [True] * len(anomal_data))\n",
        "\n",
        "all_data, x, y = shuffle(all_data, x, y, random_state=123)\n",
        "print(\"Всего экземпляров = {}\".format(len(all_data)))\n",
        "print(\"(Кол-во текстов, число признаков текста) = {}\".format(x.shape))\n",
        "print(\"Кол-во меток = {}\".format(len(y)))\n",
        "print(\"Кол-во нормальных экземпляров = {}\".format(len(normal_data)))\n",
        "print(\"Кол-во аномальных экземпляров = {}\".format(len(anomal_data)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Всего экземпляров = 1071\n",
            "(Кол-во текстов, число признаков текста) = (1071, 13691)\n",
            "Кол-во меток = 1071\n",
            "Кол-во нормальных экземпляров = 973\n",
            "Кол-во аномальных экземпляров = 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0MuCDL947Yx"
      },
      "source": [
        "## Функция Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXSYXbdS47GV"
      },
      "source": [
        "def cosine_similarity(x_predict, x):\n",
        "    if type(x_predict) is np.ndarray:\n",
        "        flat_output = x_predict\n",
        "        flat_input = x_predict\n",
        "        # flat_output = np.reshape(x_predict, (np.shape(x)[0], -1))\n",
        "        # flat_input = np.reshape(x_predict, (np.shape(x)[0], -1))\n",
        "        sum = np.sum(flat_output * flat_input, -1)\n",
        "        norm1 = np.linalg.norm(flat_output, axis=-1) + 0.000001\n",
        "        norm2 = np.linalg.norm(flat_input, axis=-1) + 0.000001 \n",
        "        return -(sum / norm1 / norm2)\n",
        "    else:\n",
        "        # ДЛЯ НЕ ПОЛНОСВЯЗНЫХ СЛОЕВ НУЖЕН ДРУГОЙ shape\n",
        "        flat_output = x_predict\n",
        "        flat_input = x_predict\n",
        "        # flat_output = tf.reshape(tensor=x_predict, shape=[x.shape.as_list()[0], -1])\n",
        "        # flat_input = tf.reshape(tensor=x_predict, shape=[x.shape.as_list()[0], -1])\n",
        "        sum = tf.math.reduce_sum(tf.math.multiply(flat_output, flat_input), axis=-1)\n",
        "        norm1 = tf.norm(flat_output, axis=-1) + 0.000001\n",
        "        norm2 = tf.norm(flat_input, axis=-1) + 0.000001\n",
        "        return -(tf.math.divide(tf.math.divide(sum, norm1), norm2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eVyaW7_5AW3"
      },
      "source": [
        "## RSRAE model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBVNmgjX4EpR",
        "outputId": "b1803bb6-224a-42d8-c219-817cc16b7db5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "print(\"Tensorflow version = {}\".format(tf.__version__)) # текущая версия tf\n",
        "\n",
        "from tensorflow.keras import Model, optimizers, metrics\n",
        "from tensorflow.keras.layers import Layer, Flatten, Dense, BatchNormalization, Dropout\n",
        "\n",
        "# from tensorflow.keras import activations, Sequential, Input\n",
        "# from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Reshape\n",
        "# from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "# Задаем random_seed для tensorflow и numpy\n",
        "random_seed = 123\n",
        "tf.random.set_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Sets the default float type\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(123)\n",
        "np.random.seed(123)\n",
        "\n",
        "\n",
        "class RSR(Layer):\n",
        "    \"\"\"\n",
        "    Robust Subspace Recovery (RSR) layer.\n",
        "    Робастный слой, восстанавливающий подпространство. Задача данного слоя - отобразить\n",
        "    закодированные энкодером данные в подпростраство так, чтобы после их обратного\n",
        "    отображения декодером дивергенция между экземпляром исходных данных и его образом,\n",
        "    полученным от автоэнкодера была незначительной для нормального экземпляра и была\n",
        "    большой для аномального экземпляра. \n",
        "\n",
        "    # Example\n",
        "    ```\n",
        "        z_rsr, A = RSR(intrinsic_size=10)(z)\n",
        "    ```\n",
        "    # Arguments\n",
        "        intrinsic_size: размерность z_rsr.\n",
        "    # Input shape\n",
        "        2D tensor with shape: `(n_samples, n_features)` after encoding.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(n_samples, intrinsic_size)`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, intrinsic_size: int, name=\"RSR_layer\", **kwargs):\n",
        "        super(RSR, self).__init__(name=name, **kwargs)\n",
        "        # Если присваивать экземпляр слоя, как атрибут другого слоя, то хорошей\n",
        "        # практикой делать создавать такие подслои в __init__ (поскольку подслои обычно\n",
        "        # имеют метод build, они будут собраны, когда будет собран внешний слой). \n",
        "        self.flatten = Flatten()\n",
        "        self.intrinsic_size = intrinsic_size\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Определяет веса слоя, а именно задает матрицу A.\"\"\"\n",
        "        self.A = self.add_weight(name=\"A\",\n",
        "                                 shape=[int(input_shape[-1]), self.intrinsic_size],\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=True,)\n",
        "        \n",
        "        # self.V = self.add_weight(name=\"V\",\n",
        "        #                          shape=[int(input_shape[-1]), 1],\n",
        "        #                          initializer='random_normal',\n",
        "        #                          trainable=True,)\n",
        "        \n",
        "    def call(self, z):\n",
        "        \"\"\"\n",
        "        Логика слоя. Умножение выхода энкодера - вектора z на матрицу A.\n",
        "        Возвращает отображенный z_rsr и матрицу A, которая потребуется далее.\n",
        "        \"\"\"\n",
        "        z = self.flatten(z)\n",
        "        # print(\"z.shpae Before A:\", z.shape)\n",
        "        z_rsr = tf.linalg.matmul(z, self.A)\n",
        "        # print(\"z_rsr.shpae After A:\", z_rsr.shape) \n",
        "        return z_rsr\n",
        "\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \n",
        "    # get_config и метода класса (@classmethod) from_config.\n",
        "    def get_config(self):\n",
        "        config = super(Layer, self).get_config()\n",
        "        config.update({'intrinsic_size': self.intrinsic_size})\n",
        "        return config\n",
        "\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class L2Normalization(Layer):\n",
        "    \"\"\"Слой для l_2 нормализации, который будет применяться к выходу RSR layer.\"\"\"\n",
        "    \n",
        "    def __init__(self, name=\"L2Normalization\", **kwargs):\n",
        "        super(L2Normalization, self).__init__(name=name, **kwargs)\n",
        "\n",
        "    def call(self, z_rsr):\n",
        "        \"\"\"\n",
        "        Выполняет l_2 нормализацию векторов, полученных после применения RSR layer\n",
        "        вдоль оси, соответсвующей числу признаков. То есть производится нормализация\n",
        "        каждого экземпляра выборки, в результате которой признаки экземпляров будут\n",
        "        находиться в отрезке [-1; 1].\n",
        "        \"\"\"\n",
        "        z_tilde = tf.math.l2_normalize(z_rsr, axis=-1)\n",
        "        return z_tilde\n",
        "\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \n",
        "    # get_config и метода класса (@classmethod) from_config.\n",
        "    def get_config(self):\n",
        "        config = super(Layer, self).get_config()\n",
        "        return config\n",
        "\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class Encoder(Layer):\n",
        "    \"\"\"\n",
        "    Класс для encoder модели RSRAE. Отображает исходные данные input_data в вектор z,\n",
        "    кодирующий исходные данные.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 hidden_layer_dimensions,\n",
        "                 activation,\n",
        "                 flag_bn=True, \n",
        "                 name=\"Encoder\",\n",
        "                 **kwargs):\n",
        "        super(Encoder, self).__init__(name=name, **kwargs)\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\n",
        "        self.activation = activation\n",
        "        self.flag_bn = flag_bn\n",
        "        self.dense0 = Dense(hidden_layer_dimensions[0], activation=activation,\n",
        "                            name='encoder_0')\n",
        "        self.dense1 = Dense(hidden_layer_dimensions[1], activation=activation,\n",
        "                            name='encoder_1')\n",
        "        self.dense2 = Dense(hidden_layer_dimensions[2], activation=activation,\n",
        "                            name='encoder_2')\n",
        "        if flag_bn:\n",
        "            self.batch_normalization0 = BatchNormalization(name=\"encoder_bn_layer_0\")\n",
        "            self.batch_normalization1 = BatchNormalization(name=\"encoder_bn_layer_1\")\n",
        "            self.batch_normalization2 = BatchNormalization(name=\"encoder_bn_layer_2\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Отображние исходных данных x -> в закодированный вектор z.\"\"\"\n",
        "        x = inputs\n",
        "        x = self.dense0(x)\n",
        "        if self.flag_bn:\n",
        "            x = self.batch_normalization0(x)\n",
        "        x = self.dense1(x)\n",
        "        if self.flag_bn:\n",
        "            x = self.batch_normalization1(x)\n",
        "        x = Dropout(0.2)((x))\n",
        "        x = self.dense2(x)\n",
        "        if self.flag_bn:\n",
        "            x = self.batch_normalization2(x)\n",
        "        x = Dropout(0.3)((x))    \n",
        "        z = x\n",
        "        return z\n",
        "    \n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \n",
        "    # get_config и метода класса (@classmethod) from_config.\n",
        "    def get_config(self):\n",
        "        config = super(Layer, self).get_config()\n",
        "        config.update({'hidden_layer_dimensions': self.hidden_layer_dimensions})\n",
        "        config.update({'activation': self.activation})\n",
        "        config.update({'flag_bn': self.flag_bn})\n",
        "        return config\n",
        "\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class Decoder(Layer):\n",
        "    \"\"\"\n",
        "    Класс для decoder модели RSRAE. Отображает вектор z_rsr, полученный в результате\n",
        "    кодирования исходных данных в вектор z, и последующим отображением вектора z при\n",
        "    помощи RSR layer (x -> z -> z_rsr), обратно в пространство исходных данных \n",
        "    (z_rsr -> x_tilde).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 inputs_dim,\n",
        "                 hidden_layer_dimensions,\n",
        "                 activation,\n",
        "                 flag_bn=True, \n",
        "                 name=\"Decoder\",\n",
        "                 **kwargs):\n",
        "        super(Decoder, self).__init__(name=name, **kwargs)\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\n",
        "        self.activation = activation\n",
        "        self.flag_bn = flag_bn\n",
        "        self.dense2 = Dense(hidden_layer_dimensions[2], activation=activation,\n",
        "                            name='decoder_2')\n",
        "        self.dense1 = Dense(hidden_layer_dimensions[1], activation=activation,\n",
        "                            name='decoder_1')\n",
        "        self.dense0 = Dense(hidden_layer_dimensions[0], activation=activation,\n",
        "                            name='decoder_0')\n",
        "        self.dense_output = Dense(inputs_dim, activation=activation,\n",
        "                            name='decoder_output')\n",
        "        if flag_bn:\n",
        "            self.batch_normalization2 = BatchNormalization(name=\"decoder_bn_layer_2\")\n",
        "            self.batch_normalization1 = BatchNormalization(name=\"decoder_bn_layer_1\")\n",
        "            self.batch_normalization0 = BatchNormalization(name=\"decoder_bn_layer_0\")\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Отображние z_rsr -> x_tilde, где x_tilde - вектор, лежащий в пространстве\n",
        "        исходных даных.\n",
        "        \"\"\"\n",
        "        z_rsr = inputs\n",
        "        z_rsr = self.dense2(z_rsr)\n",
        "        if self.flag_bn:\n",
        "            z_rsr = self.batch_normalization2(z_rsr)\n",
        "        z_rsr = Dropout(0.4)((z_rsr))\n",
        "        z_rsr = self.dense1(z_rsr)\n",
        "        if self.flag_bn:\n",
        "            z_rsr = self.batch_normalization1(z_rsr)\n",
        "        z_rsr = Dropout(0.5)((z_rsr))\n",
        "        z_rsr = self.dense0(z_rsr)\n",
        "        if self.flag_bn:\n",
        "            z_rsr = self.batch_normalization0(z_rsr)\n",
        "        z_rsr = Dropout(0.5)((z_rsr))\n",
        "        x_tilde = self.dense_output(z_rsr)\n",
        "        return x_tilde\n",
        "    \n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \n",
        "    # get_config и метода класса (@classmethod) from_config.\n",
        "    def get_config(self):\n",
        "        config = super(Layer, self).get_config()\n",
        "        config.update({'hidden_layer_dimensions': self.hidden_layer_dimensions})\n",
        "        config.update({'activation': self.activation})\n",
        "        config.update({'flag_bn': self.flag_bn})\n",
        "        return config\n",
        "\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class RSRAE(Model):\n",
        "    \"\"\"\n",
        "    Нейросетевая модель-автоэнкодер для обнаружения аномалий с робастным слоем,\n",
        "    восстанавливающим подпространство (RSR layer между encoder и decoder).\n",
        "    Комбинируем encoder + RSR layer + decoder в end-to-end модель.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 inputs_dim, # размерность вектора признаков\n",
        "                 hidden_layer_dimensions,\n",
        "                 intrinsic_size, # разерность z_rsr после RSR layer\n",
        "                 activation,\n",
        "                 flag_loss,\n",
        "                 flag_bn=True,\n",
        "                 flag_normalize=True,\n",
        "                 learning_rate=1e-3,\n",
        "                 beta=1,\n",
        "                 eta=1,\n",
        "                 t_step=0,\n",
        "                 ae_loss_norm_type='MSE',\n",
        "                 rsr_loss_norm_type='MSE',\n",
        "                 name='RSRAE',\n",
        "                 **kwargs):\n",
        "        super(RSRAE, self).__init__(name=name, **kwargs)\n",
        "        self.inputs_dim = inputs_dim\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\n",
        "        self.intrinsic_size = intrinsic_size\n",
        "        self.activation = activation\n",
        "        self.flag_bn = flag_bn\n",
        "        self.flag_normalize = flag_normalize\n",
        "        self.flag_loss = flag_loss\n",
        "        self.learning_rate = learning_rate\n",
        "        self.beta = tf.Variable(beta, dtype=tf.float64, trainable=False)\n",
        "        self.beta0 = tf.Variable(beta, dtype=tf.float64, trainable=False)\n",
        "        self.eta = tf.Variable(eta, dtype=tf.float64, trainable=False)\n",
        "        self.eta0 = tf.Variable(eta, dtype=tf.float64, trainable=False)\n",
        "        self.t_step = tf.Variable(t_step, dtype=tf.float64, trainable=False)\n",
        "        self.ae_loss_norm_type = ae_loss_norm_type\n",
        "        self.rsr_loss_norm_type = rsr_loss_norm_type\n",
        "        # Для вычисления среднего loss по loss всех батчей в эпохе\n",
        "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
        "        self.auc_tracker = metrics.Mean(name=\"auc\")\n",
        "        self.ap_tracker = metrics.Mean(name=\"ap\")\n",
        "\n",
        "        # Создание экземпляров оптимизаторов\n",
        "        self.optimizer_ae = optimizers.Adam(learning_rate=learning_rate)\n",
        "        self.optimizer_rsr1 = optimizers.Adam(learning_rate=5 * learning_rate)\n",
        "        self.optimizer_rsr2 = optimizers.Adam(learning_rate=5 * learning_rate)\n",
        "\n",
        "        # Слои\n",
        "        # self.emnedding_layer = hub_layer\n",
        "        self.encoder = Encoder(hidden_layer_dimensions=hidden_layer_dimensions,\n",
        "                               activation=activation,\n",
        "                               flag_bn=flag_bn)\n",
        "        self.rsr = RSR(intrinsic_size=intrinsic_size)\n",
        "        if flag_normalize:\n",
        "            self.l2normalization = L2Normalization()\n",
        "        self.decoder = Decoder(inputs_dim=inputs_dim,\n",
        "                               hidden_layer_dimensions=hidden_layer_dimensions,\n",
        "                               activation=activation,\n",
        "                               flag_bn=flag_bn)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # e = self.emnedding_layer(inputs)\n",
        "        e = inputs\n",
        "        e = tf.cast(e, dtype=tf.float64)\n",
        "        z = self.encoder(e)\n",
        "        z_rsr = self.rsr(z)\n",
        "        if self.flag_normalize:\n",
        "            z_rsr = self.l2normalization(z_rsr)\n",
        "        x_tilde = self.decoder(z_rsr)\n",
        "        return e, z, z_rsr, x_tilde\n",
        "\n",
        "    def ae_loss(self, x, x_tilde):\n",
        "        \"\"\"Функция потерь реконструкции автоэнкодера - L_AE.\"\"\"\n",
        "\n",
        "        x = tf.reshape(x, (tf.shape(x)[0], -1))\n",
        "        x_tilde = tf.reshape(x_tilde, (tf.shape(x_tilde)[0], -1))\n",
        "\n",
        "        # axis=1 для tf.norm => вычисление вдоль оси признаков\n",
        "        # tf.math.reduce_mean без параметров - mean от элементов матрицы\n",
        "        if self.ae_loss_norm_type in ['MSE', 'mse', 'Frob', 'F']:\n",
        "            return tf.math.reduce_mean(tf.math.square(tf.norm(x-x_tilde, \n",
        "                                                              ord=2, axis=1)))\n",
        "        elif self.ae_loss_norm_type in ['L1', 'l1']:\n",
        "            return tf.math.reduce_mean(tf.norm(x-x_tilde, ord=1, axis=1))\n",
        "        elif self.ae_loss_norm_type in ['LAD', 'lad', 'L21', 'l21', 'L2', 'l2']:\n",
        "            return tf.math.reduce_mean(tf.norm(x-x_tilde, ord=2, axis=1))\n",
        "        else:\n",
        "            raise Exception(\"Norm type error!\")\n",
        "    \n",
        "    def rsr1_loss(self, z, z_rsr, beta, eta):\n",
        "        \"\"\"Функция потери для RSR layer - L_RSR1.\"\"\"\n",
        "        z_rsr = tf.matmul(z_rsr, tf.transpose(self.rsr.A))\n",
        "        # z_rsr_new = tf.matmul(z_rsr, self.)\n",
        "\n",
        "        if self.rsr_loss_norm_type in ['MSE', 'mse', 'Frob', 'F']:\n",
        "            return tf.math.reduce_mean(tf.math.square(tf.norm(z-z_rsr, ord=2, \n",
        "                                                            axis=1)))\n",
        "        elif self.rsr_loss_norm_type in ['L1', 'l1']:\n",
        "            return tf.math.reduce_mean(tf.norm(z-z_rsr, ord=1, axis=1))\n",
        "        elif self.rsr_loss_norm_type in ['LAD', 'lad', 'L21', 'l21', 'L2', 'l2']:\n",
        "            return tf.math.reduce_mean(tf.norm(z-z_rsr, ord=2, axis=1))\n",
        "        else:\n",
        "            raise Exception(\"Norm type error!\")\n",
        "    \n",
        "    def rsr2_loss(self):\n",
        "        \"\"\"Функция потери для RSR layer - L_RSR2.\"\"\"\n",
        "        A = self.rsr.A\n",
        "        A_T = tf.transpose(A)\n",
        "        I = tf.eye(self.intrinsic_size, dtype=tf.float64)\n",
        "        return tf.math.reduce_mean(tf.math.square(tf.linalg.matmul(A_T, A) - I))\n",
        "\n",
        "    def rsr3_loss(self, z, z_rsr, beta, eta):\n",
        "        \"\"\"\n",
        "        Cтатьи 'Robust principal component analysis by \n",
        "        self-organizing rules basedon statistical physics approach', на которую\n",
        "        ссылается http://files.is.tue.mpg.de/black/papers/delatorreIJCV03.pdf\n",
        "        \"\"\"\n",
        "        z_rsr = tf.matmul(z_rsr, tf.transpose(self.rsr.A))  # AA'z\n",
        "        e_pca = tf.math.square(tf.norm(z-z_rsr, ord=2, axis=1))\n",
        "        # self.min_div = tf.reduce_min(e_pca)\n",
        "        # self.max_div = tf.reduce_max(e_pca)\n",
        "        # self.mean_div = tf.reduce_mean(e_pca)\n",
        "        loss = -1 * tf.math.reduce_mean(tf.math.log(1 + tf.math.exp(-beta * e_pca - eta))) / beta\n",
        "        return loss\n",
        "        \n",
        "    def gradients(model, inputs, targets):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss_value = loss_fn(model, inputs, targets)\n",
        "        return tape.gradient(loss_value, model.trainable_variables)\n",
        "    \n",
        "    @tf.function()\n",
        "    def train_step(self, data):\n",
        "        \"\"\"\n",
        "        Override the method. Будет вызываться при 'model.fit()'.\n",
        "        Один шаг обучения, на котором вычисляются функции потерь для автоэнкодера и\n",
        "        RSR layer, и в соотвествии с ними обновляются значения обучаемых переменных - \n",
        "        весов нейросети и матрицы A соответсвенно. Будет вызываться от одного батча.\n",
        "        Заметим, что в этом методе мы используем пользовательские оптимизаторы и функции\n",
        "        потерь, поэтому перед тренировкой метод compile вызывать не придется.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        x, y = data\n",
        "\n",
        "        # tf.GradientTape() - записывает операции для автоматического дифференцирования\n",
        "\n",
        "        # По умолчанию persistent=False и удерживаемые GradientTape, высвобождаются,\n",
        "        # как только вызывается метод GradientTape.gradient(). Чтобы вычислить несколько\n",
        "        # градиентов за одно вычисление, требуется задать persistent=true. Это позволяет\n",
        "        # многократно вызывать метод gradient(), тогда требуется самостоятельно\n",
        "        # освободить ресурсы с помощью 'del tape'.\n",
        "\n",
        "        # watch_accessed_variables=True => автоматическое отслеживание всех обучаемых\n",
        "        # переменные, к которым осуществляется доступ. Так градиенты могут быть\n",
        "        # запрошены c любого вычисленного результата в tape.\n",
        "        with tf.GradientTape(persistent=True, watch_accessed_variables=True) as tape:\n",
        "            # Здесь требуется запустить прямой проход нейросети. Операции применяемые\n",
        "            # при проходе к входных данным будут записаны на GradientTape. \n",
        "            e, z, z_rsr, x_tilde = self.call(x) # прямой проход RSRAE\n",
        "            z = tf.keras.layers.Flatten()(z) # вроде для текстовых данных необязательно\n",
        "            # Вычисляем значения функций потерь для этого прохода\n",
        "            loss_ae = self.ae_loss(e, x_tilde)\n",
        "            if (self.flag_loss == 0):\n",
        "                loss_rsr3 = self.rsr1_loss(z, z_rsr, self.beta, self.eta)\n",
        "            else:\n",
        "                loss_rsr3 = self.rsr3_loss(z, z_rsr, self.beta, self.eta)\n",
        "            loss_rsr2 = self.rsr2_loss()\n",
        "  \n",
        "        # Метод gradient вычисляет градиенты обучаемых параметров(весов) для минимизации\n",
        "        # функции потерь, используя операции, записанные в контексте этого tape.\n",
        "        gradients_ae = tape.gradient(loss_ae, self.trainable_weights)\n",
        "        gradients_rsr3 = tape.gradient(loss_rsr3, self.rsr.A)\n",
        "        gradients_rsr2 = tape.gradient(loss_rsr2, self.rsr.A)\n",
        "\n",
        "        # Обновим значения обучаемых переменных - градиентный шаг чтобы min loss.\n",
        "        self.optimizer_ae.apply_gradients(grads_and_vars=\n",
        "                                          zip(gradients_ae, self.trainable_weights))\n",
        "        self.optimizer_rsr1.apply_gradients(grads_and_vars=\n",
        "                                            zip([gradients_rsr3], [self.rsr.A]))\n",
        "        self.optimizer_rsr2.apply_gradients(grads_and_vars=\n",
        "                                            zip([gradients_rsr2], [self.rsr.A]))\n",
        "        \n",
        "        self.loss_tracker.update_state(loss_ae) # обновляем средний loss по батчам\n",
        "\n",
        "        self.t_step.assign_add(1, use_locking=True)\n",
        "        self.beta.assign(self.beta0.value() * tf.math.log(self.t_step.value() + 3))\n",
        "        self.eta.assign(self.eta0.value() * self.t_step.value())\n",
        "\n",
        "        # Обновляем метрики\n",
        "        if len(tf.unique(y)[0]) == 2:\n",
        "            # иначе roc_auc_score бросит ValueError и обучение приостановится\n",
        "            auc = self.auc_metric(y, cosine_similarity(x_tilde, e))\n",
        "            self.auc_tracker.update_state(auc)\n",
        "\n",
        "        ap = self.ap_metric(y, cosine_similarity(x_tilde, e))\n",
        "        self.ap_tracker.update_state(ap)\n",
        "\n",
        "        del tape # persistent=True => требуется самостоятельно освободить ресурсы\n",
        "        return {\"loss\": self.loss_tracker.result(),\n",
        "                \"auc\": self.auc_tracker.result(),\n",
        "                \"ap\": self.ap_tracker.result(),\n",
        "                # \"mean_div\": self.mean_div,\n",
        "                # \"min_div\": self.min_div, \n",
        "                # \"max_div\": self.max_div,\n",
        "                \"beta\": self.beta,\n",
        "                \"eta\": self.eta,\n",
        "                \"t_step\": self.t_step}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        \"\"\"\n",
        "        В пару к train_step. Сбрасывает метрики (`reset_states()`) в начале каждой\n",
        "        эпохи обучения с помощью 'fit()'. Без этого свойства 'result()' будет \n",
        "        возвращать среднее значение с начала обучения.\n",
        "        \"\"\"\n",
        "        return [self.loss_tracker, self.auc_tracker, self.ap_tracker]\n",
        "\n",
        "    def auc_metric(self, y_true, y_pred):\n",
        "        return tf.py_function(roc_auc_score, (y_true, y_pred), tf.float64)\n",
        "\n",
        "    def ap_metric(self, y_true, y_pred):\n",
        "        return tf.py_function(average_precision_score, (y_true, y_pred), tf.float64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version = 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zw6_gDz5InT"
      },
      "source": [
        "## Тренировка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGDTtcOK5DSQ",
        "outputId": "086271af-c030-4486-b972-b2161ddbbea1"
      },
      "source": [
        "# Тренировка модели\n",
        "model_rsrae = RSRAE(inputs_dim=x.shape[1],\n",
        "                    hidden_layer_dimensions=[1024, 2048, 4096],\n",
        "                    intrinsic_size=25,\n",
        "                    activation='relu',\n",
        "                    flag_loss=0,\n",
        "                    learning_rate=1e-4,\n",
        "                    beta=1.0,\n",
        "                    eta=0.0015,\n",
        "                    ae_loss_norm_type='MSE',\n",
        "                    rsr_loss_norm_type='MSE',)\n",
        "model_rsrae.compile(run_eagerly=True)\n",
        "model_rsrae.fit(x, y,\n",
        "                batch_size=512,\n",
        "                epochs=17)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/17\n",
            "3/3 [==============================] - 5s 646ms/step - loss: 1.0357 - auc: 0.5304 - ap: 0.1017 - beta: 1.6448 - eta: 0.0034 - t_step: 2.2500\n",
            "Epoch 2/17\n",
            "3/3 [==============================] - 1s 155ms/step - loss: 0.9804 - auc: 0.3946 - ap: 0.0709 - beta: 2.1050 - eta: 0.0079 - t_step: 5.2500\n",
            "Epoch 3/17\n",
            "3/3 [==============================] - 0s 145ms/step - loss: 0.9840 - auc: 0.6221 - ap: 0.1783 - beta: 2.4176 - eta: 0.0124 - t_step: 8.2500\n",
            "Epoch 4/17\n",
            "3/3 [==============================] - 1s 150ms/step - loss: 0.9869 - auc: 0.6285 - ap: 0.1852 - beta: 2.6550 - eta: 0.0169 - t_step: 11.2500\n",
            "Epoch 5/17\n",
            "3/3 [==============================] - 1s 152ms/step - loss: 0.9843 - auc: 0.6451 - ap: 0.2176 - beta: 2.8466 - eta: 0.0214 - t_step: 14.2500\n",
            "Epoch 6/17\n",
            "3/3 [==============================] - 1s 160ms/step - loss: 0.9819 - auc: 0.6319 - ap: 0.1507 - beta: 3.0073 - eta: 0.0259 - t_step: 17.2500\n",
            "Epoch 7/17\n",
            "3/3 [==============================] - 1s 156ms/step - loss: 0.9806 - auc: 0.7464 - ap: 0.2073 - beta: 3.1457 - eta: 0.0304 - t_step: 20.2500\n",
            "Epoch 8/17\n",
            "3/3 [==============================] - 1s 155ms/step - loss: 0.9798 - auc: 0.7844 - ap: 0.3433 - beta: 3.2672 - eta: 0.0349 - t_step: 23.2500\n",
            "Epoch 9/17\n",
            "3/3 [==============================] - 1s 155ms/step - loss: 0.9662 - auc: 0.8658 - ap: 0.4905 - beta: 3.3755 - eta: 0.0394 - t_step: 26.2500\n",
            "Epoch 10/17\n",
            "3/3 [==============================] - 1s 153ms/step - loss: 0.9705 - auc: 0.8860 - ap: 0.5423 - beta: 3.4732 - eta: 0.0439 - t_step: 29.2500\n",
            "Epoch 11/17\n",
            "3/3 [==============================] - 1s 151ms/step - loss: 0.9771 - auc: 0.9203 - ap: 0.5224 - beta: 3.5622 - eta: 0.0484 - t_step: 32.2500\n",
            "Epoch 12/17\n",
            "3/3 [==============================] - 1s 159ms/step - loss: 0.9756 - auc: 0.9329 - ap: 0.5748 - beta: 3.6439 - eta: 0.0529 - t_step: 35.2500\n",
            "Epoch 13/17\n",
            "3/3 [==============================] - 1s 157ms/step - loss: 0.9780 - auc: 0.9195 - ap: 0.6263 - beta: 3.7194 - eta: 0.0574 - t_step: 38.2500\n",
            "Epoch 14/17\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.9755 - auc: 0.9135 - ap: 0.6316 - beta: 3.7897 - eta: 0.0619 - t_step: 41.2500\n",
            "Epoch 15/17\n",
            "3/3 [==============================] - 1s 153ms/step - loss: 0.9743 - auc: 0.9425 - ap: 0.6426 - beta: 3.8553 - eta: 0.0664 - t_step: 44.2500\n",
            "Epoch 16/17\n",
            "3/3 [==============================] - 1s 146ms/step - loss: 0.9738 - auc: 0.9575 - ap: 0.7434 - beta: 3.9169 - eta: 0.0709 - t_step: 47.2500\n",
            "Epoch 17/17\n",
            "3/3 [==============================] - 1s 145ms/step - loss: 0.9732 - auc: 0.9668 - ap: 0.7084 - beta: 3.9749 - eta: 0.0754 - t_step: 50.2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8e2d3f0150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3REsfg0X5LA9",
        "outputId": "1ebbf7e1-32ce-4393-fe20-267f11583d72"
      },
      "source": [
        "x_predict = model_rsrae.predict(x)[3]\n",
        "\n",
        "auc = roc_auc_score(y, cosine_similarity(x_predict, x))\n",
        "ap = average_precision_score(y, cosine_similarity(x_predict, x))\n",
        "                                    \n",
        "print(\"auc = \", auc)\n",
        "print(\"ap = \", ap)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auc =  0.9661891478071187\n",
            "ap =  0.7223521132436789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAkD0bMqxHGN"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20qAMxGOxJFJ",
        "outputId": "a3c10b8e-ddfb-4c4a-bbc1-7cf4492260c2"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "\n",
        "c = 0.1  # отношение количества аномальных экземпляров к нормальным\n",
        "\n",
        "# загужаем данные\n",
        "normal_data = fetch_20newsgroups(subset='all', categories=['comp.graphics'],\n",
        "                               shuffle=True, random_state=123, \n",
        "                               remove=['headers', 'footers'], return_X_y=True)[0]\n",
        "anomal_data = fetch_20newsgroups(subset='all', categories=['rec.sport.hockey'],\n",
        "                               shuffle=True, random_state=123,\n",
        "                               remove=['headers', 'footers'],\n",
        "                               return_X_y=True)[0][:int(c * len(normal_data)) + 1]\n",
        "\n",
        "# # приводим к одинаковой длине\n",
        "# min_len = max(len(normal_data), len(anomal_data))\n",
        "# normal_data = normal_data[:min_len]\n",
        "# anomal_data = anomal_data[:min_len]\n",
        "print(\"Количество нормальных экземпляров = {}\".format(len(normal_data)))\n",
        "print(\"Количество аномальных экземпляров = {}\".format(len(anomal_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Количество нормальных экземпляров = 973\n",
            "Количество аномальных экземпляров = 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIM8_-ZVxuaY",
        "outputId": "6a569720-c670-407c-c0d0-0f2bf0299420"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.parsing.preprocessing import strip_short\n",
        "from gensim.parsing.preprocessing import strip_non_alphanum\n",
        "from gensim.parsing.preprocessing import strip_numeric\n",
        "from gensim.utils import tokenize\n",
        "import nltk; nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "def strip_html_tags(text):\n",
        "    \"\"\"Удаление html tags из текста.\"\"\"\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    stripped_text = soup.get_text(separator=\" \")\n",
        "    return stripped_text\n",
        "\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = strip_html_tags(text)  # удаление html tags\n",
        "    text = strip_non_alphanum(text) # заменили все небуквенные символы на пробел\n",
        "    text = strip_numeric(text) # удалили все цифры\n",
        "    text = remove_stopwords(text) # удалили все стоп-слова\n",
        "    # text = strip_short(text, minsize=2) # удалили короткие слова\n",
        "    word_list = list(tokenize(text, deacc=True, to_lower=True)) # токенизация, deacc - избавляет от ударений\n",
        "    word_list = [WordNetLemmatizer().lemmatize(word) for word in word_list] # лемматизация\n",
        "    return ' '.join(word for word in word_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP6a9K_ExxMm"
      },
      "source": [
        "normal_data = [preprocess_text(text) for text in normal_data]\n",
        "anomal_data = [preprocess_text(text) for text in anomal_data]\n",
        "all_data = normal_data + anomal_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8NgdaMTx2D4",
        "outputId": "8c7086a6-09e1-4bff-af02-4d29569004ac"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "all_data_tf = vectorizer.fit_transform(all_data).toarray()\n",
        "\n",
        "print(type(all_data_tf))\n",
        "print(all_data_tf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(1071, 13691)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-5jCGXTx7zh",
        "outputId": "af3e94f6-1981-4012-b38d-8f7579167a84"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "x = all_data_tf\n",
        "y = np.array([False] * len(normal_data) + [True] * len(anomal_data))\n",
        "\n",
        "all_data, x, y = shuffle(all_data, x, y, random_state=123)\n",
        "print(\"Всего экземпляров = {}\".format(len(all_data)))\n",
        "print(\"(Кол-во текстов, число признаков текста) = {}\".format(x.shape))\n",
        "print(\"Кол-во меток = {}\".format(len(y)))\n",
        "print(\"Кол-во нормальных экземпляров = {}\".format(len(normal_data)))\n",
        "print(\"Кол-во аномальных экземпляров = {}\".format(len(anomal_data)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Всего экземпляров = 1071\n",
            "(Кол-во текстов, число признаков текста) = (1071, 13691)\n",
            "Кол-во меток = 1071\n",
            "Кол-во нормальных экземпляров = 973\n",
            "Кол-во аномальных экземпляров = 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_bwUYr2yrJ3",
        "outputId": "4ad21f52-847b-49da-8a2d-e342d03b8688"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1071, 13691)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlUenHblzU6y"
      },
      "source": [
        "x = x[:,:13568]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV45k1PGzqW3"
      },
      "source": [
        "x = x.reshape((1071, 53*8, 32, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPx8TqZa4Mj6"
      },
      "source": [
        "nf = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx5XV75cx-Yy"
      },
      "source": [
        "def cosine_similarity(x_predict, x):\n",
        "    if len(x_predict.shape) == 2:\n",
        "        flat_output = x_predict\n",
        "        flat_input = x_predict\n",
        "        # flat_output = np.reshape(x_predict, (np.shape(x)[0], -1))\n",
        "        # flat_input = np.reshape(x_predict, (np.shape(x)[0], -1))\n",
        "        sum = np.sum(flat_output * flat_input, -1)\n",
        "        norm1 = np.linalg.norm(flat_output, axis=-1) + 0.000001\n",
        "        norm2 = np.linalg.norm(flat_input, axis=-1) + 0.000001 \n",
        "        return -(sum / norm1 / norm2)\n",
        "    else:\n",
        "        # ДЛЯ НЕ ПОЛНОСВЯЗНЫХ СЛОЕВ НУЖЕН ДРУГОЙ shape\n",
        "        flat_output = x_predict\n",
        "        flat_input = x_predict\n",
        "        flat_output = tf.reshape(tensor=x_predict, shape=[x.shape.as_list()[0], -1])\n",
        "        flat_input = tf.reshape(tensor=x_predict, shape=[x.shape.as_list()[0], -1])\n",
        "        sum = tf.math.reduce_sum(tf.math.multiply(flat_output, flat_input), axis=-1)\n",
        "        norm1 = tf.norm(flat_output, axis=-1) + 0.000001\n",
        "        norm2 = tf.norm(flat_input, axis=-1) + 0.000001\n",
        "        return -(tf.math.divide(tf.math.divide(sum, norm1), norm2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vRiAW2tyBjU",
        "outputId": "64d33dd9-c738-4554-8319-055339883f05"
      },
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "print(\"Tensorflow version = {}\".format(tf.__version__)) # текущая версия tf\n",
        "\n",
        "from tensorflow.keras import Model, optimizers, metrics\n",
        "from tensorflow.keras.layers import Layer, Flatten, Dense, BatchNormalization, Dropout, Conv2D, Conv2DTranspose, Reshape\n",
        "\n",
        "# from tensorflow.keras import activations, Sequential, Input\n",
        "# from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Reshape\n",
        "# from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "# Задаем random_seed для tensorflow и numpy\n",
        "random_seed = 123\n",
        "tf.random.set_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Sets the default float type\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(123)\n",
        "np.random.seed(123)\n",
        "\n",
        "\n",
        "class RSR(Layer):\n",
        "    \"\"\"\n",
        "    Robust Subspace Recovery (RSR) layer.\n",
        "    Робастный слой, восстанавливающий подпространство. Задача данного слоя - отобразить\n",
        "    закодированные энкодером данные в подпростраство так, чтобы после их обратного\n",
        "    отображения декодером дивергенция между экземпляром исходных данных и его образом,\n",
        "    полученным от автоэнкодера была незначительной для нормального экземпляра и была\n",
        "    большой для аномального экземпляра. \n",
        "\n",
        "    # Example\n",
        "    ```\n",
        "        z_rsr, A = RSR(intrinsic_size=10)(z)\n",
        "    ```\n",
        "    # Arguments\n",
        "        intrinsic_size: размерность z_rsr.\n",
        "    # Input shape\n",
        "        2D tensor with shape: `(n_samples, n_features)` after encoding.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(n_samples, intrinsic_size)`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, intrinsic_size: int, name=\"RSR_layer\", **kwargs):\n",
        "        super(RSR, self).__init__(name=name, **kwargs)\n",
        "        # Если присваивать экземпляр слоя, как атрибут другого слоя, то хорошей\n",
        "        # практикой делать создавать такие подслои в __init__ (поскольку подслои обычно\n",
        "        # имеют метод build, они будут собраны, когда будет собран внешний слой). \n",
        "        self.flatten = Flatten()\n",
        "        self.intrinsic_size = intrinsic_size\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Определяет веса слоя, а именно задает матрицу A.\"\"\"\n",
        "        self.A = self.add_weight(name=\"A\",\n",
        "                                 shape=[int(input_shape[-1]), self.intrinsic_size],\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=True,)\n",
        "        \n",
        "        # self.V = self.add_weight(name=\"V\",\n",
        "        #                          shape=[int(input_shape[-1]), 1],\n",
        "        #                          initializer='random_normal',\n",
        "        #                          trainable=True,)\n",
        "        \n",
        "    def call(self, z):\n",
        "        \"\"\"\n",
        "        Логика слоя. Умножение выхода энкодера - вектора z на матрицу A.\n",
        "        Возвращает отображенный z_rsr и матрицу A, которая потребуется далее.\n",
        "        \"\"\"\n",
        "        z = self.flatten(z)\n",
        "        # print(\"z.shpae Before A:\", z.shape)\n",
        "        z_rsr = tf.linalg.matmul(z, self.A)\n",
        "        # print(\"z_rsr.shpae After A:\", z_rsr.shape) \n",
        "        return z_rsr\n",
        "\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \n",
        "    # get_config и метода класса (@classmethod) from_config.\n",
        "    def get_config(self):\n",
        "        config = super(Layer, self).get_config()\n",
        "        config.update({'intrinsic_size': self.intrinsic_size})\n",
        "        return config\n",
        "\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class L2Normalization(Layer):\n",
        "    \"\"\"Слой для l_2 нормализации, который будет применяться к выходу RSR layer.\"\"\"\n",
        "    \n",
        "    def __init__(self, name=\"L2Normalization\", **kwargs):\n",
        "        super(L2Normalization, self).__init__(name=name, **kwargs)\n",
        "\n",
        "    def call(self, z_rsr):\n",
        "        \"\"\"\n",
        "        Выполняет l_2 нормализацию векторов, полученных после применения RSR layer\n",
        "        вдоль оси, соответсвующей числу признаков. То есть производится нормализация\n",
        "        каждого экземпляра выборки, в результате которой признаки экземпляров будут\n",
        "        находиться в отрезке [-1; 1].\n",
        "        \"\"\"\n",
        "        z_tilde = tf.math.l2_normalize(z_rsr, axis=-1)\n",
        "        return z_tilde\n",
        "\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \n",
        "    # get_config и метода класса (@classmethod) from_config.\n",
        "    def get_config(self):\n",
        "        config = super(Layer, self).get_config()\n",
        "        return config\n",
        "\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class Encoder(Layer):\n",
        "    \"\"\"\n",
        "    Класс для encoder модели RSRAE. Отображает исходные данные input_data в вектор z,\n",
        "    кодирующий исходные данные.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 hidden_layer_dimensions,\n",
        "                 activation,\n",
        "                 flag_bn=True, \n",
        "                 name=\"Encoder\",\n",
        "                 **kwargs):\n",
        "        super(Encoder, self).__init__(name=name, **kwargs)\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\n",
        "        self.activation = activation\n",
        "        self.flag_bn = flag_bn\n",
        "        self.dense0 = Dense(hidden_layer_dimensions[0], activation=activation,\n",
        "                            name='encoder_0')\n",
        "        self.dense1 = Dense(hidden_layer_dimensions[1], activation=activation,\n",
        "                            name='encoder_1')\n",
        "        self.dense2 = Dense(hidden_layer_dimensions[2], activation=activation,\n",
        "                            name='encoder_2')\n",
        "\n",
        "        self.conv1 = Conv2D(nf, (3, 3), (2, 2), activation=self.activation, padding='same')\n",
        "        self.conv2 = Conv2D(nf*2, (3, 3), (2, 2), activation=self.activation, padding='same')\n",
        "        self.conv3 = Conv2D(nf*4, (3, 3), (2, 2), activation=self.activation, padding='same')\n",
        "        if flag_bn:\n",
        "            self.batch_normalization0 = BatchNormalization(name=\"encoder_bn_layer_0\")\n",
        "            self.batch_normalization1 = BatchNormalization(name=\"encoder_bn_layer_1\")\n",
        "            self.batch_normalization2 = BatchNormalization(name=\"encoder_bn_layer_2\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Отображние исходных данных x -> в закодированный вектор z.\"\"\"\n",
        "        x = inputs\n",
        "        print('input_x.shape', x.shape)\n",
        "        x = self.conv1(x)\n",
        "        print('conv_x1.shape', x.shape)\n",
        "        # x = self.dense0(x)\n",
        "        if self.flag_bn:\n",
        "            x = self.batch_normalization0(x)\n",
        "        x = self.conv2(x)\n",
        "        print('conv_x2.shape', x.shape)\n",
        "        # x = self.dense1(x)\n",
        "        if self.flag_bn:\n",
        "            x = self.batch_normalization1(x)\n",
        "        x = Dropout(0.2)((x))\n",
        "        x = self.conv3(x)\n",
        "        print('conv_x3.shape', x.shape)\n",
        "        # x = self.dense2(x)\n",
        "        if self.flag_bn:\n",
        "            x = self.batch_normalization2(x)\n",
        "        x = Dropout(0.3)((x)) \n",
        "        x = Flatten()(x)\n",
        "        # x = Dense(nf*4, activation='tanh')(x)  \n",
        "        z = x\n",
        "        return z\n",
        "    \n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \n",
        "    # get_config и метода класса (@classmethod) from_config.\n",
        "    def get_config(self):\n",
        "        config = super(Layer, self).get_config()\n",
        "        config.update({'hidden_layer_dimensions': self.hidden_layer_dimensions})\n",
        "        config.update({'activation': self.activation})\n",
        "        config.update({'flag_bn': self.flag_bn})\n",
        "        return config\n",
        "\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class Decoder(Layer):\n",
        "    \"\"\"\n",
        "    Класс для decoder модели RSRAE. Отображает вектор z_rsr, полученный в результате\n",
        "    кодирования исходных данных в вектор z, и последующим отображением вектора z при\n",
        "    помощи RSR layer (x -> z -> z_rsr), обратно в пространство исходных данных \n",
        "    (z_rsr -> x_tilde).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 inputs_dim,\n",
        "                 hidden_layer_dimensions,\n",
        "                 activation,\n",
        "                 flag_bn=True, \n",
        "                 name=\"Decoder\",\n",
        "                 **kwargs):\n",
        "        super(Decoder, self).__init__(name=name, **kwargs)\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\n",
        "        self.activation = activation\n",
        "        self.flag_bn = flag_bn\n",
        "        self.dense2 = Dense(hidden_layer_dimensions[2], activation=activation,\n",
        "                            name='decoder_2')\n",
        "        self.dense1 = Dense(hidden_layer_dimensions[1], activation=activation,\n",
        "                            name='decoder_1')\n",
        "        self.dense0 = Dense(hidden_layer_dimensions[0], activation=activation,\n",
        "                            name='decoder_0')\n",
        "        self.dense_output = Dense(inputs_dim, activation=activation,\n",
        "                            name='decoder_output')\n",
        "\n",
        "        self.dense = Dense(nf * 4 * 53 * 4, activation=self.activation)\n",
        "        self.deconv1 = Conv2DTranspose(nf * 2, (3, 3), (2, 2), activation=self.activation, padding='same')\n",
        "        self.deconv2 = Conv2DTranspose(nf, (3, 3), (2, 2), activation=self.activation, padding='same')\n",
        "        self.deconv3 = Conv2DTranspose(1, (3, 3), (2, 2), activation=self.activation, padding='same')\n",
        "        if flag_bn:\n",
        "            self.batch_normalization2 = BatchNormalization(name=\"decoder_bn_layer_2\")\n",
        "            self.batch_normalization1 = BatchNormalization(name=\"decoder_bn_layer_1\")\n",
        "            self.batch_normalization0 = BatchNormalization(name=\"decoder_bn_layer_0\")\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Отображние z_rsr -> x_tilde, где x_tilde - вектор, лежащий в пространстве\n",
        "        исходных даных.\n",
        "        \"\"\"\n",
        "        z_rsr = inputs\n",
        "        print('z_rsr1.shape', z_rsr.shape)\n",
        "        z_rsr = self.dense(z_rsr)\n",
        "        print('z_rsr2.shape', z_rsr.shape)\n",
        "        z_rsr = Reshape((53, 4, nf * 4))(z_rsr)\n",
        "        print('z_rsr3.shape', z_rsr.shape)\n",
        "        # z_rsr = self.dense2(z_rsr)\n",
        "        if self.flag_bn:\n",
        "            z_rsr = self.batch_normalization2(z_rsr)\n",
        "        z_rsr = Dropout(0.4)((z_rsr))\n",
        "        z_rsr = self.deconv1(z_rsr)\n",
        "        print('conv_z_rsr3.shape', z_rsr.shape)\n",
        "        # z_rsr = self.dense1(z_rsr)\n",
        "        if self.flag_bn:\n",
        "            z_rsr = self.batch_normalization1(z_rsr)\n",
        "        z_rsr = Dropout(0.5)((z_rsr))\n",
        "        z_rsr = self.deconv2(z_rsr)\n",
        "        print('conv_z_rsr4.shape', z_rsr.shape)\n",
        "        # z_rsr = self.dense0(z_rsr)\n",
        "        if self.flag_bn:\n",
        "            z_rsr = self.batch_normalization0(z_rsr)\n",
        "        z_rsr = Dropout(0.5)((z_rsr))\n",
        "        z_rsr = self.deconv3(z_rsr)\n",
        "        print('conv_z_rsr5.shape', z_rsr.shape)\n",
        "        x_tilde = z_rsr\n",
        "        # x_tilde = self.dense_output(z_rsr)\n",
        "        return x_tilde\n",
        "    \n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \n",
        "    # get_config и метода класса (@classmethod) from_config.\n",
        "    def get_config(self):\n",
        "        config = super(Layer, self).get_config()\n",
        "        config.update({'hidden_layer_dimensions': self.hidden_layer_dimensions})\n",
        "        config.update({'activation': self.activation})\n",
        "        config.update({'flag_bn': self.flag_bn})\n",
        "        return config\n",
        "\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class RSRAE(Model):\n",
        "    \"\"\"\n",
        "    Нейросетевая модель-автоэнкодер для обнаружения аномалий с робастным слоем,\n",
        "    восстанавливающим подпространство (RSR layer между encoder и decoder).\n",
        "    Комбинируем encoder + RSR layer + decoder в end-to-end модель.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 inputs_dim, # размерность вектора признаков\n",
        "                 hidden_layer_dimensions,\n",
        "                 intrinsic_size, # разерность z_rsr после RSR layer\n",
        "                 activation,\n",
        "                 flag_loss,\n",
        "                 flag_bn=True,\n",
        "                 flag_normalize=True,\n",
        "                 learning_rate=1e-3,\n",
        "                 beta=1,\n",
        "                 eta=1,\n",
        "                 t_step=0,\n",
        "                 ae_loss_norm_type='MSE',\n",
        "                 rsr_loss_norm_type='MSE',\n",
        "                 name='RSRAE',\n",
        "                 **kwargs):\n",
        "        super(RSRAE, self).__init__(name=name, **kwargs)\n",
        "        self.inputs_dim = inputs_dim\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\n",
        "        self.intrinsic_size = intrinsic_size\n",
        "        self.activation = activation\n",
        "        self.flag_bn = flag_bn\n",
        "        self.flag_normalize = flag_normalize\n",
        "        self.flag_loss = flag_loss\n",
        "        self.learning_rate = learning_rate\n",
        "        self.beta = tf.Variable(beta, dtype=tf.float64, trainable=False)\n",
        "        self.beta0 = tf.Variable(beta, dtype=tf.float64, trainable=False)\n",
        "        self.eta = tf.Variable(eta, dtype=tf.float64, trainable=False)\n",
        "        self.eta0 = tf.Variable(eta, dtype=tf.float64, trainable=False)\n",
        "        self.t_step = tf.Variable(t_step, dtype=tf.float64, trainable=False)\n",
        "        self.ae_loss_norm_type = ae_loss_norm_type\n",
        "        self.rsr_loss_norm_type = rsr_loss_norm_type\n",
        "        # Для вычисления среднего loss по loss всех батчей в эпохе\n",
        "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
        "        self.auc_tracker = metrics.Mean(name=\"auc\")\n",
        "        self.ap_tracker = metrics.Mean(name=\"ap\")\n",
        "\n",
        "        # Создание экземпляров оптимизаторов\n",
        "        self.optimizer_ae = optimizers.Adam(learning_rate=learning_rate)\n",
        "        self.optimizer_rsr1 = optimizers.Adam(learning_rate=5 * learning_rate)\n",
        "        self.optimizer_rsr2 = optimizers.Adam(learning_rate=5 * learning_rate)\n",
        "\n",
        "        # Слои\n",
        "        # self.emnedding_layer = hub_layer\n",
        "        self.encoder = Encoder(hidden_layer_dimensions=hidden_layer_dimensions,\n",
        "                               activation=activation,\n",
        "                               flag_bn=flag_bn)\n",
        "        self.rsr = RSR(intrinsic_size=intrinsic_size)\n",
        "        if flag_normalize:\n",
        "            self.l2normalization = L2Normalization()\n",
        "        self.decoder = Decoder(inputs_dim=inputs_dim,\n",
        "                               hidden_layer_dimensions=hidden_layer_dimensions,\n",
        "                               activation=activation,\n",
        "                               flag_bn=flag_bn)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # e = self.emnedding_layer(inputs)\n",
        "        e = inputs\n",
        "        e = tf.cast(e, dtype=tf.float64)\n",
        "        z = self.encoder(e)\n",
        "        z_rsr = self.rsr(z)\n",
        "        if self.flag_normalize:\n",
        "            z_rsr = self.l2normalization(z_rsr)\n",
        "        x_tilde = self.decoder(z_rsr)\n",
        "        return e, z, z_rsr, x_tilde\n",
        "\n",
        "    def ae_loss(self, x, x_tilde):\n",
        "        \"\"\"Функция потерь реконструкции автоэнкодера - L_AE.\"\"\"\n",
        "\n",
        "        x = tf.reshape(x, (tf.shape(x)[0], -1))\n",
        "        x_tilde = tf.reshape(x_tilde, (tf.shape(x_tilde)[0], -1))\n",
        "\n",
        "        # axis=1 для tf.norm => вычисление вдоль оси признаков\n",
        "        # tf.math.reduce_mean без параметров - mean от элементов матрицы\n",
        "        if self.ae_loss_norm_type in ['MSE', 'mse', 'Frob', 'F']:\n",
        "            return tf.math.reduce_mean(tf.math.square(tf.norm(x-x_tilde, \n",
        "                                                              ord=2, axis=1)))\n",
        "        elif self.ae_loss_norm_type in ['L1', 'l1']:\n",
        "            return tf.math.reduce_mean(tf.norm(x-x_tilde, ord=1, axis=1))\n",
        "        elif self.ae_loss_norm_type in ['LAD', 'lad', 'L21', 'l21', 'L2', 'l2']:\n",
        "            return tf.math.reduce_mean(tf.norm(x-x_tilde, ord=2, axis=1))\n",
        "        else:\n",
        "            raise Exception(\"Norm type error!\")\n",
        "    \n",
        "    def rsr1_loss(self, z, z_rsr, beta, eta):\n",
        "        \"\"\"Функция потери для RSR layer - L_RSR1.\"\"\"\n",
        "        z_rsr = tf.matmul(z_rsr, tf.transpose(self.rsr.A))\n",
        "        # z_rsr_new = tf.matmul(z_rsr, self.)\n",
        "\n",
        "        if self.rsr_loss_norm_type in ['MSE', 'mse', 'Frob', 'F']:\n",
        "            return tf.math.reduce_mean(tf.math.square(tf.norm(z-z_rsr, ord=2, \n",
        "                                                            axis=1)))\n",
        "        elif self.rsr_loss_norm_type in ['L1', 'l1']:\n",
        "            return tf.math.reduce_mean(tf.norm(z-z_rsr, ord=1, axis=1))\n",
        "        elif self.rsr_loss_norm_type in ['LAD', 'lad', 'L21', 'l21', 'L2', 'l2']:\n",
        "            return tf.math.reduce_mean(tf.norm(z-z_rsr, ord=2, axis=1))\n",
        "        else:\n",
        "            raise Exception(\"Norm type error!\")\n",
        "    \n",
        "    def rsr2_loss(self):\n",
        "        \"\"\"Функция потери для RSR layer - L_RSR2.\"\"\"\n",
        "        A = self.rsr.A\n",
        "        A_T = tf.transpose(A)\n",
        "        I = tf.eye(self.intrinsic_size, dtype=tf.float64)\n",
        "        return tf.math.reduce_mean(tf.math.square(tf.linalg.matmul(A_T, A) - I))\n",
        "\n",
        "    def rsr3_loss(self, z, z_rsr, beta, eta):\n",
        "        \"\"\"\n",
        "        Cтатьи 'Robust principal component analysis by \n",
        "        self-organizing rules basedon statistical physics approach', на которую\n",
        "        ссылается http://files.is.tue.mpg.de/black/papers/delatorreIJCV03.pdf\n",
        "        \"\"\"\n",
        "        z_rsr = tf.matmul(z_rsr, tf.transpose(self.rsr.A))  # AA'z\n",
        "        e_pca = tf.math.square(tf.norm(z-z_rsr, ord=2, axis=1))\n",
        "        # self.min_div = tf.reduce_min(e_pca)\n",
        "        # self.max_div = tf.reduce_max(e_pca)\n",
        "        # self.mean_div = tf.reduce_mean(e_pca)\n",
        "        loss = -1 * tf.math.reduce_mean(tf.math.log(1 + tf.math.exp(-beta * e_pca - eta))) / beta\n",
        "        return loss\n",
        "        \n",
        "    def gradients(model, inputs, targets):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss_value = loss_fn(model, inputs, targets)\n",
        "        return tape.gradient(loss_value, model.trainable_variables)\n",
        "    \n",
        "    @tf.function()\n",
        "    def train_step(self, data):\n",
        "        \"\"\"\n",
        "        Override the method. Будет вызываться при 'model.fit()'.\n",
        "        Один шаг обучения, на котором вычисляются функции потерь для автоэнкодера и\n",
        "        RSR layer, и в соотвествии с ними обновляются значения обучаемых переменных - \n",
        "        весов нейросети и матрицы A соответсвенно. Будет вызываться от одного батча.\n",
        "        Заметим, что в этом методе мы используем пользовательские оптимизаторы и функции\n",
        "        потерь, поэтому перед тренировкой метод compile вызывать не придется.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        x, y = data\n",
        "\n",
        "        # tf.GradientTape() - записывает операции для автоматического дифференцирования\n",
        "\n",
        "        # По умолчанию persistent=False и удерживаемые GradientTape, высвобождаются,\n",
        "        # как только вызывается метод GradientTape.gradient(). Чтобы вычислить несколько\n",
        "        # градиентов за одно вычисление, требуется задать persistent=true. Это позволяет\n",
        "        # многократно вызывать метод gradient(), тогда требуется самостоятельно\n",
        "        # освободить ресурсы с помощью 'del tape'.\n",
        "\n",
        "        # watch_accessed_variables=True => автоматическое отслеживание всех обучаемых\n",
        "        # переменные, к которым осуществляется доступ. Так градиенты могут быть\n",
        "        # запрошены c любого вычисленного результата в tape.\n",
        "        with tf.GradientTape(persistent=True, watch_accessed_variables=True) as tape:\n",
        "            # Здесь требуется запустить прямой проход нейросети. Операции применяемые\n",
        "            # при проходе к входных данным будут записаны на GradientTape. \n",
        "            e, z, z_rsr, x_tilde = self.call(x) # прямой проход RSRAE\n",
        "            z = tf.keras.layers.Flatten()(z) # вроде для текстовых данных необязательно\n",
        "            # Вычисляем значения функций потерь для этого прохода\n",
        "            loss_ae = self.ae_loss(e, x_tilde)\n",
        "            if (self.flag_loss == 0):\n",
        "                loss_rsr3 = self.rsr1_loss(z, z_rsr, self.beta, self.eta)\n",
        "            else:\n",
        "                loss_rsr3 = self.rsr3_loss(z, z_rsr, self.beta, self.eta)\n",
        "            loss_rsr2 = self.rsr2_loss()\n",
        "  \n",
        "        # Метод gradient вычисляет градиенты обучаемых параметров(весов) для минимизации\n",
        "        # функции потерь, используя операции, записанные в контексте этого tape.\n",
        "        gradients_ae = tape.gradient(loss_ae, self.trainable_weights)\n",
        "        gradients_rsr3 = tape.gradient(loss_rsr3, self.rsr.A)\n",
        "        gradients_rsr2 = tape.gradient(loss_rsr2, self.rsr.A)\n",
        "\n",
        "        # Обновим значения обучаемых переменных - градиентный шаг чтобы min loss.\n",
        "        self.optimizer_ae.apply_gradients(grads_and_vars=\n",
        "                                          zip(gradients_ae, self.trainable_weights))\n",
        "        self.optimizer_rsr1.apply_gradients(grads_and_vars=\n",
        "                                            zip([gradients_rsr3], [self.rsr.A]))\n",
        "        self.optimizer_rsr2.apply_gradients(grads_and_vars=\n",
        "                                            zip([gradients_rsr2], [self.rsr.A]))\n",
        "        \n",
        "        self.loss_tracker.update_state(loss_ae) # обновляем средний loss по батчам\n",
        "\n",
        "        self.t_step.assign_add(1, use_locking=True)\n",
        "        self.beta.assign(self.beta0.value() * tf.math.log(self.t_step.value() + 3))\n",
        "        self.eta.assign(self.eta0.value() * self.t_step.value())\n",
        "\n",
        "        # Обновляем метрики\n",
        "        if len(tf.unique(y)[0]) == 2:\n",
        "            # иначе roc_auc_score бросит ValueError и обучение приостановится\n",
        "            auc = self.auc_metric(y, cosine_similarity(x_tilde, e))\n",
        "            self.auc_tracker.update_state(auc)\n",
        "\n",
        "        ap = self.ap_metric(y, cosine_similarity(x_tilde, e))\n",
        "        self.ap_tracker.update_state(ap)\n",
        "\n",
        "        del tape # persistent=True => требуется самостоятельно освободить ресурсы\n",
        "        return {\"loss\": self.loss_tracker.result(),\n",
        "                \"auc\": self.auc_tracker.result(),\n",
        "                \"ap\": self.ap_tracker.result(),\n",
        "                # \"mean_div\": self.mean_div,\n",
        "                # \"min_div\": self.min_div, \n",
        "                # \"max_div\": self.max_div,\n",
        "                \"beta\": self.beta,\n",
        "                \"eta\": self.eta,\n",
        "                \"t_step\": self.t_step}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        \"\"\"\n",
        "        В пару к train_step. Сбрасывает метрики (`reset_states()`) в начале каждой\n",
        "        эпохи обучения с помощью 'fit()'. Без этого свойства 'result()' будет \n",
        "        возвращать среднее значение с начала обучения.\n",
        "        \"\"\"\n",
        "        return [self.loss_tracker, self.auc_tracker, self.ap_tracker]\n",
        "\n",
        "    def auc_metric(self, y_true, y_pred):\n",
        "        return tf.py_function(roc_auc_score, (y_true, y_pred), tf.float64)\n",
        "\n",
        "    def ap_metric(self, y_true, y_pred):\n",
        "        return tf.py_function(average_precision_score, (y_true, y_pred), tf.float64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version = 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUhXFibn-LMQ",
        "outputId": "840a0871-c966-4210-a7f8-fbb3a36f885b"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1071, 424, 32, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "-Uf1xcuPyHDt",
        "outputId": "a295e931-1596-451e-d401-0f5733419163"
      },
      "source": [
        "# Тренировка модели\n",
        "model_rsrae = RSRAE(inputs_dim=x.shape[1],\n",
        "                    hidden_layer_dimensions=[1024, 2048, 4096],\n",
        "                    intrinsic_size=256,\n",
        "                    activation='relu',\n",
        "                    flag_loss=0,\n",
        "                    learning_rate=1e-5,\n",
        "                    beta=1.0,\n",
        "                    eta=0.0015,\n",
        "                    ae_loss_norm_type='MSE',\n",
        "                    rsr_loss_norm_type='MSE',)\n",
        "model_rsrae.compile(run_eagerly=True)\n",
        "model_rsrae.fit(x, y,\n",
        "                batch_size=512,\n",
        "                epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "input_x.shape (512, 424, 32, 1)\n",
            "conv_x1.shape (512, 212, 16, 64)\n",
            "conv_x2.shape (512, 106, 8, 128)\n",
            "conv_x3.shape (512, 53, 4, 256)\n",
            "z_rsr1.shape (512, 256)\n",
            "z_rsr2.shape (512, 54272)\n",
            "z_rsr3.shape (512, 53, 4, 256)\n",
            "conv_z_rsr3.shape (512, 106, 8, 128)\n",
            "conv_z_rsr4.shape (512, 212, 16, 64)\n",
            "conv_z_rsr5.shape (512, 424, 32, 1)\n",
            "input_x.shape (512, 424, 32, 1)\n",
            "conv_x1.shape (512, 212, 16, 64)\n",
            "conv_x2.shape (512, 106, 8, 128)\n",
            "conv_x3.shape (512, 53, 4, 256)\n",
            "z_rsr1.shape (512, 256)\n",
            "z_rsr2.shape (512, 54272)\n",
            "z_rsr3.shape (512, 53, 4, 256)\n",
            "conv_z_rsr3.shape (512, 106, 8, 128)\n",
            "conv_z_rsr4.shape (512, 212, 16, 64)\n",
            "conv_z_rsr5.shape (512, 424, 32, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f356815f3bad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m model_rsrae.fit(x, y,\n\u001b[1;32m     14\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 epochs=30)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    803\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[512,64,212,16] and type double on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node Decoder/conv2d_transpose_1/conv2d_transpose (defined at <ipython-input-11-934ca5615030>:253) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_step_2600]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Decoder/conv2d_transpose_1/conv2d_transpose:\n Decoder/dropout_3/Identity (defined at <ipython-input-11-934ca5615030>:252)\n\nFunction call stack:\ntrain_step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAa02Q0TyK2b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8BZOLOO-TFx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}