{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RSRAE_with_another loss V.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72kLNO3zHEqB"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzkj-zxjGPrK",
        "outputId": "936f1e09-ec1c-4a53-c066-b673447a0412"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "\n",
        "c = 0.1  # отношение количества аномальных экземпляров к нормальным\n",
        "\n",
        "# загужаем данные\n",
        "normal_data = fetch_20newsgroups(subset='all', categories=['sci.electronics'],\n",
        "                               shuffle=True, random_state=123, \n",
        "                               remove=['headers', 'footers'], return_X_y=True)[0]\n",
        "anomal_data = fetch_20newsgroups(subset='all', categories=['talk.politics.mideast'],\n",
        "                               shuffle=True, random_state=123,\n",
        "                               remove=['headers', 'footers'],\n",
        "                               return_X_y=True)[0][:int(c * len(normal_data)) + 1]\n",
        "\n",
        "# # приводим к одинаковой длине\n",
        "# min_len = max(len(normal_data), len(anomal_data))\n",
        "# normal_data = normal_data[:min_len]\n",
        "# anomal_data = anomal_data[:min_len]\n",
        "print(\"Количество нормальных экземпляров = {}\".format(len(normal_data)))\n",
        "print(\"Количество аномальных экземпляров = {}\".format(len(anomal_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество нормальных экземпляров = 984\n",
            "Количество аномальных экземпляров = 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUlKcje3HUc4"
      },
      "source": [
        "## Формирование выборок\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB0UmaY5HVEY",
        "outputId": "2abaa622-50ce-46bd-e728-2933c758972b"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd\n",
        "\n",
        "all_data = normal_data + anomal_data\n",
        "x = pd.Series(all_data)\n",
        "y = np.array([False] * len(normal_data) + [True] * len(anomal_data))\n",
        "\n",
        "all_data, x, y = shuffle(all_data, x, y, random_state=123)\n",
        "print(\"Всего экземпляров = {}\".format(len(all_data)))\n",
        "# print(\"(Кол-во текстов, число признаков текста) = {}\".format(x.shape))\n",
        "print(\"Кол-во меток = {}\".format(len(y)))\n",
        "print(\"Кол-во нормальных экземпляров = {}\".format(len(normal_data)))\n",
        "print(\"Кол-во аномальных экземпляров = {}\".format(len(anomal_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Всего экземпляров = 1083\n",
            "Кол-во меток = 1083\n",
            "Кол-во нормальных экземпляров = 984\n",
            "Кол-во аномальных экземпляров = 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHUTrmZ-HfjC"
      },
      "source": [
        "## Функция Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoC4pVv3HgF0"
      },
      "source": [
        "def cosine_similarity(x_predict, x):\n",
        "    if type(x_predict) is np.ndarray:\n",
        "        flat_output = x_predict\n",
        "        flat_input = x_predict\n",
        "        # flat_output = np.reshape(x_predict, (np.shape(x)[0], -1))\n",
        "        # flat_input = np.reshape(x_predict, (np.shape(x)[0], -1))\n",
        "        sum = np.sum(flat_output * flat_input, -1)\n",
        "        norm1 = np.linalg.norm(flat_output, axis=-1) + 0.000001\n",
        "        norm2 = np.linalg.norm(flat_input, axis=-1) + 0.000001 \n",
        "        return -(sum / norm1 / norm2)\n",
        "    else:\n",
        "        # ДЛЯ НЕ ПОЛНОСВЯЗНЫХ СЛОЕВ НУЖЕН ДРУГОЙ shape\n",
        "        flat_output = x_predict\n",
        "        flat_input = x_predict\n",
        "        # flat_output = tf.reshape(tensor=x_predict, shape=[x.shape.as_list()[0], -1])\n",
        "        # flat_input = tf.reshape(tensor=x_predict, shape=[x.shape.as_list()[0], -1])\n",
        "        sum = tf.math.reduce_sum(tf.math.multiply(flat_output, flat_input), axis=-1)\n",
        "        norm1 = tf.norm(flat_output, axis=-1) + 0.000001\n",
        "        norm2 = tf.norm(flat_input, axis=-1) + 0.000001\n",
        "        return -(tf.math.divide(tf.math.divide(sum, norm1), norm2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHe2b9uEHlwq"
      },
      "source": [
        "## RSRAE model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssId3mthN4cZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "hub_layer = hub.KerasLayer(\n",
        "    'https://tfhub.dev/google/universal-sentence-encoder/4',\n",
        "    input_shape=[], \n",
        "    dtype=tf.string,\n",
        "    trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWqarT6eHmGn",
        "outputId": "a99624c6-8e55-4538-e853-649715a88d7c"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version = {}\".format(tf.__version__)) # текущая версия tf\n",
        "\n",
        "from tensorflow.keras import Model, optimizers, metrics\n",
        "from tensorflow.keras.layers import Layer, Flatten, Dense, BatchNormalization\n",
        "\n",
        "# from tensorflow.keras import activations, Sequential, Input\n",
        "# from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Reshape\n",
        "# from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "# Задаем random_seed для tensorflow и numpy\n",
        "random_seed = 123\n",
        "tf.random.set_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Sets the default float type\n",
        "tf.keras.backend.set_floatx('float64')\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(123)\n",
        "np.random.seed(123)\n",
        "\n",
        "\n",
        "class RSR(Layer):\n",
        "    \"\"\"\n",
        "    Robust Subspace Recovery (RSR) layer.\n",
        "    Робастный слой, восстанавливающий подпространство. Задача данного слоя - отобразить\n",
        "    закодированные энкодером данные в подпростраство так, чтобы после их обратного\n",
        "    отображения декодером дивергенция между экземпляром исходных данных и его образом,\n",
        "    полученным от автоэнкодера была незначительной для нормального экземпляра и была\n",
        "    большой для аномального экземпляра. \n",
        "\n",
        "    # Example\n",
        "    ```\n",
        "        z_rsr, A = RSR(intrinsic_size=10)(z)\n",
        "    ```\n",
        "    # Arguments\n",
        "        intrinsic_size: размерность z_rsr.\n",
        "    # Input shape\n",
        "        2D tensor with shape: `(n_samples, n_features)` after encoding.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(n_samples, intrinsic_size)`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, intrinsic_size: int, name=\"RSR_layer\", **kwargs):\n",
        "        super(RSR, self).__init__(name=name, **kwargs)\n",
        "        # Если присваивать экземпляр слоя, как атрибут другого слоя, то хорошей\n",
        "        # практикой делать создавать такие подслои в __init__ (поскольку подслои обычно\n",
        "        # имеют метод build, они будут собраны, когда будет собран внешний слой). \n",
        "        self.flatten = Flatten()\n",
        "        self.intrinsic_size = intrinsic_size\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Определяет веса слоя, а именно задает матрицу A.\"\"\"\n",
        "        self.A = self.add_weight(name=\"A\",\n",
        "                                 shape=[int(input_shape[-1]), self.intrinsic_size],\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=True,)\n",
        "        \n",
        "        # self.V = self.add_weight(name=\"V\",\n",
        "        #                          shape=[int(input_shape[-1]), 1],\n",
        "        #                          initializer='random_normal',\n",
        "        #                          trainable=True,)\n",
        "        \n",
        "    def call(self, z):\n",
        "        \"\"\"\n",
        "        Логика слоя. Умножение выхода энкодера - вектора z на матрицу A.\n",
        "        Возвращает отображенный z_rsr и матрицу A, которая потребуется далее.\n",
        "        \"\"\"\n",
        "        z = self.flatten(z)\n",
        "        # print(\"z.shpae Before A:\", z.shape)\n",
        "        z_rsr = tf.linalg.matmul(z, self.A)\n",
        "        # print(\"z_rsr.shpae After A:\", z_rsr.shape) \n",
        "        return z_rsr\n",
        "\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \n",
        "    # get_config и метода класса (@classmethod) from_config.\n",
        "    def get_config(self):\n",
        "        config = super(Layer, self).get_config()\n",
        "        config.update({'intrinsic_size': self.intrinsic_size})\n",
        "        return config\n",
        "\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class L2Normalization(Layer):\n",
        "    \"\"\"Слой для l_2 нормализации, который будет применяться к выходу RSR layer.\"\"\"\n",
        "    \n",
        "    def __init__(self, name=\"L2Normalization\", **kwargs):\n",
        "        super(L2Normalization, self).__init__(name=name, **kwargs)\n",
        "\n",
        "    def call(self, z_rsr):\n",
        "        \"\"\"\n",
        "        Выполняет l_2 нормализацию векторов, полученных после применения RSR layer\n",
        "        вдоль оси, соответсвующей числу признаков. То есть производится нормализация\n",
        "        каждого экземпляра выборки, в результате которой признаки экземпляров будут\n",
        "        находиться в отрезке [-1; 1].\n",
        "        \"\"\"\n",
        "        z_tilde = tf.math.l2_normalize(z_rsr, axis=-1)\n",
        "        return z_tilde\n",
        "\n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \n",
        "    # get_config и метода класса (@classmethod) from_config.\n",
        "    def get_config(self):\n",
        "        config = super(Layer, self).get_config()\n",
        "        return config\n",
        "\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class Encoder(Layer):\n",
        "    \"\"\"\n",
        "    Класс для encoder модели RSRAE. Отображает исходные данные input_data в вектор z,\n",
        "    кодирующий исходные данные.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 hidden_layer_dimensions,\n",
        "                 activation,\n",
        "                 flag_bn=True, \n",
        "                 name=\"Encoder\",\n",
        "                 **kwargs):\n",
        "        super(Encoder, self).__init__(name=name, **kwargs)\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\n",
        "        self.activation = activation\n",
        "        self.flag_bn = flag_bn\n",
        "        self.dense0 = Dense(hidden_layer_dimensions[0], activation=activation,\n",
        "                            name='encoder_0')\n",
        "        self.dense1 = Dense(hidden_layer_dimensions[1], activation=activation,\n",
        "                            name='encoder_1')\n",
        "        self.dense2 = Dense(hidden_layer_dimensions[2], activation=activation,\n",
        "                            name='encoder_2')\n",
        "        if flag_bn:\n",
        "            self.batch_normalization0 = BatchNormalization(name=\"encoder_bn_layer_0\")\n",
        "            self.batch_normalization1 = BatchNormalization(name=\"encoder_bn_layer_1\")\n",
        "            self.batch_normalization2 = BatchNormalization(name=\"encoder_bn_layer_2\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Отображние исходных данных x -> в закодированный вектор z.\"\"\"\n",
        "        x = inputs\n",
        "        x = self.dense0(x)\n",
        "        if self.flag_bn:\n",
        "            x = self.batch_normalization0(x)\n",
        "        x = self.dense1(x)\n",
        "        if self.flag_bn:\n",
        "            x = self.batch_normalization1(x)\n",
        "        x = self.dense2(x)\n",
        "        if self.flag_bn:\n",
        "            x = self.batch_normalization2(x)\n",
        "        z = x\n",
        "        return z\n",
        "    \n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \n",
        "    # get_config и метода класса (@classmethod) from_config.\n",
        "    def get_config(self):\n",
        "        config = super(Layer, self).get_config()\n",
        "        config.update({'hidden_layer_dimensions': self.hidden_layer_dimensions})\n",
        "        config.update({'activation': self.activation})\n",
        "        config.update({'flag_bn': self.flag_bn})\n",
        "        return config\n",
        "\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class Decoder(Layer):\n",
        "    \"\"\"\n",
        "    Класс для decoder модели RSRAE. Отображает вектор z_rsr, полученный в результате\n",
        "    кодирования исходных данных в вектор z, и последующим отображением вектора z при\n",
        "    помощи RSR layer (x -> z -> z_rsr), обратно в пространство исходных данных \n",
        "    (z_rsr -> x_tilde).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 inputs_dim,\n",
        "                 hidden_layer_dimensions,\n",
        "                 activation,\n",
        "                 flag_bn=True, \n",
        "                 name=\"Decoder\",\n",
        "                 **kwargs):\n",
        "        super(Decoder, self).__init__(name=name, **kwargs)\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\n",
        "        self.activation = activation\n",
        "        self.flag_bn = flag_bn\n",
        "        self.dense2 = Dense(hidden_layer_dimensions[2], activation=activation,\n",
        "                            name='decoder_2')\n",
        "        self.dense1 = Dense(hidden_layer_dimensions[1], activation=activation,\n",
        "                            name='decoder_1')\n",
        "        self.dense0 = Dense(hidden_layer_dimensions[0], activation=activation,\n",
        "                            name='decoder_0')\n",
        "        self.dense_output = Dense(inputs_dim, activation=activation,\n",
        "                            name='decoder_output')\n",
        "        if flag_bn:\n",
        "            self.batch_normalization2 = BatchNormalization(name=\"decoder_bn_layer_2\")\n",
        "            self.batch_normalization1 = BatchNormalization(name=\"decoder_bn_layer_1\")\n",
        "            self.batch_normalization0 = BatchNormalization(name=\"decoder_bn_layer_0\")\n",
        "    def call(self, inputs):\n",
        "        \"\"\"\n",
        "        Отображние z_rsr -> x_tilde, где x_tilde - вектор, лежащий в пространстве\n",
        "        исходных даных.\n",
        "        \"\"\"\n",
        "        z_rsr = inputs\n",
        "        z_rsr = self.dense2(z_rsr)\n",
        "        if self.flag_bn:\n",
        "            z_rsr = self.batch_normalization2(z_rsr)\n",
        "        z_rsr = self.dense1(z_rsr)\n",
        "        if self.flag_bn:\n",
        "            z_rsr = self.batch_normalization1(z_rsr)\n",
        "        z_rsr = self.dense0(z_rsr)\n",
        "        if self.flag_bn:\n",
        "            z_rsr = self.batch_normalization0(z_rsr)\n",
        "        x_tilde = self.dense_output(z_rsr)\n",
        "        return x_tilde\n",
        "    \n",
        "    # Опционально, пользовательский слой может быть сериализован реализацией метода \n",
        "    # get_config и метода класса (@classmethod) from_config.\n",
        "    def get_config(self):\n",
        "        config = super(Layer, self).get_config()\n",
        "        config.update({'hidden_layer_dimensions': self.hidden_layer_dimensions})\n",
        "        config.update({'activation': self.activation})\n",
        "        config.update({'flag_bn': self.flag_bn})\n",
        "        return config\n",
        "\n",
        "    # На самом деле нет необходимости определять `from_config` здесь, поскольку \n",
        "    # возвращение `cls(**config)` - поведение по умолчанию.\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "\n",
        "class RSRAE(Model):\n",
        "    \"\"\"\n",
        "    Нейросетевая модель-автоэнкодер для обнаружения аномалий с робастным слоем,\n",
        "    восстанавливающим подпространство (RSR layer между encoder и decoder).\n",
        "    Комбинируем encoder + RSR layer + decoder в end-to-end модель.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 inputs_dim, # размерность вектора признаков\n",
        "                 hidden_layer_dimensions,\n",
        "                 intrinsic_size, # разерность z_rsr после RSR layer\n",
        "                 activation,\n",
        "                 flag_bn=True,\n",
        "                 flag_normalize=True,\n",
        "                 learning_rate=1e-3,\n",
        "                 beta=1,\n",
        "                 eta=1,\n",
        "                 t_step=0,\n",
        "                 ae_loss_norm_type='MSE',\n",
        "                 rsr_loss_norm_type='MSE',\n",
        "                 name='RSRAE',\n",
        "                 **kwargs):\n",
        "        super(RSRAE, self).__init__(name=name, **kwargs)\n",
        "        self.inputs_dim = inputs_dim\n",
        "        self.hidden_layer_dimensions = hidden_layer_dimensions\n",
        "        self.intrinsic_size = intrinsic_size\n",
        "        self.activation = activation\n",
        "        self.flag_bn = flag_bn\n",
        "        self.flag_normalize = flag_normalize\n",
        "        self.learning_rate = learning_rate\n",
        "        self.beta = tf.Variable(beta, dtype=tf.float64, trainable=True)\n",
        "        self.beta0 = tf.Variable(beta, dtype=tf.float64, trainable=True)\n",
        "        self.eta = tf.Variable(eta, dtype=tf.float64, trainable=True)\n",
        "        self.eta0 = tf.Variable(eta, dtype=tf.float64, trainable=True)\n",
        "        self.t_step = tf.Variable(t_step, dtype=tf.float64, trainable=False)\n",
        "        self.ae_loss_norm_type = ae_loss_norm_type\n",
        "        self.rsr_loss_norm_type = rsr_loss_norm_type\n",
        "        # Для вычисления среднего loss по loss всех батчей в эпохе\n",
        "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
        "        self.auc_tracker = metrics.Mean(name=\"auc\")\n",
        "        self.ap_tracker = metrics.Mean(name=\"ap\")\n",
        "\n",
        "        # Создание экземпляров оптимизаторов\n",
        "        self.optimizer_ae = optimizers.Adam(learning_rate=learning_rate)\n",
        "        self.optimizer_rsr1 = optimizers.Adam(learning_rate=5 * learning_rate)\n",
        "        self.optimizer_rsr2 = optimizers.Adam(learning_rate=5 * learning_rate)\n",
        "\n",
        "        # Слои\n",
        "        self.emnedding_layer = hub_layer\n",
        "        self.encoder = Encoder(hidden_layer_dimensions=hidden_layer_dimensions,\n",
        "                               activation=activation,\n",
        "                               flag_bn=flag_bn)\n",
        "        self.rsr = RSR(intrinsic_size=intrinsic_size)\n",
        "        if flag_normalize:\n",
        "            self.l2normalization = L2Normalization()\n",
        "        self.decoder = Decoder(inputs_dim=inputs_dim,\n",
        "                               hidden_layer_dimensions=hidden_layer_dimensions,\n",
        "                               activation=activation,\n",
        "                               flag_bn=flag_bn)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        e = self.emnedding_layer(inputs)\n",
        "        e = tf.cast(e, dtype=tf.float64)\n",
        "        z = self.encoder(e)\n",
        "        z_rsr = self.rsr(z)\n",
        "        if self.flag_normalize:\n",
        "            z_rsr = self.l2normalization(z_rsr)\n",
        "        x_tilde = self.decoder(z_rsr)\n",
        "        return e, z, z_rsr, x_tilde\n",
        "\n",
        "    def ae_loss(self, x, x_tilde):\n",
        "        \"\"\"Функция потерь реконструкции автоэнкодера - L_AE.\"\"\"\n",
        "\n",
        "        x = tf.reshape(x, (tf.shape(x)[0], -1))\n",
        "        x_tilde = tf.reshape(x_tilde, (tf.shape(x_tilde)[0], -1))\n",
        "\n",
        "        # axis=1 для tf.norm => вычисление вдоль оси признаков\n",
        "        # tf.math.reduce_mean без параметров - mean от элементов матрицы\n",
        "        if self.ae_loss_norm_type in ['MSE', 'mse', 'Frob', 'F']:\n",
        "            return tf.math.reduce_mean(tf.math.square(tf.norm(x-x_tilde, \n",
        "                                                              ord=2, axis=1)))\n",
        "        elif self.ae_loss_norm_type in ['L1', 'l1']:\n",
        "            return tf.math.reduce_mean(tf.norm(x-x_tilde, ord=1, axis=1))\n",
        "        elif self.ae_loss_norm_type in ['LAD', 'lad', 'L21', 'l21', 'L2', 'l2']:\n",
        "            return tf.math.reduce_mean(tf.norm(x-x_tilde, ord=2, axis=1))\n",
        "        else:\n",
        "            raise Exception(\"Norm type error!\")\n",
        "    \n",
        "    def rsr1_loss(self, z, z_rsr):\n",
        "        \"\"\"Функция потери для RSR layer - L_RSR1.\"\"\"\n",
        "        z_rsr = tf.matmul(z_rsr, tf.transpose(self.rsr.A))\n",
        "        # z_rsr_new = tf.matmul(z_rsr, self.)\n",
        "\n",
        "        if self.rsr_loss_norm_type in ['MSE', 'mse', 'Frob', 'F']:\n",
        "            return tf.math.reduce_mean(tf.math.square(tf.norm(z-z_rsr, ord=2, \n",
        "                                                            axis=1)))\n",
        "        elif self.rsr_loss_norm_type in ['L1', 'l1']:\n",
        "            return tf.math.reduce_mean(tf.norm(z-z_rsr, ord=1, axis=1))\n",
        "        elif self.rsr_loss_norm_type in ['LAD', 'lad', 'L21', 'l21', 'L2', 'l2']:\n",
        "            return tf.math.reduce_mean(tf.norm(z-z_rsr, ord=2, axis=1))\n",
        "        else:\n",
        "            raise Exception(\"Norm type error!\")\n",
        "    \n",
        "    def rsr2_loss(self):\n",
        "        \"\"\"Функция потери для RSR layer - L_RSR2.\"\"\"\n",
        "        A = self.rsr.A\n",
        "        A_T = tf.transpose(A)\n",
        "        I = tf.eye(self.intrinsic_size, dtype=tf.float64)\n",
        "        return tf.math.reduce_mean(tf.math.square(tf.linalg.matmul(A_T, A) - I))\n",
        "\n",
        "    def rsr3_loss(self, z, z_rsr, beta, eta):\n",
        "        \"\"\"\n",
        "        Cтатьи 'Robust principal component analysis by \n",
        "        self-organizing rules basedon statistical physics approach', на которую\n",
        "        ссылается http://files.is.tue.mpg.de/black/papers/delatorreIJCV03.pdf\n",
        "        \"\"\"\n",
        "        z_rsr = tf.matmul(z_rsr, tf.transpose(self.rsr.A))  # AA'z\n",
        "        e_pca = tf.math.square(tf.norm(z-z_rsr, ord=2, axis=1))\n",
        "        self.min_div = tf.reduce_min(e_pca)\n",
        "        self.max_div = tf.reduce_max(e_pca)\n",
        "        self.mean_div = tf.reduce_mean(e_pca)\n",
        "        print(beta)\n",
        "        loss = -1 * tf.math.reduce_mean(tf.math.log(1 + tf.math.exp(-beta * e_pca - eta))) / beta\n",
        "        return loss\n",
        "        \n",
        "    def gradients(model, inputs, targets):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss_value = loss_fn(model, inputs, targets)\n",
        "        return tape.gradient(loss_value, model.trainable_variables)\n",
        "    \n",
        "    @tf.function()\n",
        "    def train_step(self, data):\n",
        "        \"\"\"\n",
        "        Override the method. Будет вызываться при 'model.fit()'.\n",
        "        Один шаг обучения, на котором вычисляются функции потерь для автоэнкодера и\n",
        "        RSR layer, и в соотвествии с ними обновляются значения обучаемых переменных - \n",
        "        весов нейросети и матрицы A соответсвенно. Будет вызываться от одного батча.\n",
        "        Заметим, что в этом методе мы используем пользовательские оптимизаторы и функции\n",
        "        потерь, поэтому перед тренировкой метод compile вызывать не придется.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        x, y = data\n",
        "\n",
        "        # tf.GradientTape() - записывает операции для автоматического дифференцирования\n",
        "\n",
        "        # По умолчанию persistent=False и удерживаемые GradientTape, высвобождаются,\n",
        "        # как только вызывается метод GradientTape.gradient(). Чтобы вычислить несколько\n",
        "        # градиентов за одно вычисление, требуется задать persistent=true. Это позволяет\n",
        "        # многократно вызывать метод gradient(), тогда требуется самостоятельно\n",
        "        # освободить ресурсы с помощью 'del tape'.\n",
        "\n",
        "        # watch_accessed_variables=True => автоматическое отслеживание всех обучаемых\n",
        "        # переменные, к которым осуществляется доступ. Так градиенты могут быть\n",
        "        # запрошены c любого вычисленного результата в tape.\n",
        "        with tf.GradientTape(persistent=True, watch_accessed_variables=True) as tape:\n",
        "            # Здесь требуется запустить прямой проход нейросети. Операции применяемые\n",
        "            # при проходе к входных данным будут записаны на GradientTape. \n",
        "            e, z, z_rsr, x_tilde = self.call(x) # прямой проход RSRAE\n",
        "            z = tf.keras.layers.Flatten()(z) # вроде для текстовых данных необязательно\n",
        "            # Вычисляем значения функций потерь для этого прохода\n",
        "            loss_ae = self.ae_loss(e, x_tilde)\n",
        "            loss_rsr3 = self.rsr3_loss(z, z_rsr, self.beta, self.eta)\n",
        "            loss_rsr2 = self.rsr2_loss()\n",
        "  \n",
        "        # Метод gradient вычисляет градиенты обучаемых параметров(весов) для минимизации\n",
        "        # функции потерь, используя операции, записанные в контексте этого tape.\n",
        "        gradients_ae = tape.gradient(loss_ae, self.trainable_weights)\n",
        "        gradients_rsr3 = tape.gradient(loss_rsr3, self.rsr.A)\n",
        "        gradients_rsr2 = tape.gradient(loss_rsr2, self.rsr.A)\n",
        "\n",
        "        # Обновим значения обучаемых переменных - градиентный шаг чтобы min loss.\n",
        "        self.optimizer_ae.apply_gradients(grads_and_vars=\n",
        "                                          zip(gradients_ae, self.trainable_weights))\n",
        "        self.optimizer_rsr1.apply_gradients(grads_and_vars=\n",
        "                                            zip([gradients_rsr3], [self.rsr.A]))\n",
        "        self.optimizer_rsr2.apply_gradients(grads_and_vars=\n",
        "                                            zip([gradients_rsr2], [self.rsr.A]))\n",
        "        \n",
        "        self.loss_tracker.update_state(loss_ae) # обновляем средний loss по батчам\n",
        "\n",
        "        self.t_step.assign_add(1, use_locking=True)\n",
        "        self.beta.assign(self.beta0.value() * tf.math.log(self.t_step.value() + 3))\n",
        "        self.eta.assign(self.eta0.value() * self.t_step.value())\n",
        "\n",
        "        # Обновляем метрики\n",
        "        if len(tf.unique(y)[0]) == 2:\n",
        "            # иначе roc_auc_score бросит ValueError и обучение приостановится\n",
        "            auc = self.auc_metric(y, cosine_similarity(x_tilde, e))\n",
        "            self.auc_tracker.update_state(auc)\n",
        "\n",
        "        ap = self.ap_metric(y, cosine_similarity(x_tilde, e))\n",
        "        self.ap_tracker.update_state(ap)\n",
        "\n",
        "        del tape # persistent=True => требуется самостоятельно освободить ресурсы\n",
        "        return {\"loss\": self.loss_tracker.result(),\n",
        "                \"auc\": self.auc_tracker.result(),\n",
        "                \"ap\": self.ap_tracker.result(),\n",
        "                \"mean_div\": self.mean_div,\n",
        "                \"min_div\": self.min_div, \n",
        "                \"max_div\": self.max_div,\n",
        "                \"beta\": self.beta,\n",
        "                \"eta\": self.eta,\n",
        "                \"t_step\": self.t_step}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        \"\"\"\n",
        "        В пару к train_step. Сбрасывает метрики (`reset_states()`) в начале каждой\n",
        "        эпохи обучения с помощью 'fit()'. Без этого свойства 'result()' будет \n",
        "        возвращать среднее значение с начала обучения.\n",
        "        \"\"\"\n",
        "        return [self.loss_tracker, self.auc_tracker, self.ap_tracker]\n",
        "\n",
        "    def auc_metric(self, y_true, y_pred):\n",
        "        return tf.py_function(roc_auc_score, (y_true, y_pred), tf.float64)\n",
        "\n",
        "    def ap_metric(self, y_true, y_pred):\n",
        "        return tf.py_function(average_precision_score, (y_true, y_pred), tf.float64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version = 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8n3rxAbHv25"
      },
      "source": [
        "## Тренировка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd7ieHfIHo0n",
        "outputId": "a5293cd9-fc31-4d48-ec4a-d7a492dc71cc"
      },
      "source": [
        "model_rsrae = RSRAE(inputs_dim=512,\n",
        "                    hidden_layer_dimensions=[256, 512, 1024],\n",
        "                    intrinsic_size=20,\n",
        "                    activation='relu',\n",
        "                    learning_rate=1e-4,\n",
        "                    beta=1.0,\n",
        "                    eta=0.0015,\n",
        "                    ae_loss_norm_type='MSE',\n",
        "                    rsr_loss_norm_type='MSE',)\n",
        "model_rsrae.compile(run_eagerly=True)\n",
        "model_rsrae.fit(x, y,\n",
        "                batch_size=128,\n",
        "                epochs=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_1_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_1_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_2_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_3_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_3_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_3_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_4_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_4_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_4_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_5_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_5_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_5_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_6_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_6_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_6_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_7_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_7_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_7_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_8_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_8_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_8_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_9_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_9_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_9_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_10_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_10_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_10_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_11_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_11_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_11_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_12_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_12_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_12_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_13_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_13_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_13_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_14_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_14_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_14_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_15_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_15_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_15_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_16_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_16_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_16_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_17_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_17_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_17_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_18_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_18_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_18_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_19_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_19_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_19_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_20_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_20_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_20_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_21_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_21_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_21_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_22_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_22_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_22_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_23_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_23_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_23_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_24_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_24_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_24_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_25_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_25_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_25_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_26_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_26_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_26_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_27_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_27_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_27_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_28_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_28_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_28_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_29_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_29_grad/Reshape:0\", shape=(None, 320), dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup_grad/GatherV2_29_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gradients/EncoderDNN/DNN/combine_word_embeddings/SegmentSum_grad/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gradients/EncoderDNN/DNN/combine_word_embeddings/SegmentSum_grad/GatherV2_grad/Reshape:0\", dtype=float32), dense_shape=Tensor(\"gradients/gradients/EncoderDNN/DNN/combine_word_embeddings/SegmentSum_grad/GatherV2_grad/Cast:0\", shape=(None,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float64>\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float64>\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8/9 [=========================>....] - ETA: 0s - loss: 1.0023 - auc: 0.5494 - ap: 0.1703 - mean_div: 2.1881 - min_div: 2.0604 - max_div: 2.3605 - beta: 1.9638 - eta: 0.0068 - t_step: 4.5000<tf.Variable 'Variable:0' shape=() dtype=float64>\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 23s 1s/step - loss: 0.9958 - auc: 0.5509 - ap: 0.1613 - mean_div: 2.0726 - min_div: 1.9602 - max_div: 2.2226 - beta: 2.0680 - eta: 0.0081 - t_step: 5.4000\n",
            "Epoch 2/25\n",
            "9/9 [==============================] - 4s 484ms/step - loss: 0.8936 - auc: 0.6846 - ap: 0.2126 - mean_div: 1.1126 - min_div: 1.0578 - max_div: 1.1942 - beta: 2.8437 - eta: 0.0216 - t_step: 14.4000\n",
            "Epoch 3/25\n",
            "9/9 [==============================] - 4s 443ms/step - loss: 0.7761 - auc: 0.8129 - ap: 0.3921 - mean_div: 0.5493 - min_div: 0.5132 - max_div: 0.6061 - beta: 3.2679 - eta: 0.0351 - t_step: 23.4000\n",
            "Epoch 4/25\n",
            "9/9 [==============================] - 4s 521ms/step - loss: 0.6453 - auc: 0.8827 - ap: 0.4806 - mean_div: 0.2512 - min_div: 0.2187 - max_div: 0.3133 - beta: 3.5637 - eta: 0.0486 - t_step: 32.4000\n",
            "Epoch 5/25\n",
            "9/9 [==============================] - 5s 544ms/step - loss: 0.5205 - auc: 0.9285 - ap: 0.5840 - mean_div: 0.1209 - min_div: 0.0912 - max_div: 0.1865 - beta: 3.7913 - eta: 0.0621 - t_step: 41.4000\n",
            "Epoch 6/25\n",
            "9/9 [==============================] - 4s 375ms/step - loss: 0.4190 - auc: 0.9546 - ap: 0.6777 - mean_div: 0.0723 - min_div: 0.0462 - max_div: 0.1376 - beta: 3.9765 - eta: 0.0756 - t_step: 50.4000\n",
            "Epoch 7/25\n",
            "9/9 [==============================] - 4s 511ms/step - loss: 0.3431 - auc: 0.9587 - ap: 0.6783 - mean_div: 0.0526 - min_div: 0.0309 - max_div: 0.1090 - beta: 4.1326 - eta: 0.0891 - t_step: 59.4000\n",
            "Epoch 8/25\n",
            "9/9 [==============================] - 4s 480ms/step - loss: 0.2921 - auc: 0.9718 - ap: 0.7637 - mean_div: 0.0438 - min_div: 0.0256 - max_div: 0.1007 - beta: 4.2676 - eta: 0.1026 - t_step: 68.4000\n",
            "Epoch 9/25\n",
            "9/9 [==============================] - 4s 466ms/step - loss: 0.2569 - auc: 0.9722 - ap: 0.8184 - mean_div: 0.0379 - min_div: 0.0217 - max_div: 0.0927 - beta: 4.3864 - eta: 0.1161 - t_step: 77.4000\n",
            "Epoch 10/25\n",
            "9/9 [==============================] - 4s 443ms/step - loss: 0.2334 - auc: 0.9726 - ap: 0.8274 - mean_div: 0.0338 - min_div: 0.0186 - max_div: 0.0872 - beta: 4.4927 - eta: 0.1296 - t_step: 86.4000\n",
            "Epoch 11/25\n",
            "9/9 [==============================] - 5s 446ms/step - loss: 0.2165 - auc: 0.9529 - ap: 0.8157 - mean_div: 0.0310 - min_div: 0.0172 - max_div: 0.0873 - beta: 4.5887 - eta: 0.1431 - t_step: 95.4000\n",
            "Epoch 12/25\n",
            "9/9 [==============================] - 4s 432ms/step - loss: 0.2042 - auc: 0.9268 - ap: 0.7600 - mean_div: 0.0292 - min_div: 0.0160 - max_div: 0.0791 - beta: 4.6762 - eta: 0.1566 - t_step: 104.4000\n",
            "Epoch 13/25\n",
            "9/9 [==============================] - 4s 495ms/step - loss: 0.1949 - auc: 0.9209 - ap: 0.7747 - mean_div: 0.0277 - min_div: 0.0149 - max_div: 0.0812 - beta: 4.7568 - eta: 0.1701 - t_step: 113.4000\n",
            "Epoch 14/25\n",
            "9/9 [==============================] - 4s 512ms/step - loss: 0.1861 - auc: 0.9159 - ap: 0.7492 - mean_div: 0.0264 - min_div: 0.0143 - max_div: 0.0791 - beta: 4.8313 - eta: 0.1836 - t_step: 122.4000\n",
            "Epoch 15/25\n",
            "9/9 [==============================] - 4s 462ms/step - loss: 0.1791 - auc: 0.9054 - ap: 0.7250 - mean_div: 0.0260 - min_div: 0.0140 - max_div: 0.0797 - beta: 4.9006 - eta: 0.1971 - t_step: 131.4000\n",
            "Epoch 16/25\n",
            "9/9 [==============================] - 4s 516ms/step - loss: 0.1739 - auc: 0.8919 - ap: 0.6666 - mean_div: 0.0255 - min_div: 0.0135 - max_div: 0.0717 - beta: 4.9655 - eta: 0.2106 - t_step: 140.4000\n",
            "Epoch 17/25\n",
            "9/9 [==============================] - 4s 430ms/step - loss: 0.1691 - auc: 0.8792 - ap: 0.6739 - mean_div: 0.0246 - min_div: 0.0130 - max_div: 0.0738 - beta: 5.0263 - eta: 0.2241 - t_step: 149.4000\n",
            "Epoch 18/25\n",
            "9/9 [==============================] - 4s 514ms/step - loss: 0.1642 - auc: 0.8657 - ap: 0.6536 - mean_div: 0.0238 - min_div: 0.0124 - max_div: 0.0750 - beta: 5.0837 - eta: 0.2376 - t_step: 158.4000\n",
            "Epoch 19/25\n",
            "9/9 [==============================] - 4s 508ms/step - loss: 0.1609 - auc: 0.8911 - ap: 0.6446 - mean_div: 0.0236 - min_div: 0.0125 - max_div: 0.0757 - beta: 5.1380 - eta: 0.2511 - t_step: 167.4000\n",
            "Epoch 20/25\n",
            "9/9 [==============================] - 5s 509ms/step - loss: 0.1559 - auc: 0.8798 - ap: 0.6337 - mean_div: 0.0225 - min_div: 0.0117 - max_div: 0.0709 - beta: 5.1895 - eta: 0.2646 - t_step: 176.4000\n",
            "Epoch 21/25\n",
            "9/9 [==============================] - 4s 294ms/step - loss: 0.1524 - auc: 0.8764 - ap: 0.6198 - mean_div: 0.0217 - min_div: 0.0114 - max_div: 0.0647 - beta: 5.2385 - eta: 0.2781 - t_step: 185.4000\n",
            "Epoch 22/25\n",
            "9/9 [==============================] - 4s 372ms/step - loss: 0.1490 - auc: 0.8668 - ap: nan - mean_div: 0.0211 - min_div: 0.0111 - max_div: 0.0665 - beta: 5.2851 - eta: 0.2916 - t_step: 194.4000\n",
            "Epoch 23/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 4s 479ms/step - loss: 0.1457 - auc: 0.8307 - ap: 0.5665 - mean_div: 0.0206 - min_div: 0.0107 - max_div: 0.0725 - beta: 5.3297 - eta: 0.3051 - t_step: 203.4000\n",
            "Epoch 24/25\n",
            "9/9 [==============================] - 4s 391ms/step - loss: 0.1433 - auc: 0.8519 - ap: 0.5869 - mean_div: 0.0204 - min_div: 0.0098 - max_div: 0.0743 - beta: 5.3724 - eta: 0.3186 - t_step: 212.4000\n",
            "Epoch 25/25\n",
            "9/9 [==============================] - 5s 452ms/step - loss: 0.1409 - auc: 0.8511 - ap: 0.5769 - mean_div: 0.0204 - min_div: 0.0099 - max_div: 0.0746 - beta: 5.4134 - eta: 0.3321 - t_step: 221.4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe6df344278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay5pGjWKHKMw"
      },
      "source": [
        "list_min = []\n",
        "list_max = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIe9PBCtHflz",
        "outputId": "2a1b9d8b-e517-4f89-919c-cf3155dbc889"
      },
      "source": [
        "print(list_min)\n",
        "print(list_max)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lxGKBy4hVVH"
      },
      "source": [
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train'], loc='upper left')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci8n2ixwH8si"
      },
      "source": [
        "## Тестирование модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PzM-V7oH7hE",
        "outputId": "94c12d8a-f45d-4e51-b37a-c18f588219a9"
      },
      "source": [
        "# model_rsrae.predict(x) - ВЫДАЕТ НЕПОНЯТНЫЕ ОШИБКИ\n",
        "e, _, _, x_predict = model_rsrae.call(x)\n",
        "\n",
        "auc = roc_auc_score(y, cosine_similarity(x_predict, e))\n",
        "ap = average_precision_score(y, cosine_similarity(x_predict, e))\n",
        "                                    \n",
        "print(\"auc = \", auc)\n",
        "print(\"ap = \", ap)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "auc =  0.8534327009936766\n",
            "ap =  0.5398163453945186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ActbTm8PcKh",
        "outputId": "ce423c80-d25d-4b7b-e1c2-7ed41b13d4e1"
      },
      "source": [
        "\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1083,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-El0X-36Pga6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "604cf945-85c8-4dc8-df00-4a95c54ce7ef"
      },
      "source": [
        "pd.Series(all_data).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1083,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AyDhgUlfyul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50722c13-323f-47c2-e277-f8fb7f245f37"
      },
      "source": [
        "l = Dense(10, activation='softmax')\n",
        "l.variables"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "dRzf8Vcw4Rqv",
        "outputId": "4160c929-7a02-4695-911c-0bad24881a0c"
      },
      "source": [
        "    \n",
        "dense1 = layers.Dense(10, activation='relu')\n",
        "y = dense1(input_x)\n",
        "weights = dense1.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-47d9b8c12f80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdense1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJO-1pCHFhxx"
      },
      "source": [
        "a = tf.constant([[1, 2], [3, 4]])\n",
        "b = np.array(tf.reduce_max(a))\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYJT5ECi3jis"
      },
      "source": [
        ""
      ]
    }
  ]
}